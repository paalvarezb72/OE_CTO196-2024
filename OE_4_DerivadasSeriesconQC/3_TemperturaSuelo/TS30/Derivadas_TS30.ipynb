{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad644f7",
   "metadata": {},
   "source": [
    "# Cálculo de derivadas temperatura del suelo -30cm y graficación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a268314",
   "metadata": {},
   "source": [
    "> Elaborado por Paola Álvarez, profesional contratista IDEAM, contrato 196 de 2024. Comentarios o inquietudes, remitir a *palvarez@ideam.gov.co* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc197bfa",
   "metadata": {},
   "source": [
    "**Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a06ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import statistics\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import gc\n",
    "import calendar\n",
    "from collections import deque\n",
    "from datetime import timedelta\n",
    "from scipy import stats\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.chart import ScatterChart, Reference, Series\n",
    "from openpyxl.chart import LineChart, Reference\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5dbca0",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0b13d-32b9-4249-8f67-b9579629c775",
   "metadata": {},
   "source": [
    "### Pruebas unitarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27ed7b",
   "metadata": {},
   "source": [
    "#### Datos con QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8cdb286-46d3-49de-8050-56a678c42f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar frecuencias\n",
    "def process_frequencies(df, columna_fecha, freq_csv_path, porc_min=0.7):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Cargar el archivo de frecuencias\n",
    "    freqinst200b = pd.read_csv(freq_csv_path, encoding='latin-1')\n",
    "\n",
    "    # Definir el diccionario de frecuencias y cantidades esperadas\n",
    "    frecuencias = {\n",
    "        'T': {'cant_esperd_h': 60, 'cant_esperd_d': 1440, 'cant_esperd_m': 43200, 'cant_esperd_a': 518400, 'minutos': 1},\n",
    "        '5T': {'cant_esperd_h': 12, 'cant_esperd_d': 288, 'cant_esperd_m': 8640, 'cant_esperd_a': 103680, 'minutos': 5},\n",
    "        '10T': {'cant_esperd_h': 6, 'cant_esperd_d': 144, 'cant_esperd_m': 4320, 'cant_esperd_a': 51840, 'minutos': 10},\n",
    "        'h': {'cant_esperd_h': 1, 'cant_esperd_d': 24, 'cant_esperd_m': 720, 'cant_esperd_a': 8640}\n",
    "    }\n",
    "\n",
    "    # Obtener el valor de la estación\n",
    "    station_value = df['Station'].values[0]\n",
    "    freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == station_value]\n",
    "    periodos = freqinst200b_station['FreqInf'].values[0]\n",
    "\n",
    "    if pd.isna(periodos):\n",
    "        try:\n",
    "            periodos = pd.infer_freq(df[columna_fecha][-25:])\n",
    "            print(periodos)\n",
    "            if periodos is None:\n",
    "                print(f\"Frecuencia inferida es None para el archivo {df}\")\n",
    "                return None, None, None, None\n",
    "        except ValueError as e:\n",
    "            print(f'Error al inferir la frecuencia en el archivo {df}: {str(e)}')\n",
    "            return None, None, None, None\n",
    "\n",
    "    # Obtener las cantidades esperadas y el offset en minutos\n",
    "    cant_esperd_h = frecuencias[periodos]['cant_esperd_h']\n",
    "    cant_esperd_d = frecuencias[periodos]['cant_esperd_d']\n",
    "    cant_esperd_m = frecuencias[periodos]['cant_esperd_m']\n",
    "    cant_esperd_a = frecuencias[periodos]['cant_esperd_a']\n",
    "    if periodos == 'h':\n",
    "        pass\n",
    "    else:\n",
    "        minutoffset = frecuencias[periodos]['minutos']\n",
    "\n",
    "    # Ajustar la hora de cada registro\n",
    "    df_c = df.copy()\n",
    "    if periodos == 'h':\n",
    "        df_c[columna_fecha] = df_c[columna_fecha] - pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df_c[columna_fecha] = df_c[columna_fecha] - pd.Timedelta(minutes=minutoffset)\n",
    "\n",
    "    # Establecer la columna de fecha como índice\n",
    "    df_c.set_index(columna_fecha, inplace=True)\n",
    "\n",
    "    # Función para verificar si un día, mes o año tiene suficientes datos\n",
    "    def complet_dia(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_d * porc_min\n",
    "\n",
    "    def complet_mes(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_m * porc_min\n",
    "\n",
    "    def complet_anio(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_a * porc_min\n",
    "\n",
    "    return df_c, complet_dia, complet_mes, complet_anio\n",
    "\n",
    "# Uso funciones de frecuencias\n",
    "df_example = pd.read_csv('../../OE_3_QC_Variables/2_HumedadRelativa/Test_QC/Estacion_0011025501_qc.csv', encoding='latin-1')#, dtype={'Estado_Anterior':str})\n",
    "if 'Estado' in df_example.columns:\n",
    "    df_example = df_example[~df_example['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PSO','0PAT','0PER']]))]\n",
    "    \n",
    "columna_fecha = 'Fecha'\n",
    "freq_csv_path = '../../OE_3_QC_Variables/2_HumedadRelativa/EMATS30_LatLonEntFreq2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74e85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2_22/07/2024, cambio de procesamiento de frecuencias\n",
    "## Derivadas diarias, mensuales y anuales\n",
    "# Humedad relativa del aire a 10 cm media diaria\n",
    "df_example_c = df_example.copy()\n",
    "def TS30_MEDIA_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "     \n",
    "    # Se filtran los que hayan superaddo las pruebas\n",
    "    #dfC = df[df['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PC']]))]\n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, complet_dia, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_dia is None:\n",
    "        return None\n",
    "\n",
    "    # Se filtran los datos que tienen la complititud mínima\n",
    "    df_filtrado = df_c.groupby([df_c.index.date]).filter(complet_dia) #dfC.groupby([dfC.index.date]).filter(complet_dia)\n",
    "    TS30_med_d = df_filtrado[[columna_valor]].resample('D').mean()\n",
    "\n",
    "    return TS30_med_d\n",
    "\n",
    "# Ejemplo de uso de la función\n",
    "dfTS30_med_d = TS30_MEDIA_D(df_example_c)\n",
    "\n",
    "# Presión atmosférica media mensual\n",
    "def TS30_MEDIA_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):    \n",
    "    df.reset_index(inplace=True)\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    \n",
    "    # Establecer la columna 'Fecha' como índice\n",
    "    df.set_index(columna_fecha, inplace=True)\n",
    "    \n",
    "    days_in_month = df.index.to_series().dt.days_in_month\n",
    "    days_in_month = days_in_month.resample('ME').first()\n",
    "    \n",
    "    # Función para verificar si una hora específica tiene suficientes datos\n",
    "    def complet_mes(sub_df):\n",
    "        mes = sub_df.index[0].month\n",
    "        total_esperado = days_in_month[days_in_month.index.month == mes].iloc[0]\n",
    "        return len(sub_df) >= total_esperado * porc_min\n",
    "\n",
    "    # Luego de establecer el índice, aplicar resample\n",
    "    df_filtrado = df.groupby([df.index.year, df.index.month]).filter(complet_mes)\n",
    "    TS30_med_m = df_filtrado[['Valor']].resample('ME').mean()\n",
    "    \n",
    "    return TS30_med_m\n",
    "\n",
    "dfTS30_med_m = TS30_MEDIA_M(dfTS30_med_d)\n",
    "\n",
    "# Presión atmosférica del Aire a 2 metros media anual\n",
    "def TS30_MEDIA_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "    df.reset_index(inplace=True)\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    \n",
    "    # Función para verificar si una hora específica tiene suficientes datos\n",
    "    def complet_anio(sub_df):\n",
    "        return len(sub_df) >= 12 * porc_min\n",
    "       \n",
    "    # Antes de resample, establecer la columna 'Fecha' como índice\n",
    "    df.set_index(columna_fecha, inplace=True)\n",
    "\n",
    "    # Luego de establecer el índice, aplicar resample\n",
    "    df_filtrado = df.groupby([df.index.year]).filter(complet_anio)\n",
    "    TS30_med_a = df_filtrado[['Valor']].resample('YE').mean()\n",
    "    \n",
    "    return TS30_med_a\n",
    "\n",
    "dfTS30_med_a = TS30_MEDIA_A(dfTS30_med_m)\n",
    "\n",
    "###-- Derivados máximos y mínimos\n",
    "#Humedad relativa del aire a 10 cm  mínima diaria\n",
    "df_example_c = df_example.copy()\n",
    "def TS30_MN_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, complet_dia, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_dia is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los días que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    dias_validos = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_dia).index\n",
    "    \n",
    "    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "    dias_validos = pd.to_datetime(dias_validos).normalize()\n",
    "    df_filtrado = df_c[df_c.index.normalize().isin(dias_validos)]\n",
    "    \n",
    "    # Encontrar el valor mínimo por cada día válido\n",
    "    idx_minimos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmin()\n",
    "    mn_d = df_filtrado.loc[idx_minimos_dia]\n",
    "    \n",
    "    # Eliminar la columna temporal antes de retornar el resultado\n",
    "    if 'Fecha_temp' in mn_d.columns:\n",
    "        mn_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "    \n",
    "    return mn_d[[columna_valor]]\n",
    "\n",
    "df_mn_d = TS30_MN_D(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm  máxima diaria\n",
    "df_example_c = df_example.copy()\n",
    "def TS30_MX_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, complet_dia, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_dia is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los días que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    dias_validos = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_dia).index\n",
    "    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "    dias_validos = pd.to_datetime(dias_validos).normalize()\n",
    "    df_filtrado = df_c[df_c.index.normalize().isin(dias_validos)]\n",
    "    # Encontrar el valor mínimo por cada día válido\n",
    "    idx_maximos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmax()\n",
    "    mx_d = df_filtrado.loc[idx_maximos_dia]\n",
    "    \n",
    "    # Eliminar la columna temporal antes de retornar el resultado\n",
    "    if 'Fecha_temp' in mx_d.columns:\n",
    "        mx_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "    \n",
    "    return mx_d[[columna_valor]]\n",
    "\n",
    "df_mx_d = TS30_MX_D(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm  mínima mensual\n",
    "df_example_c = df_example.copy()\n",
    "def TS30_MN_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, _, complet_mes, _ = process_frequencies(df, columna_fecha, freq_csv_path,porc_min)\n",
    "\n",
    "    if df_c is None or complet_mes is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los meses que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    # Eliminar duplicados en el índice\n",
    "    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "    meses_validos = df_c.groupby(df_c.index.to_period('M')).filter(complet_mes).index.to_period('M')\n",
    "\n",
    "    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "    df_filtrado = df_c[df_c.index.to_period('M').isin(meses_validos)]\n",
    "\n",
    "    # Encontrar el valor mínimo por cada mes válido\n",
    "    idx_minimos_mes = df_filtrado.groupby(df_filtrado.index.to_period('M'))[columna_valor].idxmin()\n",
    "    min_m = df_filtrado.loc[idx_minimos_mes]\n",
    "\n",
    "    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "    if 'Fecha_temp' in min_m.columns:\n",
    "        min_m.drop(columns=['Fecha_temp'], inplace=True)\n",
    "\n",
    "    return min_m[[columna_valor]]\n",
    "    \n",
    "df_mn_m = TS30_MN_M(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm  máxima mensual\n",
    "df_example_c = df_example.copy()\n",
    "def TS30_MX_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    \n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, _, complet_mes, _ = process_frequencies(df, columna_fecha, freq_csv_path,porc_min)\n",
    "\n",
    "    if df_c is None or complet_mes is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los meses que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    # Eliminar duplicados en el índice\n",
    "    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "    meses_validos = df_c.groupby(df_c.index.to_period('M')).filter(complet_mes).index.to_period('M')\n",
    "\n",
    "    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "    df_filtrado = df_c[df_c.index.to_period('M').isin(meses_validos)]\n",
    "\n",
    "    # Encontrar el valor mínimo por cada mes válido\n",
    "    idx_maximos_mes = df_filtrado.groupby(df_filtrado.index.to_period('M'))[columna_valor].idxmax()\n",
    "    max_m = df_filtrado.loc[idx_maximos_mes]\n",
    "\n",
    "    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "    if 'Fecha_temp' in max_m.columns:\n",
    "        max_m.drop(columns=['Fecha_temp'], inplace=True)\n",
    "\n",
    "    return max_m[[columna_valor]]\n",
    "    \n",
    "df_mx_m = TS30_MX_M(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm mínima anual\n",
    "df_example_c = df_example.copy()\n",
    "def TS30_MN_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, _, _, complet_anio = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_anio is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los meses que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    # Eliminar duplicados en el índice\n",
    "    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "    anios_validos = df_c.groupby(df_c.index.to_period('A')).filter(complet_anio).index.to_period('A')\n",
    "\n",
    "    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "    df_filtrado = df_c[df_c.index.to_period('A').isin(anios_validos)]\n",
    "\n",
    "    # Encontrar el valor mínimo por cada mes válido\n",
    "    idx_minimos_anio = df_filtrado.groupby(df_filtrado.index.to_period('A'))[columna_valor].idxmin()\n",
    "    min_a = df_filtrado.loc[idx_minimos_anio]\n",
    "\n",
    "    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "    if 'Fecha_temp' in min_a.columns:\n",
    "        min_a.drop(columns=['Fecha_temp'], inplace=True)\n",
    "\n",
    "    return min_a[[columna_valor]]\n",
    "    \n",
    "df_mn_a = TS30_MN_A(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm  máxima anual\n",
    "df_example_c = df_example.copy()\n",
    "def TS30_MX_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, _, _, complet_anio = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_anio is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los meses que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    # Eliminar duplicados en el índice\n",
    "    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "    anios_validos = df_c.groupby(df_c.index.to_period('A')).filter(complet_anio).index.to_period('A')\n",
    "\n",
    "    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "    df_filtrado = df_c[df_c.index.to_period('A').isin(anios_validos)]\n",
    "\n",
    "    # Encontrar el valor mínimo por cada mes válido\n",
    "    idx_minimos_anio = df_filtrado.groupby(df_filtrado.index.to_period('A'))[columna_valor].idxmax()\n",
    "    max_a = df_filtrado.loc[idx_minimos_anio]\n",
    "\n",
    "    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "    if 'Fecha_temp' in max_a.columns:\n",
    "        max_a.drop(columns=['Fecha_temp'], inplace=True)\n",
    "\n",
    "    return max_a[[columna_valor]]\n",
    "    \n",
    "df_mx_a = TS30_MN_A(df_example_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d69c9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfTS30_med_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## -- Gráficas y export en excel\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Se crea un nuevo archivo Excel con openpyxl\u001b[39;00m\n\u001b[0;32m      3\u001b[0m wb \u001b[38;5;241m=\u001b[39m Workbook()\n\u001b[0;32m      4\u001b[0m sheets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MEDIA_D\u001b[39m\u001b[38;5;124m'\u001b[39m: dfTS30_med_d, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MEDIA_M\u001b[39m\u001b[38;5;124m'\u001b[39m: dfTS30_med_m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MEDIA_A\u001b[39m\u001b[38;5;124m'\u001b[39m: dfTS30_med_a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MN_D\u001b[39m\u001b[38;5;124m'\u001b[39m: df_mn_d,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MX_D\u001b[39m\u001b[38;5;124m'\u001b[39m: df_mx_d, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MN_M\u001b[39m\u001b[38;5;124m'\u001b[39m: df_mn_m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MX_M\u001b[39m\u001b[38;5;124m'\u001b[39m: df_mx_m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MN_A\u001b[39m\u001b[38;5;124m'\u001b[39m: df_mn_a,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS30_MX_A\u001b[39m\u001b[38;5;124m'\u001b[39m: df_mx_a \n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Si el workbook todavía tiene la hoja por defecto, se elimina\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSheet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m wb\u001b[38;5;241m.\u001b[39msheetnames:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfTS30_med_d' is not defined"
     ]
    }
   ],
   "source": [
    "## -- Gráficas y export en excel\n",
    "# Se crea un nuevo archivo Excel con openpyxl\n",
    "wb = Workbook()\n",
    "sheets = {\n",
    "    'TS30_MEDIA_D': dfTS30_med_d, 'TS30_MEDIA_M': dfTS30_med_m,\n",
    "    'TS30_MEDIA_A': dfTS30_med_a, 'TS30_MN_D': df_mn_d,\n",
    "    'TS30_MX_D': df_mx_d, 'TS30_MN_M': df_mn_m,\n",
    "    'TS30_MX_M': df_mx_m, 'TS30_MN_A': df_mn_a,\n",
    "    'TS30_MX_A': df_mx_a \n",
    "}\n",
    "\n",
    "# Si el workbook todavía tiene la hoja por defecto, se elimina\n",
    "if \"Sheet\" in wb.sheetnames:\n",
    "    del wb[\"Sheet\"]\n",
    "\n",
    "for sheet_name, data in sheets.items():\n",
    "    ws = wb.create_sheet(title=sheet_name)\n",
    "    \n",
    "    # Agregamos los datos al Excel\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(data, index=True, header=True), 1):\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "    \n",
    "    # Crear una gráfica\n",
    "    chart = LineChart()\n",
    "    chart.title = sheet_name\n",
    "    chart.style = 5\n",
    "    chart.y_axis.title = 'Humedad relativa (%)'\n",
    "    chart.x_axis.title = 'Fecha'\n",
    "    \n",
    "    # Establecer datos para la gráfica\n",
    "    max_row = ws.max_row\n",
    "    values = Reference(ws, min_col=2, min_row=2, max_col=2, max_row=max_row)\n",
    "    dates = Reference(ws, min_col=1, min_row=3, max_col=1, max_row=max_row)\n",
    "    chart.add_data(values, titles_from_data=True)\n",
    "    chart.set_categories(dates)\n",
    "    \n",
    "    # Quitar la leyenda\n",
    "    chart.legend = None\n",
    "        \n",
    "    # Posicionar la gráfica en el Excel\n",
    "    ws.add_chart(chart, \"E3\")\n",
    "\n",
    "# Guardar el archivo Excel\n",
    "wb.save(\"Agreg_graf_TS30_AUT_60_5T_cohr5vals.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4c130",
   "metadata": {},
   "source": [
    "## Función para cálculo masivo de derivadas y generación de gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfd6f3d-f60d-4d27-b653-7eb769b203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar frecuencias\n",
    "def process_frequencies(df, columna_fecha, freq_csv_path, porc_min=0.7):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Cargar el archivo de frecuencias\n",
    "    freqinst200b = pd.read_csv(freq_csv_path, encoding='latin-1', sep=';')\n",
    "\n",
    "    # Definir el diccionario de frecuencias y cantidades esperadas\n",
    "    frecuencias = {\n",
    "        'min': {'cant_esperd_h': 60, 'cant_esperd_d': 1440, 'cant_esperd_m': 43200, 'cant_esperd_a': 518400, 'minutos': 1},\n",
    "        '5min': {'cant_esperd_h': 12, 'cant_esperd_d': 288, 'cant_esperd_m': 8640, 'cant_esperd_a': 103680, 'minutos': 5},\n",
    "        '10min': {'cant_esperd_h': 6, 'cant_esperd_d': 144, 'cant_esperd_m': 4320, 'cant_esperd_a': 51840, 'minutos': 10},\n",
    "        'h': {'cant_esperd_h': 1, 'cant_esperd_d': 24, 'cant_esperd_m': 720, 'cant_esperd_a': 8640}\n",
    "    }\n",
    "\n",
    "    # Obtener el valor de la estación\n",
    "    station_value = df['Station'].values[0]\n",
    "    freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == station_value]\n",
    "    periodos = freqinst200b_station['FreqInf'].values[0]\n",
    "\n",
    "    if pd.isna(periodos):\n",
    "        try:\n",
    "            periodos = pd.infer_freq(df[columna_fecha][-25:])\n",
    "            if periodos is None:\n",
    "                project_value = freqinst100b_station['Instituc'].values[0]\n",
    "                periodos = {'CENICAFE': '5min', 'IDEAM': '10min', 'CAR': 'h', 'IDIGER': 'min'}.get(project_value, 'min')\n",
    "                print(f\"Frecuencia inferida para {df['Station']} es None. Se determina según entidad {project_value}\")\n",
    "                \n",
    "                #return None, None, None, None, None, None\n",
    "        except ValueError as e:\n",
    "            print(f'Error al inferir la frecuencia en el archivo {df}: {str(e)}')\n",
    "            return None, None, None, None, None, None\n",
    "\n",
    "    # Obtener las cantidades esperadas y el offset en minutos\n",
    "    cant_esperd_h = frecuencias[periodos]['cant_esperd_h']\n",
    "    cant_esperd_d = frecuencias[periodos]['cant_esperd_d']\n",
    "    cant_esperd_m = frecuencias[periodos]['cant_esperd_m']\n",
    "    cant_esperd_a = frecuencias[periodos]['cant_esperd_a']\n",
    "    if periodos == 'h':\n",
    "        pass\n",
    "    else:\n",
    "        minutoffset = frecuencias[periodos]['minutos']\n",
    "\n",
    "    # Ajustar la hora de cada registro\n",
    "    df_c = df.copy()\n",
    "    if periodos == 'h':\n",
    "        df_c[columna_fecha] = df_c[columna_fecha] #- pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df_c[columna_fecha] = df_c[columna_fecha] - pd.Timedelta(minutes=minutoffset)\n",
    "\n",
    "    # Establecer la columna de fecha como índice\n",
    "    df_c.set_index(columna_fecha, inplace=True)\n",
    "\n",
    "    # Función para verificar si un día, mes o año tiene suficientes datos\n",
    "    def complet_hora(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_h * porc_min\n",
    "    \n",
    "    def complet_dia(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_d * porc_min\n",
    "\n",
    "    def complet_mes(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_m * porc_min\n",
    "\n",
    "    def complet_anio(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_a * porc_min\n",
    "\n",
    "    return df_c, periodos, complet_hora, complet_dia, complet_mes, complet_anio\n",
    "\n",
    "# # Uso funciones de frecuencias\n",
    "# df_example = pd.read_csv('../../OE_3_QC_Variables/2_HumedadRelativa/Test_QC/Estacion_0011115501.csv', encoding='latin-1')#, dtype={'Estado_Anterior':str})\n",
    "# if 'Estado' in df_example.columns:\n",
    "#     df_example = df_example[df_example['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PC']]))]    \n",
    "columna_fecha = 'Fecha'\n",
    "freq_csv_path = '../../../OE_3_QC_Variables/3_TemperaturaSuelo/TS30/EMATS30_LatLonEntFreq.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb23a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cálculo de derivadas de varios archivos en una sola carpeta\n",
    "def calc_deriv_TS30(carpeta, chunk_size=540000):\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Se recorre cada archivo en la carpeta\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(carpeta, archivo)\n",
    "        \n",
    "            # Se procesan los archivos csv por fragmentos\n",
    "            reader = pd.read_csv(ruta_archivo, encoding='latin-1', chunksize=chunk_size)\n",
    "            \n",
    "            for chunk in reader:\n",
    "                # Se generan dataframes analizados\n",
    "                # De cada chunk se transforma a datetime la serie/columna 'Fecha'\n",
    "                try:\n",
    "                    chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                except ValueError:\n",
    "                    chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    try:\n",
    "                        dfC = chunk[~chunk['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PSO0','0PAT','0PER']]))]\n",
    "                        dfC_c = dfC.copy()\n",
    "                        station_value = dfC_c['Station'].values[0]\n",
    "                    except IndexError:\n",
    "                        print(f\"Error en el archivo {archivo}: dfC está vacío. Saltando al siguiente archivo.\")\n",
    "                        continue  # Sale del bucle de chunks y continúa con el siguiente archivo\n",
    "                else:\n",
    "                    chunk_c = chunk.copy()\n",
    "                    station_value = chunk_c['Station'].values[0]\n",
    "\n",
    "                # Humedad relativa media horaria\n",
    "                def TS30_MEDIA_H(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):  \n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                        \n",
    "                    # Se filtran los que hayan superaddo las pruebas\n",
    "                    df_c, periodos, complet_hora, _, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    # Luego de establecer el índice, aplicar resample\n",
    "                    df_filtrado = df_c.groupby([df_c.index.date, df_c.index.hour]).filter(complet_hora)\n",
    "                    ts30_med_h = df_filtrado[['Valor']].resample('h').mean()\n",
    "                \n",
    "                    return ts30_med_h[['Valor']]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    dfts30_med_h = TS30_MEDIA_H(dfC_c)\n",
    "                else:\n",
    "                    dfts30_med_h = TS30_MEDIA_H(chunk_c)\n",
    "                \n",
    "                ## Derivadas diarias, mensuales y anuales\n",
    "                # Humedad relativa del aire a 10 cm media diaria\n",
    "                def TS30_MEDIA_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    df.reset_index(inplace=True)\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    \n",
    "                    # Cantidad esperada por día\n",
    "                    cant_esperd_d = 24\n",
    "                    # Función para verificar si una hora específica tiene suficientes datos\n",
    "                    def complet_dia(sub_df, total_esperado=cant_esperd_d, porc_min=porc_min):\n",
    "                        return len(sub_df) >= total_esperado * porc_min\n",
    "                    \n",
    "                    df.set_index('Fecha', inplace=True)\n",
    "                    # Se filtran los datos que tienen la complititud mínima\n",
    "                    df_filtrado = df.groupby([df.index.date]).filter(complet_dia) \n",
    "                    ts30_med_d = df_filtrado[[columna_valor]].resample('D').mean()\n",
    "                \n",
    "                    return ts30_med_d\n",
    "                \n",
    "                dfts30_med_d = TS30_MEDIA_D(dfts30_med_h)\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                #if 'Estado' in chunk.columns:\n",
    "                #    dfts30_med_d = TS30_MEDIA_D(dfC_c)\n",
    "                #else:\n",
    "                #    dfts30_med_d = TS30_MEDIA_D(chunk_c)\n",
    "                \n",
    "                # Presión atmosférica media mensual\n",
    "                def TS30_MEDIA_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):    \n",
    "                    if df is None:\n",
    "                        return None                  \n",
    "                    days_in_month = df.index.to_series().dt.days_in_month\n",
    "                    days_in_month = days_in_month.resample('ME').first()\n",
    "                    \n",
    "                    # Función para verificar si una hora específica tiene suficientes datos\n",
    "                    def complet_mes(sub_df):\n",
    "                        mes = sub_df.index[0].month\n",
    "                        total_esperado = days_in_month[days_in_month.index.month == mes].iloc[0]\n",
    "                        return len(sub_df) >= total_esperado * porc_min\n",
    "                \n",
    "                    # Luego de establecer el índice, aplicar resample\n",
    "                    df_filtrado = df.groupby([df.index.year, df.index.month]).filter(complet_mes)\n",
    "                    ts30_med_m = df_filtrado[['Valor']].resample('ME').mean()\n",
    "                    \n",
    "                    return ts30_med_m\n",
    "                \n",
    "                dfts30_med_m = TS30_MEDIA_M(dfts30_med_d)\n",
    "                \n",
    "                # Presión atmosférica del Aire a 2 metros media anual\n",
    "                def TS30_MEDIA_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    if df is None:\n",
    "                        return None\n",
    "                    \n",
    "                    # Función para verificar si una hora específica tiene suficientes datos\n",
    "                    def complet_anio(sub_df):\n",
    "                        return len(sub_df) >= 12 * porc_min\n",
    "                \n",
    "                    # Luego de establecer el índice, aplicar resample\n",
    "                    df_filtrado = df.groupby([df.index.year]).filter(complet_anio)\n",
    "                    ts30_med_a = df_filtrado[['Valor']].resample('YE').mean()\n",
    "                    \n",
    "                    return ts30_med_a\n",
    "                \n",
    "                dfts30_med_a = TS30_MEDIA_A(dfts30_med_m)\n",
    "                \n",
    "                ###-- Derivados máximos y mínimos\n",
    "                #Humedad relativa del aire a 10 cm  mínima diaria\n",
    "                def TS30_MN_H(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo, complet_hora, _, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_hora is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los días que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    horas_validas = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_hora).index\n",
    "                    \n",
    "                    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "                    horas_validas = pd.to_datetime(horas_validas).normalize()\n",
    "                    df_filtrado = df_c[df_c.index.normalize().isin(horas_validas)]\n",
    "                    \n",
    "                    # Encontrar el valor mínimo por cada día válido\n",
    "                    idx_minimos_hora = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmin()\n",
    "                    mn_d = df_filtrado.loc[idx_minimos_hora]\n",
    "                    \n",
    "                    # Eliminar la columna temporal antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in mn_d.columns:\n",
    "                        mn_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                    \n",
    "                    return mn_d[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_h = TS30_MN_H(dfC_c)\n",
    "                else:\n",
    "                    df_mn_h = TS30_MN_H(chunk_c)\n",
    "                   \n",
    "                #Humedad relativa del aire a 10 cm  mínima diaria\n",
    "                def TS30_MX_H(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo, complet_hora, _, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_hora is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los días que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    horas_validas = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_hora).index\n",
    "                    \n",
    "                    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "                    horas_validas = pd.to_datetime(horas_validas).normalize()\n",
    "                    df_filtrado = df_c[df_c.index.normalize().isin(horas_validas)]\n",
    "                    \n",
    "                    # Encontrar el valor mínimo por cada día válido\n",
    "                    idx_maximos_hora = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmax()\n",
    "                    mx_h = df_filtrado.loc[idx_maximos_hora]\n",
    "                    \n",
    "                    # Eliminar la columna temporal antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in mx_h.columns:\n",
    "                        mx_h.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                    \n",
    "                    return mx_h[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mx_h = TS30_MX_H(dfC_c)\n",
    "                else:\n",
    "                    df_mx_h = TS30_MX_H(chunk_c)\n",
    "                \n",
    "                def TS30_MN_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,complet_dia, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_dia is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los días que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    dias_validos = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_dia).index\n",
    "                    \n",
    "                    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "                    dias_validos = pd.to_datetime(dias_validos).normalize()\n",
    "                    df_filtrado = df_c[df_c.index.normalize().isin(dias_validos)]\n",
    "                    \n",
    "                    # Encontrar el valor mínimo por cada día válido\n",
    "                    idx_minimos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmin()\n",
    "                    mn_d = df_filtrado.loc[idx_minimos_dia]\n",
    "                    \n",
    "                    # Eliminar la columna temporal antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in mn_d.columns:\n",
    "                        mn_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                    \n",
    "                    return mn_d[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_d = TS30_MN_D(dfC_c)\n",
    "                else:\n",
    "                    df_mn_d = TS30_MN_D(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm  máxima diaria\n",
    "                def TS30_MX_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,complet_dia,_,_ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_dia is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los días que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    dias_validos = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_dia).index\n",
    "                    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "                    dias_validos = pd.to_datetime(dias_validos).normalize()\n",
    "                    df_filtrado = df_c[df_c.index.normalize().isin(dias_validos)]\n",
    "                    # Encontrar el valor mínimo por cada día válido\n",
    "                    idx_maximos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmax()\n",
    "                    mx_d = df_filtrado.loc[idx_maximos_dia]\n",
    "                    \n",
    "                    # Eliminar la columna temporal antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in mx_d.columns:\n",
    "                        mx_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                    \n",
    "                    return mx_d[[columna_valor]]\n",
    "                \n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mx_d = TS30_MX_D(dfC_c)\n",
    "                else:\n",
    "                    df_mx_d = TS30_MX_D(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm  mínima mensual\n",
    "                def TS30_MN_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,_,complet_mes,_ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_mes is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los meses que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    # Eliminar duplicados en el índice\n",
    "                    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "                    meses_validos = df_c.groupby(df_c.index.to_period('M')).filter(complet_mes).index.to_period('M')\n",
    "                \n",
    "                    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "                    df_filtrado = df_c[df_c.index.to_period('M').isin(meses_validos)]\n",
    "                \n",
    "                    # Encontrar el valor mínimo por cada mes válido\n",
    "                    idx_minimos_mes = df_filtrado.groupby(df_filtrado.index.to_period('M'))[columna_valor].idxmin()\n",
    "                    min_m = df_filtrado.loc[idx_minimos_mes]\n",
    "                \n",
    "                    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in min_m.columns:\n",
    "                        min_m.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                \n",
    "                    return min_m[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_m = TS30_MN_M(dfC_c)\n",
    "                else:\n",
    "                    df_mn_m = TS30_MN_M(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm  máxima mensual\n",
    "                def TS30_MX_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,_,complet_mes,_ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_mes is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los meses que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    # Eliminar duplicados en el índice\n",
    "                    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "                    meses_validos = df_c.groupby(df_c.index.to_period('M')).filter(complet_mes).index.to_period('M')\n",
    "                \n",
    "                    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "                    df_filtrado = df_c[df_c.index.to_period('M').isin(meses_validos)]\n",
    "                \n",
    "                    # Encontrar el valor mínimo por cada mes válido\n",
    "                    idx_maximos_mes = df_filtrado.groupby(df_filtrado.index.to_period('M'))[columna_valor].idxmax()\n",
    "                    max_m = df_filtrado.loc[idx_maximos_mes]\n",
    "                \n",
    "                    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in max_m.columns:\n",
    "                        max_m.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                \n",
    "                    return max_m[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mx_m = TS30_MX_M(dfC_c)\n",
    "                else:\n",
    "                    df_mx_m = TS30_MX_M(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm mínima anual\n",
    "                def TS30_MN_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,_,_,complet_anio = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_anio is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los meses que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    # Eliminar duplicados en el índice\n",
    "                    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "                    anios_validos = df_c.groupby(df_c.index.to_period('Y')).filter(complet_anio).index.to_period('Y')\n",
    "                \n",
    "                    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "                    df_filtrado = df_c[df_c.index.to_period('Y').isin(anios_validos)]\n",
    "                \n",
    "                    # Encontrar el valor mínimo por cada mes válido\n",
    "                    idx_minimos_anio = df_filtrado.groupby(df_filtrado.index.to_period('Y'))[columna_valor].idxmin()\n",
    "                    min_a = df_filtrado.loc[idx_minimos_anio]\n",
    "                \n",
    "                    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in min_a.columns:\n",
    "                        min_a.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                \n",
    "                    return min_a[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_a = TS30_MN_A(dfC_c)\n",
    "                else:\n",
    "                    df_mn_a = TS30_MN_A(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm  máxima anual\n",
    "                def TS30_MX_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.7):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,_,_,complet_anio = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_anio is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los meses que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    # Eliminar duplicados en el índice\n",
    "                    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "                    anios_validos = df_c.groupby(df_c.index.to_period('Y')).filter(complet_anio).index.to_period('Y')\n",
    "                \n",
    "                    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "                    df_filtrado = df_c[df_c.index.to_period('Y').isin(anios_validos)]\n",
    "                \n",
    "                    # Encontrar el valor mínimo por cada mes válido\n",
    "                    idx_maximos_anio = df_filtrado.groupby(df_filtrado.index.to_period('Y'))[columna_valor].idxmax()\n",
    "                    max_a = df_filtrado.loc[idx_maximos_anio]\n",
    "                \n",
    "                    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in max_a.columns:\n",
    "                        max_a.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                \n",
    "                    return max_a[[columna_valor]]\n",
    "                    \n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mx_a = TS30_MX_A(dfC_c)\n",
    "                else:\n",
    "                    df_mx_a = TS30_MX_A(chunk_c)\n",
    "        \n",
    "                ### Se crea un nuevo archivo Excel con openpyxl\n",
    "                wb = Workbook()\n",
    "                sheets = {\n",
    "                    'TS30_MEDIA_H': dfts30_med_h, 'TS30_MEDIA_D': dfts30_med_d,\n",
    "                    'TS30_MEDIA_M': dfts30_med_m, 'TS30_MEDIA_A': dfts30_med_a, \n",
    "                    'TS30_MN_H': df_mn_h,'TS30_MX_H': df_mx_h,\n",
    "                    'TS30_MN_D': df_mn_d,'TS30_MX_D': df_mx_d, \n",
    "                    'TS30_MN_M': df_mn_m,'TS30_MX_M': df_mx_m, \n",
    "                    'TS30_MN_A': df_mn_a,'TS30_MX_A': df_mx_a \n",
    "                }\n",
    "                \n",
    "                # Si el workbook todavía tiene la hoja por defecto, se elimina\n",
    "                if \"Sheet\" in wb.sheetnames:\n",
    "                    del wb[\"Sheet\"]\n",
    "                \n",
    "                for sheet_name, data in sheets.items():\n",
    "                    ws = wb.create_sheet(title=sheet_name)\n",
    "                    \n",
    "                    # Agregamos los datos al Excel\n",
    "                    if data is None:\n",
    "                        pass\n",
    "                    else:\n",
    "                        for r_idx, row in enumerate(dataframe_to_rows(data, index=True, header=True), 1):\n",
    "                            for c_idx, value in enumerate(row, 1):\n",
    "                                ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "                    \n",
    "                    # Crear una gráfica\n",
    "                    chart = LineChart()\n",
    "                    chart.title = sheet_name\n",
    "                    chart.style = 5\n",
    "                    chart.y_axis.title = 'Temperatura del suelo -30cm (°C)'\n",
    "                    chart.x_axis.title = 'Fecha'\n",
    "                    \n",
    "                    # Establecer datos para la gráfica\n",
    "                    max_row = ws.max_row\n",
    "                    values = Reference(ws, min_col=2, min_row=2, max_col=2, max_row=max_row)\n",
    "                    dates = Reference(ws, min_col=1, min_row=3, max_col=1, max_row=max_row)\n",
    "                    chart.add_data(values, titles_from_data=True)\n",
    "                    chart.set_categories(dates)\n",
    "                    \n",
    "                    # Quitar la leyenda\n",
    "                    chart.legend = None\n",
    "                    \n",
    "                    # Cambiar el grosor de la línea a 0.5 puntos (equivalente a 50 centésimas de punto)\n",
    "                    for series in chart.series:\n",
    "                        series.graphicalProperties.line.width = 50\n",
    "                        series.graphicalProperties.line.solidFill = \"873600\"  # Marrón\n",
    "                        \n",
    "                    # Posicionar la gráfica en el Excel\n",
    "                    ws.add_chart(chart, \"E3\")\n",
    "                \n",
    "                # Nombres archivos\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    nombre_archivo_salida = os.path.join(carpeta, archivo[:22] + '_deriv.xlsx')\n",
    "                else:\n",
    "                    nombre_archivo_salida = os.path.join(carpeta, archivo[:19] + '_deriv.xlsx')\n",
    "                \n",
    "                # Guardar el archivo Excel\n",
    "                wb.save(nombre_archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0262efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_25752\\3041958614.py:13: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en el archivo Estacion_0024015110_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_25752\\3041958614.py:13: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n"
     ]
    }
   ],
   "source": [
    "calc_deriv_TS30('../../../OE_3_QC_Variables/3_TemperaturaSuelo/TS30/QCResult_TS30/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fed6a778-39bc-42b0-afd6-8b5adc4ee4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_deriv_TS30('../../../OE_3_QC_Variables/3_TemperaturaSuelo/TS30/RawUnmodified_TS30/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df022d20-772d-4041-a291-da25abf644e6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0bb96-7e66-4509-90a3-e1a97bf517ec",
   "metadata": {},
   "source": [
    "## Función cálculo masivo de derivadas y alistamiento Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac274a3-3b32-403e-a606-0004f3c97c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_deriv_PA_60(carpeta):#, chunk_size=540000):\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Se crean carpetas para cada tipo de DataFrame si no existen\n",
    "    carpetas_salidas = ['PA_60_MEDIA_D_QC', 'PA_60_MEDIA_M_QC', 'PA_60_MEDIA_A_QC']\n",
    "    for cs in carpetas_salidas:\n",
    "        os.makedirs(os.path.join(carpeta, cs), exist_ok=True)\n",
    "    \n",
    "    # Procesar cada archivo en la carpeta\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(carpeta, archivo)\n",
    "            df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
    "\n",
    "            # Procesar la fecha y filtrar según estado, como en el ejemplo original\n",
    "            try:\n",
    "                df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "            except ValueError:\n",
    "                df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "                  \n",
    "            try:\n",
    "                dfC = df[df['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PC']]))] # Se comenta si es de crudos\n",
    "                station_value = dfC['Station'].values[0] #df['Station'].values[0]\n",
    "            except IndexError:\n",
    "                print(f\"Error en el archivo {archivo}: dfC está vacío. Saltando al siguiente archivo.\")\n",
    "                continue  # Sale del bucle de chunks y continúa con el siguiente archivo\n",
    "\n",
    "            # Presión atmosférica media diaria\n",
    "            def PA_60_MEDIA_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                if df.empty:\n",
    "                    return df\n",
    "                df.reset_index(inplace=True)\n",
    "                # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                # Ajustar la hora de cada registro para que corresponda al rango deseado\n",
    "                df[columna_fecha] = df[columna_fecha] - pd.Timedelta(hours=1)\n",
    "                # Establecer la columna de fecha como índice\n",
    "                df.set_index(columna_fecha, inplace=True)\n",
    "                \n",
    "                # Calcular el total de registros esperados por día pluviométrico\n",
    "                total_esperado_por_dia = 24\n",
    "                # Función para verificar si un día pluviométrico tiene suficientes datos\n",
    "                def complet_dia(sub_df):\n",
    "                    return len(sub_df) >= total_esperado_por_dia * porc_min\n",
    "            \n",
    "                # Filtrar los días con suficientes datos y calcular el promedio diario\n",
    "                df_filtrado = df.groupby([df.index.date]).filter(complet_dia)\n",
    "                # Verificar si el DataFrame filtrado está vacío\n",
    "                if df_filtrado.empty:\n",
    "                    print(f\"DataFrame vacío después de filtrar por días válidos. Regresando {archivo[:19]} vacío.\")\n",
    "                    return df_filtrado\n",
    "                    \n",
    "                # Se calcula la media\n",
    "                PA_60_med_d = df_filtrado[[columna_valor]].resample('D').mean()\n",
    "\n",
    "                # Cambio de contenido de columnas\n",
    "                PA_60_med_d['Station'] = df['Station'].iloc[0]\n",
    "                PA_60_med_d['Station'] = PA_60_med_d['Station'].astype('int64')\n",
    "                PA_60_med_d['Sensor'] = 'PA_60_MEDIA_D_QC'\n",
    "                \n",
    "                # Reset index\n",
    "                PA_60_med_d.reset_index(inplace=True)\n",
    "                \n",
    "                # Se reordenan las columnas\n",
    "                nuevo_orden = ['Station', 'Sensor', 'Fecha', 'Valor']\n",
    "                # Reordenar las columnas usando el nuevo orden\n",
    "                PA_60_med_d = PA_60_med_d[nuevo_orden]\n",
    "            \n",
    "                # Convertir 'Fecha' de nuevo a datetime para uniformidad\n",
    "                PA_60_med_d['Fecha'] = pd.to_datetime(PA_60_med_d['Fecha'])\n",
    "            \n",
    "                return PA_60_med_d\n",
    "\n",
    "            dfmn_med_d = PA_60_MEDIA_D(dfC)\n",
    "            \n",
    "            # Presión atmosférica media mensual\n",
    "            dfmn_med_d_c = dfmn_med_d.copy()\n",
    "            def PA_60_MEDIA_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):    \n",
    "                if df.empty:\n",
    "                    return df\n",
    "                df.reset_index(inplace=True)\n",
    "                # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                \n",
    "                # Establecer la columna 'Fecha' como índice\n",
    "                df.set_index(columna_fecha, inplace=True)\n",
    "                \n",
    "                days_in_month = df.index.to_series().dt.days_in_month\n",
    "                days_in_month = days_in_month.resample('ME').first()\n",
    "                \n",
    "                # Función para verificar si una hora específica tiene suficientes datos\n",
    "                def complet_mes(sub_df):\n",
    "                    mes = sub_df.index[0].month\n",
    "                    total_esperado = days_in_month[days_in_month.index.month == mes].iloc[0]\n",
    "                    return len(sub_df) >= total_esperado * porc_min\n",
    "            \n",
    "                # Luego de establecer el índice, aplicar resample\n",
    "                df_filtrado = df.groupby([df.index.year, df.index.month]).filter(complet_mes)\n",
    "                # Verificar si el DataFrame filtrado está vacío\n",
    "                if df_filtrado.empty:\n",
    "                    print(f\"DataFrame vacío después de filtrar por meses válidos. Regresando {archivo[:19]} vacío.\")\n",
    "                    return df_filtrado\n",
    "                    \n",
    "                # Se calcula la media \n",
    "                PA_60_med_m = df_filtrado[['Valor']].resample('ME').mean()\n",
    "\n",
    "                # Cambio de contenido de columnas\n",
    "                PA_60_med_m['Station'] = df['Station'].iloc[0]\n",
    "                PA_60_med_m['Station'] = PA_60_med_m['Station'].astype('int64')\n",
    "                PA_60_med_m['Sensor'] = 'PA_60_MEDIA_M_QC'\n",
    "                \n",
    "                # Reset index\n",
    "                PA_60_med_m.reset_index(inplace=True)\n",
    "                \n",
    "                # Se reordenan las columnas\n",
    "                nuevo_orden = ['Station', 'Sensor', 'Fecha', 'Valor']\n",
    "                # Reordenar las columnas usando el nuevo orden\n",
    "                PA_60_med_m = PA_60_med_m[nuevo_orden]\n",
    "            \n",
    "                # Convertir 'Fecha' de nuevo a datetime para uniformidad\n",
    "                PA_60_med_m['Fecha'] = pd.to_datetime(PA_60_med_m['Fecha'])\n",
    "                \n",
    "                return PA_60_med_m\n",
    "            \n",
    "            dfmn_med_m = PA_60_MEDIA_M(dfmn_med_d_c)\n",
    "            \n",
    "            # Presión atmosférica media anual\n",
    "            dfmn_med_m_c = dfmn_med_m.copy()\n",
    "            def PA_60_MEDIA_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                if df.empty:\n",
    "                    return df\n",
    "                df.reset_index(inplace=True)\n",
    "                # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                \n",
    "                # Función para verificar si una hora específica tiene suficientes datos\n",
    "                def complet_anio(sub_df):\n",
    "                    return len(sub_df) >= 12 * porc_min\n",
    "                   \n",
    "                # Antes de resample, establecer la columna 'Fecha' como índice\n",
    "                df.set_index(columna_fecha, inplace=True)\n",
    "            \n",
    "                # Luego de establecer el índice, aplicar resample\n",
    "                df_filtrado = df.groupby([df.index.year]).filter(complet_anio)\n",
    "                # Verificar si el DataFrame filtrado está vacío\n",
    "                if df_filtrado.empty:\n",
    "                    print(f\"DataFrame vacío después de filtrar por años válidos. Regresando {archivo[:19]} vacío.\")\n",
    "                    return df_filtrado\n",
    "                    \n",
    "                # Se calcula la media    \n",
    "                PA_60_med_a = df_filtrado[['Valor']].resample('YE').mean()\n",
    "\n",
    "                # Cambio de contenido de columnas\n",
    "                PA_60_med_a['Station'] = df['Station'].iloc[0]\n",
    "                PA_60_med_a['Station'] = PA_60_med_a['Station'].astype('int64')\n",
    "                PA_60_med_a['Sensor'] = 'PA_60_MEDIA_A_QC'\n",
    "                \n",
    "                # Reset index\n",
    "                PA_60_med_a.reset_index(inplace=True)\n",
    "                \n",
    "                # Se reordenan las columnas\n",
    "                nuevo_orden = ['Station', 'Sensor', 'Fecha', 'Valor']\n",
    "                # Reordenar las columnas usando el nuevo orden\n",
    "                PA_60_med_a = PA_60_med_a[nuevo_orden]\n",
    "            \n",
    "                # Convertir 'Fecha' de nuevo a datetime para uniformidad\n",
    "                PA_60_med_a['Fecha'] = pd.to_datetime(PA_60_med_a['Fecha'])\n",
    "                \n",
    "                return PA_60_med_a\n",
    "            \n",
    "            dfmn_med_a = PA_60_MEDIA_A(dfmn_med_m_c)\n",
    "\n",
    "            if not dfmn_med_d.empty:\n",
    "                dfmn_med_d.to_csv(os.path.join(carpeta, 'PA_60_MEDIA_D_QC', f'{archivo[:19]}.csv'), index=False)\n",
    "            if not dfmn_med_m.empty:\n",
    "                dfmn_med_m.to_csv(os.path.join(carpeta, 'PA_60_MEDIA_M_QC', f'{archivo[:19]}.csv'), date_format='%Y-%m', index=False)\n",
    "            if not dfmn_med_a.empty:\n",
    "                dfmn_med_a.to_csv(os.path.join(carpeta, 'PA_60_MEDIA_A_QC', f'{archivo[:19]}.csv'), date_format='%Y',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90943a6b-2791-482e-b411-611884b55457",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_deriv_PA_60('ReadyToCassandraFiles_Tmin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f8d21-7fc5-42ff-88af-84a73cb7cb5a",
   "metadata": {},
   "source": [
    "### Cálculo promedios horarios mensuales multianuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15a30dc0-69e9-4016-8d4d-3033f49e5113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hmMa_TS30(carpeta, chunk_size=540000):\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Se recorre cada archivo en la carpeta\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(carpeta, archivo)\n",
    "        \n",
    "            # Se procesan los archivos csv por fragmentos\n",
    "            reader = pd.read_csv(ruta_archivo, encoding='latin-1', chunksize=chunk_size)\n",
    "            \n",
    "            for chunk in reader:\n",
    "                # Se generan dataframes analizados\n",
    "                # De cada chunk se transforma a datetime la serie/columna 'Fecha'\n",
    "                try:\n",
    "                    chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                except ValueError:\n",
    "                    chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "                    chunk = chunk[~chunk['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PSO0','0PAT','0PER']]))]\n",
    "\n",
    "                # Se hace la agrupación para cálculo de medias horarias mensuales multianuales\n",
    "                hym_ma = chunk['Valor'].groupby(by =[chunk[\"Fecha\"].dt.month, chunk[\"Fecha\"].dt.hour]).mean().unstack(level=0)\n",
    "\n",
    "                # Crear un archivo Excel y agregar los datos\n",
    "                wb = Workbook()\n",
    "                ws = wb.active\n",
    "                ws.title = \"Datos\"\n",
    "                \n",
    "                # Agregar datos al archivo Excel\n",
    "                for r in dataframe_to_rows(hym_ma.reset_index(), index=False, header=True):\n",
    "                    ws.append(r)\n",
    "                \n",
    "                # Crear la gráfica de dispersión\n",
    "                chart = ScatterChart()\n",
    "                chart.title = \"Valores Promedio por Hora y Mes\"\n",
    "                chart.style = 13\n",
    "                chart.x_axis.title = 'Hora del día'\n",
    "                chart.y_axis.title = 'Valor'\n",
    "                \n",
    "                # Aumentar el tamaño del gráfico\n",
    "                chart.width = 20  # Anchura del gráfico (pulgadas)\n",
    "                chart.height = 12  # Altura del gráfico (pulgadas)\n",
    "                \n",
    "                # Fijar el máximo valor del eje x\n",
    "                chart.x_axis.scaling.max = 23\n",
    "                chart.x_axis.scaling.min = 0\n",
    "                chart.x_axis.majorUnit = 1\n",
    "                \n",
    "                # Agregar series a la gráfica\n",
    "                colors = ['1F77B4', 'FF7F0E', '2CA02C', 'D62728', '9467BD', '8C564B', 'E377C2', '7F7F7F', 'BCBD22', '17BECF', 'AEC7E8', 'FFBB78']\n",
    "                for i in range(2, 14):  # Columnas B a M (meses 1 a 12)\n",
    "                    xvalues = Reference(ws, min_col=1, min_row=2, max_row=25)\n",
    "                    yvalues = Reference(ws, min_col=i, min_row=1, max_row=25)\n",
    "                    series = Series(yvalues, xvalues, title_from_data=True)\n",
    "                    series.graphicalProperties.line.solidFill = colors[i % len(colors)]  # Asignar colores a las líneas\n",
    "                    series.graphicalProperties.line.width = 30000  # Ajustar el grosor de las líneas\n",
    "                    series.marker.symbol = 'circle'  # Cambiar el marcador a círculo\n",
    "                    series.marker.size = 5\n",
    "                    series.marker.graphicalProperties.solidFill = colors[i % len(colors)]  # Cambiar el color del marcador\n",
    "                    chart.series.append(series)\n",
    "                \n",
    "                # Insertar la gráfica en la hoja de cálculo\n",
    "                ws.add_chart(chart, \"O2\")\n",
    "\n",
    "                # Nombres archivos\n",
    "                nombre_archivo_salida = os.path.join(carpeta, archivo[:19] + '_hm_ma.xlsx') #archivo[:22] el de qc\n",
    "                # Guardar el archivo Excel\n",
    "                wb.save(nombre_archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1c99242-480a-4d33-afb9-c9b9bf75ad91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_44160\\2207598420.py:12: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_44160\\2207598420.py:12: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n"
     ]
    }
   ],
   "source": [
    "calc_hmMa_TS30('../../../OE_3_QC_Variables/3_TemperaturaSuelo/TS30/QCResult_TS30/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4390a1bb-935c-43dd-8902-c4921521bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_hmMa_TS30('../../../OE_3_QC_Variables/3_TemperaturaSuelo/TS30/RawUnmodified_TS30/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efcfb47-9fdd-4505-b20f-9adac77bdbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
