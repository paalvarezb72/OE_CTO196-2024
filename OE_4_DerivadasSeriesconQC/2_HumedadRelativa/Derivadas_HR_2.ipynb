{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad644f7",
   "metadata": {},
   "source": [
    "# Cálculo de derivadas humedad relativa y graficación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a268314",
   "metadata": {},
   "source": [
    "> Elaborado por Paola Álvarez, profesional contratista IDEAM, contrato 196 de 2024. Comentarios o inquietudes, remitir a *palvarez@ideam.gov.co* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc197bfa",
   "metadata": {},
   "source": [
    "**Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a06ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import statistics\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import gc\n",
    "import calendar\n",
    "from collections import deque\n",
    "from datetime import timedelta\n",
    "from scipy import stats\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.chart import LineChart, Reference\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5dbca0",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0b13d-32b9-4249-8f67-b9579629c775",
   "metadata": {},
   "source": [
    "### Pruebas unitarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27ed7b",
   "metadata": {},
   "source": [
    "#### Datos con QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8cdb286-46d3-49de-8050-56a678c42f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar frecuencias\n",
    "def process_frequencies(df, columna_fecha, freq_csv_path, porc_min=0.67):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Cargar el archivo de frecuencias\n",
    "    freqinst200b = pd.read_csv(freq_csv_path, encoding='latin-1')\n",
    "\n",
    "    # Definir el diccionario de frecuencias y cantidades esperadas\n",
    "    frecuencias = {\n",
    "        'min': {'cant_esperd_h': 60, 'cant_esperd_d': 1440, 'cant_esperd_m': 43200, 'cant_esperd_a': 518400, 'minutos': 1},\n",
    "        '5min': {'cant_esperd_h': 12, 'cant_esperd_d': 288, 'cant_esperd_m': 8640, 'cant_esperd_a': 103680, 'minutos': 5},\n",
    "        '10min': {'cant_esperd_h': 6, 'cant_esperd_d': 144, 'cant_esperd_m': 4320, 'cant_esperd_a': 51840, 'minutos': 10},\n",
    "        'h': {'cant_esperd_h': 1, 'cant_esperd_d': 24, 'cant_esperd_m': 720, 'cant_esperd_a': 8640}\n",
    "    }\n",
    "\n",
    "    # Obtener el valor de la estación\n",
    "    station_value = df['station'].values[0]\n",
    "    freqinst200b_station = freqinst200b.loc[freqinst200b['station'] == station_value]\n",
    "    periodos = freqinst200b_station['FreqInf'].values[0]\n",
    "\n",
    "    if pd.isna(periodos):\n",
    "        try:\n",
    "            periodos = pd.infer_freq(df[columna_fecha][-25:])\n",
    "            print(periodos)\n",
    "            if periodos is None:\n",
    "                print(f\"Frecuencia inferida es None para el archivo {df}\")\n",
    "                return None, None, None, None\n",
    "        except ValueError as e:\n",
    "            print(f'Error al inferir la frecuencia en el archivo {df}: {str(e)}')\n",
    "            return None, None, None, None\n",
    "\n",
    "    # Obtener las cantidades esperadas y el offset en minutos\n",
    "    cant_esperd_h = frecuencias[periodos]['cant_esperd_h']\n",
    "    cant_esperd_d = frecuencias[periodos]['cant_esperd_d']\n",
    "    cant_esperd_m = frecuencias[periodos]['cant_esperd_m']\n",
    "    cant_esperd_a = frecuencias[periodos]['cant_esperd_a']\n",
    "    if periodos == 'h':\n",
    "        pass\n",
    "    else:\n",
    "        minutoffset = frecuencias[periodos]['minutos']\n",
    "\n",
    "    # Ajustar la hora de cada registro\n",
    "    df_c = df.copy()\n",
    "    if periodos == 'h':\n",
    "        df_c[columna_fecha] = df_c[columna_fecha] - pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df_c[columna_fecha] = df_c[columna_fecha] - pd.Timedelta(minutes=minutoffset)\n",
    "\n",
    "    # Establecer la columna de fecha como índice\n",
    "    df_c.set_index(columna_fecha, inplace=True)\n",
    "\n",
    "    # Función para verificar si un día, mes o año tiene suficientes datos\n",
    "    def complet_dia(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_d * porc_min\n",
    "\n",
    "    def complet_mes(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_m * porc_min\n",
    "\n",
    "    def complet_anio(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_a * porc_min\n",
    "\n",
    "    return df_c, complet_dia, complet_mes, complet_anio\n",
    "\n",
    "# Uso funciones de frecuencias\n",
    "df_example = pd.read_csv('../../OE_3_QC_Variables/2_HumedadRelativa/Test_QC/Estacion_0011025501_qc.csv', encoding='latin-1')#, dtype={'Estado_Anterior':str})\n",
    "if 'Estado' in df_example.columns:\n",
    "    df_example = df_example[~df_example['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PSO','0PAT','0PER']]))]\n",
    "    \n",
    "columna_fecha = 'Fecha'\n",
    "freq_csv_path = '../../OE_3_QC_Variables/2_HumedadRelativa/EMAHR_LatLonEntFreq2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74e85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2_22/07/2024, cambio de procesamiento de frecuencias\n",
    "## Derivadas diarias, mensuales y anuales\n",
    "# Humedad relativa del aire a 10 cm media diaria\n",
    "df_example_c = df_example.copy()\n",
    "def HRA2_MEDIA_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "     \n",
    "    # Se filtran los que hayan superaddo las pruebas\n",
    "    #dfC = df[df['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PC']]))]\n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, complet_dia, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_dia is None:\n",
    "        return None\n",
    "\n",
    "    # Se filtran los datos que tienen la complititud mínima\n",
    "    df_filtrado = df_c.groupby([df_c.index.date]).filter(complet_dia) #dfC.groupby([dfC.index.date]).filter(complet_dia)\n",
    "    HR_med_d = df_filtrado[[columna_valor]].resample('D').mean()\n",
    "\n",
    "    return HR_med_d\n",
    "\n",
    "# Ejemplo de uso de la función\n",
    "dfhr_med_d = HRA2_MEDIA_D(df_example_c)\n",
    "\n",
    "# Humedad relativa media mensual\n",
    "def HRA2_MEDIA_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):    \n",
    "    df.reset_index(inplace=True)\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    \n",
    "    # Establecer la columna 'Fecha' como índice\n",
    "    df.set_index(columna_fecha, inplace=True)\n",
    "    \n",
    "    days_in_month = df.index.to_series().dt.days_in_month\n",
    "    days_in_month = days_in_month.resample('ME').first()\n",
    "    \n",
    "    # Función para verificar si una hora específica tiene suficientes datos\n",
    "    def complet_mes(sub_df):\n",
    "        mes = sub_df.index[0].month\n",
    "        total_esperado = days_in_month[days_in_month.index.month == mes].iloc[0]\n",
    "        return len(sub_df) >= total_esperado * porc_min\n",
    "\n",
    "    # Luego de establecer el índice, aplicar resample\n",
    "    df_filtrado = df.groupby([df.index.year, df.index.month]).filter(complet_mes)\n",
    "    HR_med_m = df_filtrado[['Valor']].resample('ME').mean()\n",
    "    \n",
    "    return HR_med_m\n",
    "\n",
    "dfhr_med_m = HRA2_MEDIA_M(dfhr_med_d)\n",
    "\n",
    "# Humedad relativa del Aire a 2 metros media anual\n",
    "def HRA2_MEDIA_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "    df.reset_index(inplace=True)\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    \n",
    "    # Función para verificar si una hora específica tiene suficientes datos\n",
    "    def complet_anio(sub_df):\n",
    "        return len(sub_df) >= 12 * porc_min\n",
    "       \n",
    "    # Antes de resample, establecer la columna 'Fecha' como índice\n",
    "    df.set_index(columna_fecha, inplace=True)\n",
    "\n",
    "    # Luego de establecer el índice, aplicar resample\n",
    "    df_filtrado = df.groupby([df.index.year]).filter(complet_anio)\n",
    "    HR_med_a = df_filtrado[['Valor']].resample('YE').mean()\n",
    "    \n",
    "    return HR_med_a\n",
    "\n",
    "dfhr_med_a = HRA2_MEDIA_A(dfhr_med_m)\n",
    "\n",
    "###-- Derivados máximos y mínimos\n",
    "#Humedad relativa del aire a 10 cm  mínima diaria\n",
    "df_example_c = df_example.copy()\n",
    "def HRA2_MN_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, complet_dia, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_dia is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los días que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    dias_validos = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_dia).index\n",
    "    \n",
    "    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "    dias_validos = pd.to_datetime(dias_validos).normalize()\n",
    "    df_filtrado = df_c[df_c.index.normalize().isin(dias_validos)]\n",
    "    \n",
    "    # Encontrar el valor mínimo por cada día válido\n",
    "    idx_minimos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmin()\n",
    "    mn_d = df_filtrado.loc[idx_minimos_dia]\n",
    "    \n",
    "    # Eliminar la columna temporal antes de retornar el resultado\n",
    "    if 'Fecha_temp' in mn_d.columns:\n",
    "        mn_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "    \n",
    "    return mn_d[[columna_valor]]\n",
    "\n",
    "df_mn_d = HRA2_MN_D(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm  máxima diaria\n",
    "df_example_c = df_example.copy()\n",
    "def HRA2_MX_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, complet_dia, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_dia is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los días que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    dias_validos = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_dia).index\n",
    "    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "    dias_validos = pd.to_datetime(dias_validos).normalize()\n",
    "    df_filtrado = df_c[df_c.index.normalize().isin(dias_validos)]\n",
    "    # Encontrar el valor mínimo por cada día válido\n",
    "    idx_maximos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmax()\n",
    "    mx_d = df_filtrado.loc[idx_maximos_dia]\n",
    "    \n",
    "    # Eliminar la columna temporal antes de retornar el resultado\n",
    "    if 'Fecha_temp' in mx_d.columns:\n",
    "        mx_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "    \n",
    "    return mx_d[[columna_valor]]\n",
    "\n",
    "df_mx_d = HRA2_MX_D(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm  mínima mensual\n",
    "df_example_c = df_example.copy()\n",
    "def HRA2_MN_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, _, complet_mes, _ = process_frequencies(df, columna_fecha, freq_csv_path,porc_min)\n",
    "\n",
    "    if df_c is None or complet_mes is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los meses que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    # Eliminar duplicados en el índice\n",
    "    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "    meses_validos = df_c.groupby(df_c.index.to_period('M')).filter(complet_mes).index.to_period('M')\n",
    "\n",
    "    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "    df_filtrado = df_c[df_c.index.to_period('M').isin(meses_validos)]\n",
    "\n",
    "    # Encontrar el valor mínimo por cada mes válido\n",
    "    idx_minimos_mes = df_filtrado.groupby(df_filtrado.index.to_period('M'))[columna_valor].idxmin()\n",
    "    min_m = df_filtrado.loc[idx_minimos_mes]\n",
    "\n",
    "    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "    if 'Fecha_temp' in min_m.columns:\n",
    "        min_m.drop(columns=['Fecha_temp'], inplace=True)\n",
    "\n",
    "    return min_m[[columna_valor]]\n",
    "    \n",
    "df_mn_m = HRA2_MN_M(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm  máxima mensual\n",
    "df_example_c = df_example.copy()\n",
    "def HRA2_MX_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    \n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, _, complet_mes, _ = process_frequencies(df, columna_fecha, freq_csv_path,porc_min)\n",
    "\n",
    "    if df_c is None or complet_mes is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los meses que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    # Eliminar duplicados en el índice\n",
    "    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "    meses_validos = df_c.groupby(df_c.index.to_period('M')).filter(complet_mes).index.to_period('M')\n",
    "\n",
    "    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "    df_filtrado = df_c[df_c.index.to_period('M').isin(meses_validos)]\n",
    "\n",
    "    # Encontrar el valor mínimo por cada mes válido\n",
    "    idx_maximos_mes = df_filtrado.groupby(df_filtrado.index.to_period('M'))[columna_valor].idxmax()\n",
    "    max_m = df_filtrado.loc[idx_maximos_mes]\n",
    "\n",
    "    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "    if 'Fecha_temp' in max_m.columns:\n",
    "        max_m.drop(columns=['Fecha_temp'], inplace=True)\n",
    "\n",
    "    return max_m[[columna_valor]]\n",
    "    \n",
    "df_mx_m = HRA2_MX_M(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm mínima anual\n",
    "df_example_c = df_example.copy()\n",
    "def HRA2_MN_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, _, _, complet_anio = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_anio is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los meses que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    # Eliminar duplicados en el índice\n",
    "    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "    anios_validos = df_c.groupby(df_c.index.to_period('A')).filter(complet_anio).index.to_period('A')\n",
    "\n",
    "    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "    df_filtrado = df_c[df_c.index.to_period('A').isin(anios_validos)]\n",
    "\n",
    "    # Encontrar el valor mínimo por cada mes válido\n",
    "    idx_minimos_anio = df_filtrado.groupby(df_filtrado.index.to_period('A'))[columna_valor].idxmin()\n",
    "    min_a = df_filtrado.loc[idx_minimos_anio]\n",
    "\n",
    "    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "    if 'Fecha_temp' in min_a.columns:\n",
    "        min_a.drop(columns=['Fecha_temp'], inplace=True)\n",
    "\n",
    "    return min_a[[columna_valor]]\n",
    "    \n",
    "df_mn_a = HRA2_MN_A(df_example_c)\n",
    "\n",
    "# Humedad relativa del aire a 10 cm  máxima anual\n",
    "df_example_c = df_example.copy()\n",
    "def HRA2_MX_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Se llama la función de procesamiento de frecuencias\n",
    "    df_c, _, _, complet_anio = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "    if df_c is None or complet_anio is None:\n",
    "        return None\n",
    "\n",
    "    # Filtrar los meses que tienen suficientes datos\n",
    "    df_c['Fecha_temp'] = df_c.index\n",
    "    # Eliminar duplicados en el índice\n",
    "    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "    anios_validos = df_c.groupby(df_c.index.to_period('A')).filter(complet_anio).index.to_period('A')\n",
    "\n",
    "    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "    df_filtrado = df_c[df_c.index.to_period('A').isin(anios_validos)]\n",
    "\n",
    "    # Encontrar el valor mínimo por cada mes válido\n",
    "    idx_minimos_anio = df_filtrado.groupby(df_filtrado.index.to_period('A'))[columna_valor].idxmax()\n",
    "    max_a = df_filtrado.loc[idx_minimos_anio]\n",
    "\n",
    "    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "    if 'Fecha_temp' in max_a.columns:\n",
    "        max_a.drop(columns=['Fecha_temp'], inplace=True)\n",
    "\n",
    "    return max_a[[columna_valor]]\n",
    "    \n",
    "df_mx_a = HRA2_MN_A(df_example_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d69c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Gráficas y export en excel\n",
    "# Se crea un nuevo archivo Excel con openpyxl\n",
    "wb = Workbook()\n",
    "sheets = {\n",
    "    'HRA2_MEDIA_D': dfhr_med_d, 'HRA2_MEDIA_M': dfhr_med_m,\n",
    "    'HRA2_MEDIA_A': dfhr_med_a, 'HRA2_MN_D': df_mn_d,\n",
    "    'HRA2_MX_D': df_mx_d, 'HRA2_MN_M': df_mn_m,\n",
    "    'HRA2_MX_M': df_mx_m, 'HRA2_MN_A': df_mn_a,\n",
    "    'HRA2_MX_A': df_mx_a \n",
    "}\n",
    "\n",
    "# Si el workbook todavía tiene la hoja por defecto, se elimina\n",
    "if \"Sheet\" in wb.sheetnames:\n",
    "    del wb[\"Sheet\"]\n",
    "\n",
    "for sheet_name, data in sheets.items():\n",
    "    ws = wb.create_sheet(title=sheet_name)\n",
    "    \n",
    "    # Agregamos los datos al Excel\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(data, index=True, header=True), 1):\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "    \n",
    "    # Crear una gráfica\n",
    "    chart = LineChart()\n",
    "    chart.title = sheet_name\n",
    "    chart.style = 5\n",
    "    chart.y_axis.title = 'Humedad relativa (%)'\n",
    "    chart.x_axis.title = 'Fecha'\n",
    "    \n",
    "    # Establecer datos para la gráfica\n",
    "    max_row = ws.max_row\n",
    "    values = Reference(ws, min_col=2, min_row=2, max_col=2, max_row=max_row)\n",
    "    dates = Reference(ws, min_col=1, min_row=3, max_col=1, max_row=max_row)\n",
    "    chart.add_data(values, titles_from_data=True)\n",
    "    chart.set_categories(dates)\n",
    "    \n",
    "    # Quitar la leyenda\n",
    "    chart.legend = None\n",
    "        \n",
    "    # Posicionar la gráfica en el Excel\n",
    "    ws.add_chart(chart, \"E3\")\n",
    "\n",
    "# Guardar el archivo Excel\n",
    "wb.save(\"Agreg_graf_HRA2_AUT_60_5min_cohr5vals.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4c130",
   "metadata": {},
   "source": [
    "## Función para cálculo masivo de derivadas y generación de gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfd6f3d-f60d-4d27-b653-7eb769b203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar frecuencias\n",
    "def process_frequencies(df, columna_fecha, freq_csv_path, porc_min=0.67):\n",
    "    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "        \n",
    "    # Cargar el archivo de frecuencias\n",
    "    freqinst200b = pd.read_csv(freq_csv_path, encoding='latin-1', sep=';')\n",
    "\n",
    "    # Definir el diccionario de frecuencias y cantidades esperadas\n",
    "    frecuencias = {\n",
    "        'min': {'cant_esperd_h': 60, 'cant_esperd_d': 1440, 'cant_esperd_m': 43200, 'cant_esperd_a': 518400, 'minutos': 1},\n",
    "        '5min': {'cant_esperd_h': 12, 'cant_esperd_d': 288, 'cant_esperd_m': 8640, 'cant_esperd_a': 103680, 'minutos': 5},\n",
    "        '10min': {'cant_esperd_h': 6, 'cant_esperd_d': 144, 'cant_esperd_m': 4320, 'cant_esperd_a': 51840, 'minutos': 10},\n",
    "        'h': {'cant_esperd_h': 1, 'cant_esperd_d': 24, 'cant_esperd_m': 720, 'cant_esperd_a': 8640}\n",
    "    }\n",
    "\n",
    "    # Obtener el valor de la estación\n",
    "    station_value = df['station'].values[0] #Station\n",
    "    freqinst200b_station = freqinst200b.loc[freqinst200b['station'] == station_value] #Station\n",
    "    periodos = freqinst200b_station['FreqInf'].values[0]\n",
    "\n",
    "    if pd.isna(periodos):\n",
    "        try:\n",
    "            periodos = pd.infer_freq(df[columna_fecha][-25:])\n",
    "            print(periodos)\n",
    "            if periodos is None:\n",
    "                project_value = freqinst100b_station['Instituc'].values[0]\n",
    "                periodos = {'CENICAFE': '5min', 'IDEAM': '10min', 'CAR': 'h', 'IDIGER': 'min'}.get(project_value, 'min')\n",
    "                print(f\"Frecuencia inferida para {df['Station']} es None. Se determina según entidad {project_value}\")\n",
    "                \n",
    "                #return None, None, None, None, None, None\n",
    "        except ValueError as e:\n",
    "            print(f'Error al inferir la frecuencia en el archivo {df}: {str(e)}')\n",
    "            return None, None, None, None, None, None\n",
    "\n",
    "    # Obtener las cantidades esperadas y el offset en minutos\n",
    "    cant_esperd_h = frecuencias[periodos]['cant_esperd_h']\n",
    "    cant_esperd_d = frecuencias[periodos]['cant_esperd_d']\n",
    "    cant_esperd_m = frecuencias[periodos]['cant_esperd_m']\n",
    "    cant_esperd_a = frecuencias[periodos]['cant_esperd_a']\n",
    "    if periodos == 'h':\n",
    "        pass\n",
    "    else:\n",
    "        minutoffset = frecuencias[periodos]['minutos']\n",
    "\n",
    "    # Ajustar la hora de cada registro\n",
    "    df_c = df.copy()\n",
    "    if periodos == 'h':\n",
    "        df_c[columna_fecha] = df_c[columna_fecha] - pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df_c[columna_fecha] = df_c[columna_fecha] - pd.Timedelta(minutes=minutoffset)\n",
    "\n",
    "    # Establecer la columna de fecha como índice\n",
    "    df_c.set_index(columna_fecha, inplace=True)\n",
    "\n",
    "    # Función para verificar si un día, mes o año tiene suficientes datos\n",
    "    def complet_hora(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_h * porc_min\n",
    "    \n",
    "    def complet_dia(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_d * porc_min\n",
    "\n",
    "    def complet_mes(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_m * porc_min\n",
    "\n",
    "    def complet_anio(sub_df):\n",
    "        return len(sub_df) >= cant_esperd_a * porc_min\n",
    "\n",
    "    return df_c, periodos, complet_hora, complet_dia, complet_mes, complet_anio\n",
    "\n",
    "# # Uso funciones de frecuencias\n",
    "# df_example = pd.read_csv('../../OE_3_QC_Variables/2_HumedadRelativa/Test_QC/Estacion_0011115501.csv', encoding='latin-1')#, dtype={'Estado_Anterior':str})\n",
    "# if 'Estado' in df_example.columns:\n",
    "#     df_example = df_example[df_example['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PC']]))]    \n",
    "columna_fecha = 'event_value' #Fecha\n",
    "freq_csv_path = '../../OE_3_QC_Variables/2_HumedadRelativa/EMAHR_Allinfo_Replcble1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb23a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cálculo de derivadas de varios archivos en una sola carpeta\n",
    "def calc_deriv_HR(carpeta, chunk_size=540000):\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Se recorre cada archivo en la carpeta\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(carpeta, archivo)\n",
    "        \n",
    "            # Se procesan los archivos csv por fragmentos\n",
    "            reader = pd.read_csv(ruta_archivo, encoding='latin-1', chunksize=chunk_size)\n",
    "            \n",
    "            for chunk in reader:\n",
    "                # Se generan dataframes analizados\n",
    "                # De cada chunk se transforma a datetime la serie/columna 'Fecha'\n",
    "                try:\n",
    "                    chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                except ValueError:\n",
    "                    chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    try:\n",
    "                        dfC = chunk[~chunk['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PSO0','0PAT','0PER']]))]\n",
    "                        dfC_c = dfC.copy()\n",
    "                        station_value = dfC_c['station'].values[0]\n",
    "                    except IndexError:\n",
    "                        print(f\"Error en el archivo {archivo}: dfC está vacío. Saltando al siguiente archivo.\")\n",
    "                        continue  # Sale del bucle de chunks y continúa con el siguiente archivo\n",
    "                else:\n",
    "                    chunk_c = chunk.copy()\n",
    "                    station_value = chunk_c['station'].values[0]\n",
    "\n",
    "                # Humedad relativa media horaria\n",
    "                def HRA2_MEDIA_H(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):  \n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                        \n",
    "                    # Se filtran los que hayan superaddo las pruebas\n",
    "                    df_c, periodos, complet_hora, _, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "                    #if periodos == 'h':\n",
    "                        # Si la frecuencia es horaria, retornar el DataFrame tal como está\n",
    "                        #return df_c[[columna_valor]]\n",
    "                    \n",
    "                    # Si es una frecuencia diferente a la horaria, se pueden seleccionar los minutos debidos para el offset\n",
    "                    #minutoffset = frecuencias[periodos]['minutos']\n",
    "                \n",
    "                    # Función para verificar si una hora específica tiene suficientes datos\n",
    "                    #def complet_hora(sub_df, total_esperado=cant_esperd_h, porc_min=porc_min):\n",
    "                        #return len(sub_df) >= total_esperado * porc_min\n",
    "                    \n",
    "                    # Ajustar la hora de cada registro para que corresponda al rango deseado\n",
    "                    #df_ajustado = df.copy() #df.copy()\n",
    "                    #df_ajustado[columna_fecha] = df_ajustado[columna_fecha] - pd.Timedelta(minutes=minutoffset)\n",
    "                    \n",
    "                    # Antes de resample, establecer la columna 'Fecha' como índice\n",
    "                    #df_ajustado.set_index(columna_fecha, inplace=True)\n",
    "                \n",
    "                    # Luego de establecer el índice, aplicar resample\n",
    "                    df_filtrado = df_c.groupby([df_c.index.date, df_c.index.hour]).filter(complet_hora)\n",
    "                    hr10_med_h = df_filtrado[['Valor']].resample('h').mean()\n",
    "                \n",
    "                    return hr10_med_h[['Valor']]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    dfhr_med_h = HRA2_MEDIA_H(dfC_c)\n",
    "                else:\n",
    "                    dfhr_med_h = HRA2_MEDIA_H(chunk_c)\n",
    "                \n",
    "                ## Derivadas diarias, mensuales y anuales\n",
    "                # Humedad relativa del aire a 10 cm media diaria\n",
    "                def HRA2_MEDIA_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    df.reset_index(inplace=True)\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    \n",
    "                    # Cantidad esperada por día\n",
    "                    cant_esperd_d = 24\n",
    "                    # Función para verificar si una hora específica tiene suficientes datos\n",
    "                    def complet_dia(sub_df, total_esperado=cant_esperd_d, porc_min=porc_min):\n",
    "                        return len(sub_df) >= total_esperado * porc_min\n",
    "                    \n",
    "                    df.set_index('Fecha', inplace=True)\n",
    "                    # Se filtran los datos que tienen la complititud mínima\n",
    "                    df_filtrado = df.groupby([df.index.date]).filter(complet_dia) #dfC.groupby([dfC.index.date]).filter(complet_dia)\n",
    "                    HR_med_d = df_filtrado[[columna_valor]].resample('D').mean()\n",
    "                \n",
    "                    return HR_med_d\n",
    "                \n",
    "                dfhr_med_d = HRA2_MEDIA_D(dfhr_med_h)                \n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                #if 'Estado' in chunk.columns:\n",
    "                #    dfhr_med_d = HRA2_MEDIA_D(dfC_c)\n",
    "                #else:\n",
    "                #    dfhr_med_d = HRA2_MEDIA_D(chunk_c)\n",
    "                \n",
    "                # Humedad relativa media mensual\n",
    "                def HRA2_MEDIA_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):    \n",
    "                    if df is None:\n",
    "                        return None                  \n",
    "                    days_in_month = df.index.to_series().dt.days_in_month\n",
    "                    days_in_month = days_in_month.resample('ME').first()\n",
    "                    \n",
    "                    # Función para verificar si una hora específica tiene suficientes datos\n",
    "                    def complet_mes(sub_df):\n",
    "                        mes = sub_df.index[0].month\n",
    "                        total_esperado = days_in_month[days_in_month.index.month == mes].iloc[0]\n",
    "                        return len(sub_df) >= total_esperado * porc_min\n",
    "                \n",
    "                    # Luego de establecer el índice, aplicar resample\n",
    "                    df_filtrado = df.groupby([df.index.year, df.index.month]).filter(complet_mes)\n",
    "                    HR_med_m = df_filtrado[['Valor']].resample('ME').mean()\n",
    "                    \n",
    "                    return HR_med_m\n",
    "                \n",
    "                dfhr_med_m = HRA2_MEDIA_M(dfhr_med_d)\n",
    "                \n",
    "                # Humedad relativa del Aire a 2 metros media anual\n",
    "                def HRA2_MEDIA_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    if df is None:\n",
    "                        return None\n",
    "                    \n",
    "                    # Función para verificar si una hora específica tiene suficientes datos\n",
    "                    def complet_anio(sub_df):\n",
    "                        return len(sub_df) >= 12 * porc_min\n",
    "                \n",
    "                    # Luego de establecer el índice, aplicar resample\n",
    "                    df_filtrado = df.groupby([df.index.year]).filter(complet_anio)\n",
    "                    HR_med_a = df_filtrado[['Valor']].resample('YE').mean()\n",
    "                    \n",
    "                    return HR_med_a\n",
    "                \n",
    "                dfhr_med_a = HRA2_MEDIA_A(dfhr_med_m)\n",
    "                \n",
    "                ###-- Derivados máximos y mínimos\n",
    "                #Humedad relativa del aire a 10 cm  mínima diaria\n",
    "                def HRA2_MN_H(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo, complet_hora, _, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_hora is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los días que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    horas_validas = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_hora).index\n",
    "                    \n",
    "                    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "                    horas_validas = pd.to_datetime(horas_validas).normalize()\n",
    "                    df_filtrado = df_c[df_c.index.normalize().isin(horas_validas)]\n",
    "                    \n",
    "                    # Encontrar el valor mínimo por cada día válido\n",
    "                    idx_minimos_hora = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmin()\n",
    "                    mn_d = df_filtrado.loc[idx_minimos_hora]\n",
    "                    \n",
    "                    # Eliminar la columna temporal antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in mn_d.columns:\n",
    "                        mn_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                    \n",
    "                    return mn_d[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_h = HRA2_MN_H(dfC_c)\n",
    "                else:\n",
    "                    df_mn_h = HRA2_MN_H(chunk_c)\n",
    "                    \n",
    "                #Humedad relativa del aire a 10 cm  mínima diaria\n",
    "                def HRA2_MX_H(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo, complet_hora, _, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_hora is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los días que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    horas_validas = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_hora).index\n",
    "                    \n",
    "                    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "                    horas_validas = pd.to_datetime(horas_validas).normalize()\n",
    "                    df_filtrado = df_c[df_c.index.normalize().isin(horas_validas)]\n",
    "                    \n",
    "                    # Encontrar el valor mínimo por cada día válido\n",
    "                    idx_minimos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmin()\n",
    "                    mn_d = df_filtrado.loc[idx_minimos_dia]\n",
    "                    \n",
    "                    # Eliminar la columna temporal antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in mn_d.columns:\n",
    "                        mn_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                    \n",
    "                    return mn_d[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_h = HRA2_MN_H(dfC_c)\n",
    "                else:\n",
    "                    df_mn_h = HRA2_MN_H(chunk_c)\n",
    "                \n",
    "                def HRA2_MN_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,complet_dia, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_dia is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los días que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    dias_validos = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_dia).index\n",
    "                    \n",
    "                    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "                    dias_validos = pd.to_datetime(dias_validos).normalize()\n",
    "                    df_filtrado = df_c[df_c.index.normalize().isin(dias_validos)]\n",
    "                    \n",
    "                    # Encontrar el valor mínimo por cada día válido\n",
    "                    idx_minimos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmin()\n",
    "                    mn_d = df_filtrado.loc[idx_minimos_dia]\n",
    "                    \n",
    "                    # Eliminar la columna temporal antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in mn_d.columns:\n",
    "                        mn_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                    \n",
    "                    return mn_d[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_d = HRA2_MN_D(dfC_c)\n",
    "                else:\n",
    "                    df_mn_d = HRA2_MN_D(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm  máxima diaria\n",
    "                def HRA2_MX_D(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,complet_dia,_,_ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_dia is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los días que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    dias_validos = df_c.groupby(df_c['Fecha_temp'].dt.date).filter(complet_dia).index\n",
    "                    # Filtrar el DataFrame original para incluir solo los días válidos\n",
    "                    dias_validos = pd.to_datetime(dias_validos).normalize()\n",
    "                    df_filtrado = df_c[df_c.index.normalize().isin(dias_validos)]\n",
    "                    # Encontrar el valor mínimo por cada día válido\n",
    "                    idx_maximos_dia = df_filtrado.groupby(df_filtrado.index.to_series().dt.date)[columna_valor].idxmax()\n",
    "                    mx_d = df_filtrado.loc[idx_maximos_dia]\n",
    "                    \n",
    "                    # Eliminar la columna temporal antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in mx_d.columns:\n",
    "                        mx_d.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                    \n",
    "                    return mx_d[[columna_valor]]\n",
    "                \n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mx_d = HRA2_MX_D(dfC_c)\n",
    "                else:\n",
    "                    df_mx_d = HRA2_MX_D(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm  mínima mensual\n",
    "                def HRA2_MN_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,_,complet_mes,_ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_mes is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los meses que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    # Eliminar duplicados en el índice\n",
    "                    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "                    meses_validos = df_c.groupby(df_c.index.to_period('M')).filter(complet_mes).index.to_period('M')\n",
    "                \n",
    "                    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "                    df_filtrado = df_c[df_c.index.to_period('M').isin(meses_validos)]\n",
    "                \n",
    "                    # Encontrar el valor mínimo por cada mes válido\n",
    "                    idx_minimos_mes = df_filtrado.groupby(df_filtrado.index.to_period('M'))[columna_valor].idxmin()\n",
    "                    min_m = df_filtrado.loc[idx_minimos_mes]\n",
    "                \n",
    "                    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in min_m.columns:\n",
    "                        min_m.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                \n",
    "                    return min_m[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_m = HRA2_MN_M(dfC_c)\n",
    "                else:\n",
    "                    df_mn_m = HRA2_MN_M(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm  máxima mensual\n",
    "                def HRA2_MX_M(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,_,complet_mes,_ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_mes is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los meses que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    # Eliminar duplicados en el índice\n",
    "                    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "                    meses_validos = df_c.groupby(df_c.index.to_period('M')).filter(complet_mes).index.to_period('M')\n",
    "                \n",
    "                    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "                    df_filtrado = df_c[df_c.index.to_period('M').isin(meses_validos)]\n",
    "                \n",
    "                    # Encontrar el valor mínimo por cada mes válido\n",
    "                    idx_maximos_mes = df_filtrado.groupby(df_filtrado.index.to_period('M'))[columna_valor].idxmax()\n",
    "                    max_m = df_filtrado.loc[idx_maximos_mes]\n",
    "                \n",
    "                    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in max_m.columns:\n",
    "                        max_m.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                \n",
    "                    return max_m[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mx_m = HRA2_MX_M(dfC_c)\n",
    "                else:\n",
    "                    df_mx_m = HRA2_MX_M(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm mínima anual\n",
    "                def HRA2_MN_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,_,_,complet_anio = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_anio is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los meses que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    # Eliminar duplicados en el índice\n",
    "                    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "                    anios_validos = df_c.groupby(df_c.index.to_period('Y')).filter(complet_anio).index.to_period('Y')\n",
    "                \n",
    "                    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "                    df_filtrado = df_c[df_c.index.to_period('Y').isin(anios_validos)]\n",
    "                \n",
    "                    # Encontrar el valor mínimo por cada mes válido\n",
    "                    idx_minimos_anio = df_filtrado.groupby(df_filtrado.index.to_period('Y'))[columna_valor].idxmin()\n",
    "                    min_a = df_filtrado.loc[idx_minimos_anio]\n",
    "                \n",
    "                    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in min_a.columns:\n",
    "                        min_a.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                \n",
    "                    return min_a[[columna_valor]]\n",
    "\n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mn_a = HRA2_MN_A(dfC_c)\n",
    "                else:\n",
    "                    df_mn_a = HRA2_MN_A(chunk_c)\n",
    "                \n",
    "                # Humedad relativa del aire a 10 cm  máxima anual\n",
    "                def HRA2_MX_A(df, columna_fecha='Fecha', columna_valor='Valor', porc_min=0.67):\n",
    "                    # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                        df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    # Se llama la función de procesamiento de frecuencias\n",
    "                    df_c, periodo,_,_,_,complet_anio = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "                \n",
    "                    if df_c is None or complet_anio is None:\n",
    "                        return None\n",
    "                \n",
    "                    # Filtrar los meses que tienen suficientes datos\n",
    "                    df_c['Fecha_temp'] = df_c.index\n",
    "                    # Eliminar duplicados en el índice\n",
    "                    df_c = df_c[~df_c.index.duplicated(keep='first')]\n",
    "                    anios_validos = df_c.groupby(df_c.index.to_period('Y')).filter(complet_anio).index.to_period('Y')\n",
    "                \n",
    "                    # Filtrar el DataFrame original para incluir solo los meses válidos\n",
    "                    df_filtrado = df_c[df_c.index.to_period('Y').isin(anios_validos)]\n",
    "                \n",
    "                    # Encontrar el valor mínimo por cada mes válido\n",
    "                    idx_minimos_anio = df_filtrado.groupby(df_filtrado.index.to_period('Y'))[columna_valor].idxmax()\n",
    "                    max_a = df_filtrado.loc[idx_minimos_anio]\n",
    "                \n",
    "                    # Eliminar las columnas temporales antes de retornar el resultado\n",
    "                    if 'Fecha_temp' in max_a.columns:\n",
    "                        max_a.drop(columns=['Fecha_temp'], inplace=True)\n",
    "                \n",
    "                    return max_a[[columna_valor]]\n",
    "                    \n",
    "                # Se llama el archivo original según si es dato crudo o con qc\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    df_mx_a = HRA2_MN_A(dfC_c)\n",
    "                else:\n",
    "                    df_mx_a = HRA2_MN_A(chunk_c)\n",
    "        \n",
    "                ### Se crea un nuevo archivo Excel con openpyxl\n",
    "                wb = Workbook()\n",
    "                sheets = {\n",
    "                    'HRA2_MEDIA_H': dfhr_med_h, 'HRA2_MEDIA_D': dfhr_med_d,\n",
    "                    'HRA2_MEDIA_M': dfhr_med_m, 'HRA2_MEDIA_A': dfhr_med_a, \n",
    "                    'HRA2_MN_H': df_mn_h,\n",
    "                    'HRA2_MN_D': df_mn_d,'HRA2_MX_D': df_mx_d, \n",
    "                    'HRA2_MN_M': df_mn_m,'HRA2_MX_M': df_mx_m, \n",
    "                    'HRA2_MN_A': df_mn_a,'HRA2_MX_A': df_mx_a \n",
    "                }\n",
    "                \n",
    "                # Si el workbook todavía tiene la hoja por defecto, se elimina\n",
    "                if \"Sheet\" in wb.sheetnames:\n",
    "                    del wb[\"Sheet\"]\n",
    "                \n",
    "                for sheet_name, data in sheets.items():\n",
    "                    ws = wb.create_sheet(title=sheet_name)\n",
    "                    \n",
    "                    # Agregamos los datos al Excel\n",
    "                    if data is None:\n",
    "                        pass\n",
    "                    else:\n",
    "                        for r_idx, row in enumerate(dataframe_to_rows(data, index=True, header=True), 1):\n",
    "                            for c_idx, value in enumerate(row, 1):\n",
    "                                ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "                    \n",
    "                    # Crear una gráfica\n",
    "                    chart = LineChart()\n",
    "                    chart.title = sheet_name\n",
    "                    chart.style = 5\n",
    "                    chart.y_axis.title = 'Humedad relativa (%)'\n",
    "                    chart.x_axis.title = 'Fecha'\n",
    "                    \n",
    "                    # Establecer datos para la gráfica\n",
    "                    max_row = ws.max_row\n",
    "                    values = Reference(ws, min_col=2, min_row=2, max_col=2, max_row=max_row)\n",
    "                    dates = Reference(ws, min_col=1, min_row=3, max_col=1, max_row=max_row)\n",
    "                    chart.add_data(values, titles_from_data=True)\n",
    "                    chart.set_categories(dates)\n",
    "                    \n",
    "                    # Quitar la leyenda\n",
    "                    chart.legend = None\n",
    "                    \n",
    "                    # Cambiar el grosor de la línea a 0.5 puntos (equivalente a 50 centésimas de punto)\n",
    "                    for series in chart.series:\n",
    "                        series.graphicalProperties.line.width = 50\n",
    "                        \n",
    "                    # Posicionar la gráfica en el Excel\n",
    "                    ws.add_chart(chart, \"E3\")\n",
    "                \n",
    "                # Nombres archivos\n",
    "                if 'Estado' in chunk.columns:\n",
    "                    nombre_archivo_salida = os.path.join(carpeta, archivo[:22] + '_deriv.xlsx')\n",
    "                else:\n",
    "                    nombre_archivo_salida = os.path.join(carpeta, archivo[:19] + '_deriv.xlsx')\n",
    "                #nombre_archivo_salida = os.path.join(carpeta, archivo[:22] + '_deriv.xlsx') #archivo[:19] el original #archivo[:22] con qc\n",
    "                \n",
    "                # Guardar el archivo Excel\n",
    "                wb.save(nombre_archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0262efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_deriv_HR('../../OE_3_QC_Variables/2_HumedadRelativa/QCResult_HR')\n",
    "#calc_deriv_HR(r'C:\\Users\\palvarez\\Downloads\\2023-12_a_2024-12_0027')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df022d20-772d-4041-a291-da25abf644e6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0bb96-7e66-4509-90a3-e1a97bf517ec",
   "metadata": {},
   "source": [
    "## Función cálculo masivo de derivadas y alistamiento Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac274a3-3b32-403e-a606-0004f3c97c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_deriv_HRA2_QC(carpeta):#, chunk_size=540000):\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Se crean carpetas para cada tipo de DataFrame si no existen\n",
    "    carpetas_salidas = ['HRA2_MEDIA_H_QC', 'HRA2_MEDIA_D_QC', 'HRA2_MEDIA_M_QC', 'HRA2_MEDIA_A_QC']#,\n",
    "                        #'HRA2_MN_H_QC', 'HRA2_MX_H_QC', 'HRA2_MN_D_QC', 'HRA2_MX_D_QC',\n",
    "                        #'HRA2_MN_M_QC', 'HRA2_MX_M_QC', 'HRA2_MN_A_QC', 'HRA2_MX_A_QC']\n",
    "\n",
    "    for cs in carpetas_salidas:\n",
    "        os.makedirs(os.path.join(carpeta, cs), exist_ok=True)\n",
    "    \n",
    "    # Procesar cada archivo en la carpeta\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(carpeta, archivo)\n",
    "            df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
    "\n",
    "            # Procesar la fecha y filtrar según estado, como en el ejemplo original\n",
    "            try:\n",
    "                df['event_time'] = pd.to_datetime(df['event_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "            except ValueError:\n",
    "                df['event_time'] = pd.to_datetime(df['event_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "                  \n",
    "            try:\n",
    "                dfC = df[df['state'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PC']]))] # Se comenta si es de crudos\n",
    "                station_value = dfC['station'].values[0] #df['station'].values[0]\n",
    "            except IndexError:\n",
    "                print(f\"Error en el archivo {archivo}: dfC está vacío. Saltando al siguiente archivo.\")\n",
    "                continue  # Sale del bucle de chunks y continúa con el siguiente archivo\n",
    "\n",
    "            # Humedad relativa media horaria\n",
    "            def HRA2_MEDIA_H_QC(df, columna_fecha='event_time', columna_valor='event_value', porc_min=0.67):  \n",
    "                # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                    \n",
    "                # Se filtran los que hayan superaddo las pruebas\n",
    "                df_c, periodos, complet_hora, _, _, _ = process_frequencies(df, columna_fecha, freq_csv_path, porc_min)\n",
    "\n",
    "                # Luego de establecer el índice, aplicar resample\n",
    "                df_filtrado = df_c.groupby([df_c.index.date, df_c.index.hour]).filter(complet_hora)\n",
    "                HRA2_60_med_h = df_filtrado[['event_value']].resample('h').mean()\n",
    "\n",
    "                # Cambio de contenido de columnas\n",
    "                HRA2_60_med_h['station'] = df['station'].iloc[0]\n",
    "                HRA2_60_med_h['station'] = HRA2_60_med_h['station'].astype('int64')\n",
    "                HRA2_60_med_h['label'] = 'HRA2_MEDIA_H_QC'\n",
    "                \n",
    "                # Reset index\n",
    "                HRA2_60_med_h.reset_index(inplace=True)\n",
    "                \n",
    "                # Se reordenan las columnas\n",
    "                nuevo_orden = ['station', 'label', 'event_time', 'event_value']\n",
    "                # Reordenar las columnas usando el nuevo orden\n",
    "                HRA2_60_med_h = HRA2_60_med_h[nuevo_orden]\n",
    "            \n",
    "                # Convertir 'event_time' de nuevo a datetime para uniformidad\n",
    "                HRA2_60_med_h['event_time'] = pd.to_datetime(HRA2_60_med_h['event_time'])\n",
    "            \n",
    "                return HRA2_60_med_h\n",
    "\n",
    "            dfhra2_med_h = HRA2_MEDIA_H_QC(dfC)\n",
    "            \n",
    "            # Humedad relativa media diaria\n",
    "            def HRA2_MEDIA_D_QC(df, columna_fecha='event_time', columna_valor='event_value', porc_min=0.67):\n",
    "                if df.empty:\n",
    "                    return df\n",
    "                df.reset_index(inplace=True)\n",
    "                # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                # Ajustar la hora de cada registro para que corresponda al rango deseado\n",
    "                df[columna_fecha] = df[columna_fecha] - pd.Timedelta(hours=1)\n",
    "                # Establecer la columna de fecha como índice\n",
    "                df.set_index(columna_fecha, inplace=True)\n",
    "                \n",
    "                # Calcular el total de registros esperados por día pluviométrico\n",
    "                total_esperado_por_dia = 24\n",
    "                # Función para verificar si un día pluviométrico tiene suficientes datos\n",
    "                def complet_dia(sub_df):\n",
    "                    return len(sub_df) >= total_esperado_por_dia * porc_min\n",
    "            \n",
    "                # Filtrar los días con suficientes datos y calcular el promedio diario\n",
    "                df_filtrado = df.groupby([df.index.date]).filter(complet_dia)\n",
    "                # Verificar si el DataFrame filtrado está vacío\n",
    "                if df_filtrado.empty:\n",
    "                    print(f\"DataFrame vacío después de filtrar por días válidos. Regresando {archivo[:19]} vacío.\")\n",
    "                    return df_filtrado\n",
    "                    \n",
    "                # Se calcula la media\n",
    "                HRA2_60_med_d = df_filtrado[[columna_valor]].resample('D').mean()\n",
    "\n",
    "                # Cambio de contenido de columnas\n",
    "                HRA2_60_med_d['station'] = df['station'].iloc[0]\n",
    "                HRA2_60_med_d['station'] = HRA2_60_med_d['station'].astype('int64')\n",
    "                HRA2_60_med_d['label'] = 'HRA2_MEDIA_D_QC'\n",
    "                \n",
    "                # Reset index\n",
    "                HRA2_60_med_d.reset_index(inplace=True)\n",
    "                \n",
    "                # Se reordenan las columnas\n",
    "                nuevo_orden = ['station', 'label', 'event_time', 'event_value']\n",
    "                # Reordenar las columnas usando el nuevo orden\n",
    "                HRA2_60_med_d = HRA2_60_med_d[nuevo_orden]\n",
    "            \n",
    "                # Convertir 'event_time' de nuevo a datetime para uniformidad\n",
    "                HRA2_60_med_d['event_time'] = pd.to_datetime(HRA2_60_med_d['event_time'])\n",
    "            \n",
    "                return HRA2_60_med_d\n",
    "\n",
    "            dfhra2_med_d = HRA2_MEDIA_D_QC(dfhra2_med_h)\n",
    "            \n",
    "            # Humedad relativa media mensual\n",
    "            dfhra2_med_d_c = dfhra2_med_d.copy()\n",
    "            def HRA2_MEDIA_M_QC(df, columna_fecha='event_time', columna_valor='event_value', porc_min=0.67):    \n",
    "                if df.empty:\n",
    "                    return df\n",
    "                df.reset_index(inplace=True)\n",
    "                # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                \n",
    "                # Establecer la columna 'event_time' como índice\n",
    "                df.set_index(columna_fecha, inplace=True)\n",
    "                \n",
    "                days_in_month = df.index.to_series().dt.days_in_month\n",
    "                days_in_month = days_in_month.resample('ME').first()\n",
    "                \n",
    "                # Función para verificar si una hora específica tiene suficientes datos\n",
    "                def complet_mes(sub_df):\n",
    "                    mes = sub_df.index[0].month\n",
    "                    total_esperado = days_in_month[days_in_month.index.month == mes].iloc[0]\n",
    "                    return len(sub_df) >= total_esperado * porc_min\n",
    "            \n",
    "                # Luego de establecer el índice, aplicar resample\n",
    "                df_filtrado = df.groupby([df.index.year, df.index.month]).filter(complet_mes)\n",
    "                # Verificar si el DataFrame filtrado está vacío\n",
    "                if df_filtrado.empty:\n",
    "                    print(f\"DataFrame vacío después de filtrar por meses válidos. Regresando {archivo[:19]} vacío.\")\n",
    "                    return df_filtrado\n",
    "                    \n",
    "                # Se calcula la media \n",
    "                HRA2_60_med_m = df_filtrado[['event_value']].resample('ME').mean()\n",
    "\n",
    "                # Cambio de contenido de columnas\n",
    "                HRA2_60_med_m['station'] = df['station'].iloc[0]\n",
    "                HRA2_60_med_m['station'] = HRA2_60_med_m['station'].astype('int64')\n",
    "                HRA2_60_med_m['label'] = 'HRA2_MEDIA_M_QC'\n",
    "                \n",
    "                # Reset index\n",
    "                HRA2_60_med_m.reset_index(inplace=True)\n",
    "                \n",
    "                # Se reordenan las columnas\n",
    "                nuevo_orden = ['station', 'label', 'event_time', 'event_value']\n",
    "                # Reordenar las columnas usando el nuevo orden\n",
    "                HRA2_60_med_m = HRA2_60_med_m[nuevo_orden]\n",
    "            \n",
    "                # Convertir 'event_time' de nuevo a datetime para uniformidad\n",
    "                HRA2_60_med_m['event_time'] = pd.to_datetime(HRA2_60_med_m['event_time'])\n",
    "                \n",
    "                return HRA2_60_med_m\n",
    "            \n",
    "            dfhra2_med_m = HRA2_MEDIA_M_QC(dfhra2_med_d_c)\n",
    "            \n",
    "            # Humedad relativa media anual\n",
    "            dfhra2_med_m_c = dfhra2_med_m.copy()\n",
    "            def HRA2_MEDIA_A_QC(df, columna_fecha='event_time', columna_valor='event_value', porc_min=0.67):\n",
    "                if df.empty:\n",
    "                    return df\n",
    "                df.reset_index(inplace=True)\n",
    "                # Convertir la columna de fecha a datetime si aún no lo es\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df[columna_fecha]):\n",
    "                    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "                \n",
    "                # Función para verificar si una hora específica tiene suficientes datos\n",
    "                def complet_anio(sub_df):\n",
    "                    return len(sub_df) >= 12 * porc_min\n",
    "                   \n",
    "                # Antes de resample, establecer la columna 'event_time' como índice\n",
    "                df.set_index(columna_fecha, inplace=True)\n",
    "            \n",
    "                # Luego de establecer el índice, aplicar resample\n",
    "                df_filtrado = df.groupby([df.index.year]).filter(complet_anio)\n",
    "                # Verificar si el DataFrame filtrado está vacío\n",
    "                if df_filtrado.empty:\n",
    "                    print(f\"DataFrame vacío después de filtrar por años válidos. Regresando {archivo[:19]} vacío.\")\n",
    "                    return df_filtrado\n",
    "                    \n",
    "                # Se calcula la media    \n",
    "                HRA2_60_med_a = df_filtrado[['event_value']].resample('YE').mean()\n",
    "\n",
    "                # Cambio de contenido de columnas\n",
    "                HRA2_60_med_a['station'] = df['station'].iloc[0]\n",
    "                HRA2_60_med_a['station'] = HRA2_60_med_a['station'].astype('int64')\n",
    "                HRA2_60_med_a['label'] = 'HRA2_MEDIA_A_QC'\n",
    "                \n",
    "                # Reset index\n",
    "                HRA2_60_med_a.reset_index(inplace=True)\n",
    "                \n",
    "                # Se reordenan las columnas\n",
    "                nuevo_orden = ['station', 'label', 'event_time', 'event_value']\n",
    "                # Reordenar las columnas usando el nuevo orden\n",
    "                HRA2_60_med_a = HRA2_60_med_a[nuevo_orden]\n",
    "            \n",
    "                # Convertir 'event_time' de nuevo a datetime para uniformidad\n",
    "                HRA2_60_med_a['event_time'] = pd.to_datetime(HRA2_60_med_a['event_time'])\n",
    "                \n",
    "                return HRA2_60_med_a\n",
    "            \n",
    "            dfhra2_med_a = HRA2_MEDIA_A_QC(dfhra2_med_m_c)\n",
    "\n",
    "            if not dfhra2_med_h.empty:\n",
    "                dfhra2_med_h.to_csv(os.path.join(carpeta, 'HRA2_MEDIA_H_QC', f'{archivo[:19]}.csv'), index=False)\n",
    "            if not dfhra2_med_d.empty:\n",
    "                dfhra2_med_d.to_csv(os.path.join(carpeta, 'HRA2_MEDIA_D_QC', f'{archivo[:19]}.csv'), index=False)\n",
    "            if not dfhra2_med_m.empty:\n",
    "                dfhra2_med_m.to_csv(os.path.join(carpeta, 'HRA2_MEDIA_M_QC', f'{archivo[:19]}.csv'), date_format='%Y-%m', index=False)\n",
    "            if not dfhra2_med_a.empty:\n",
    "                dfhra2_med_a.to_csv(os.path.join(carpeta, 'HRA2_MEDIA_A_QC', f'{archivo[:19]}.csv'), date_format='%Y',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90943a6b-2791-482e-b411-611884b55457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0011120040 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0011155030 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0015015050 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0015079010 vacío.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0021045010 vacío.\n",
      "Error en el archivo Estacion_0021055020_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "Error en el archivo Estacion_0021085030_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0021095010 vacío.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0021115100 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0021130050 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0021140120 vacío.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0021185030 vacío.\n",
      "Error en el archivo Estacion_0021201580_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0021206560 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0021206900 vacío.\n",
      "Error en el archivo Estacion_0021237020_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0021255090 vacío.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0023020080 vacío.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0023067020 vacío.\n",
      "Error en el archivo Estacion_0023097030_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0024015513 vacío.\n",
      "Error en el archivo Estacion_0024027070_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0024030350 vacío.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0024037620 vacío.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0025027720 vacío.\n",
      "DataFrame vacío después de filtrar por días válidos. Regresando Estacion_0026035501 vacío.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0026185020 vacío.\n",
      "Error en el archivo Estacion_0026200120_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0028025501 vacío.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0029045180 vacío.\n",
      "Error en el archivo Estacion_0032067030_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "Error en el archivo Estacion_0035017020_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "Error en el archivo Estacion_0035037100_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0035075040 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0035095110 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0035195050 vacío.\n",
      "Error en el archivo Estacion_0035237040_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "Error en el archivo Estacion_0044045030_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0052055160 vacío.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0054015020 vacío.\n",
      "Error en el archivo Estacion_0054017040_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0056010040 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_0056015040 vacío.\n",
      "DataFrame vacío después de filtrar por meses válidos. Regresando Estacion_0088112901 vacío.\n",
      "Error en el archivo Estacion_1507500207_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "Error en el archivo Estacion_2120000099_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "Error en el archivo Estacion_2120000100_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_2120500204 vacío.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_34504\\2623457436.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_archivo, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en el archivo Estacion_2120700162_qc.csv: dfC está vacío. Saltando al siguiente archivo.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_2612500210 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_2612500211 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_2612500212 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_2612500213 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_2612500214 vacío.\n",
      "DataFrame vacío después de filtrar por años válidos. Regresando Estacion_2612500215 vacío.\n"
     ]
    }
   ],
   "source": [
    "calc_deriv_HRA2_QC('../../OE_3_QC_Variables/2_HumedadRelativa/ReadyToCassandraFiles_HR/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f8d21-7fc5-42ff-88af-84a73cb7cb5a",
   "metadata": {},
   "source": [
    "### Cálculo promedios horarios mensuales multianuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a30dc0-69e9-4016-8d4d-3033f49e5113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hmMa_patm(carpeta, chunk_size=540000):\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Se recorre cada archivo en la carpeta\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(carpeta, archivo)\n",
    "        \n",
    "            # Se procesan los archivos csv por fragmentos\n",
    "            reader = pd.read_csv(ruta_archivo, encoding='latin-1', chunksize=chunk_size)\n",
    "            \n",
    "            for chunk in reader:\n",
    "                # Se generan dataframes analizados\n",
    "                # De cada chunk se transforma a datetime la serie/columna 'Fecha'\n",
    "                try:\n",
    "                    chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                except ValueError:\n",
    "                    chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "                    chunk = chunk[~chunk['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PSO0','0PAT','0PER']]))]\n",
    "\n",
    "                # Se hace la agrupación para cálculo de medias horarias mensuales multianuales\n",
    "                hym_ma = chunk['event_value'].groupby(by =[chunk[\"Fecha\"].dt.month, chunk[\"Fecha\"].dt.hour]).mean().unstack(level=0)\n",
    "\n",
    "                # Crear un archivo Excel y agregar los datos\n",
    "                wb = Workbook()\n",
    "                ws = wb.active\n",
    "                ws.title = \"Datos\"\n",
    "                \n",
    "                # Agregar datos al archivo Excel\n",
    "                for r in dataframe_to_rows(hym_ma.reset_index(), index=False, header=True):\n",
    "                    ws.append(r)\n",
    "                \n",
    "                # Crear la gráfica de dispersión\n",
    "                chart = ScatterChart()\n",
    "                chart.title = \"Valores Promedio por Hora y Mes\"\n",
    "                chart.style = 13\n",
    "                chart.x_axis.title = 'Hora del día'\n",
    "                chart.y_axis.title = 'Valor'\n",
    "                \n",
    "                # Aumentar el tamaño del gráfico\n",
    "                chart.width = 20  # Anchura del gráfico (pulgadas)\n",
    "                chart.height = 12  # Altura del gráfico (pulgadas)\n",
    "                \n",
    "                # Fijar el máximo valor del eje x\n",
    "                chart.x_axis.scaling.max = 23\n",
    "                chart.x_axis.scaling.min = 0\n",
    "                chart.x_axis.majorUnit = 1\n",
    "                \n",
    "                # Agregar series a la gráfica\n",
    "                colors = ['1F77B4', 'FF7F0E', '2CA02C', 'D62728', '9467BD', '8C564B', 'E377C2', '7F7F7F', 'BCBD22', '17BECF', 'AEC7E8', 'FFBB78']\n",
    "                for i in range(2, 14):  # Columnas B a M (meses 1 a 12)\n",
    "                    xvalues = Reference(ws, min_col=1, min_row=2, max_row=25)\n",
    "                    yvalues = Reference(ws, min_col=i, min_row=1, max_row=25)\n",
    "                    series = Series(yvalues, xvalues, title_from_data=True)\n",
    "                    series.graphicalProperties.line.solidFill = colors[i % len(colors)]  # Asignar colores a las líneas\n",
    "                    series.graphicalProperties.line.width = 30000  # Ajustar el grosor de las líneas\n",
    "                    series.marker.symbol = 'circle'  # Cambiar el marcador a círculo\n",
    "                    series.marker.size = 5\n",
    "                    series.marker.graphicalProperties.solidFill = colors[i % len(colors)]  # Cambiar el color del marcador\n",
    "                    chart.series.append(series)\n",
    "                \n",
    "                # Insertar la gráfica en la hoja de cálculo\n",
    "                ws.add_chart(chart, \"O2\")\n",
    "\n",
    "                # Nombres archivos\n",
    "                nombre_archivo_salida = os.path.join(carpeta, archivo[:19] + '_hm_ma.xlsx') #archivo[:22] el de qc\n",
    "                # Guardar el archivo Excel\n",
    "                wb.save(nombre_archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c99242-480a-4d33-afb9-c9b9bf75ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_hmMa_patm('QCResult_Patm/V3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
