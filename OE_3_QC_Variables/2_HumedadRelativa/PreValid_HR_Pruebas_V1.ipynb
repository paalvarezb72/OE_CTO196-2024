{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f2b16b-912e-4a9b-98c0-5a393e545013",
   "metadata": {},
   "source": [
    "# Pruebas automatizadas datos humedad relativa - Clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885f6f6",
   "metadata": {},
   "source": [
    "> Elaborado por Paola Álvarez, profesional contratista IDEAM, contrato 196 de 2024. Comentarios o inquietudes, remitir a *palvarez@ideam.gov.co* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ebabc-ed05-4660-a06e-7c242cb0ffeb",
   "metadata": {},
   "source": [
    "**Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28398810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14c1a4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7267c",
   "metadata": {},
   "source": [
    "A continuación, se encuentran las pruebas de pre-validación de datos de EMA para verificar su capacidad de detección de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2be3c",
   "metadata": {},
   "source": [
    "## Clase con métodos de aplicación de QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9474e9-bcdb-4d60-a03d-7e72ebdf588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del logger para guardar en el directorio de archivos y sobrescribir cada vez\n",
    "def setup_logger(log_file_path):\n",
    "    logger = logging.getLogger('Test_QC')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    # Clear existing handlers to avoid duplicate logs\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    file_handler = logging.FileHandler(log_file_path, mode='a')\n",
    "    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(file_handler)\n",
    "    return logger\n",
    "\n",
    "def log_failures(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(self, chunk, archivo):\n",
    "        try:\n",
    "            result, mask = func(self, chunk, archivo)\n",
    "            if mask is not None:\n",
    "                try:\n",
    "                    aligned_mask = mask.reindex(chunk.index, fill_value=False)  # Asegura que la máscara esté alineada con el índice del DataFrame\n",
    "                except AttributeError:\n",
    "                    aligned_mask = mask  # Si no se puede reindexar, usa la máscara tal como está\n",
    "                for index, row in chunk[aligned_mask].iterrows():\n",
    "                    self.logger.info('Archivo: %s - Fila: %s - Valor fallido en %s: %s', archivo, index, func.__name__, row['Valor'])\n",
    "            return result\n",
    "        except ValueError as e:\n",
    "            self.logger.error('Error procesando el archivo %s: %s', archivo, str(e))\n",
    "            return chunk  # Devuelve una máscara falsa para manejar el error\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddb424af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutomatHREMA:\n",
    "    \n",
    "    def __init__(self, dir_files, chunk_size=54000):\n",
    "        self.dir_files = dir_files\n",
    "        self.ruta_archivos = os.listdir(dir_files)\n",
    "        self.chunk_size = chunk_size\n",
    "        self.last_rows = None\n",
    "        self.current_file = None\n",
    "        # Sección configuración de logs\n",
    "        log_file_path = os.path.join(dir_files, 'QC_HR.log')\n",
    "        self.logger = setup_logger(log_file_path)\n",
    "        self.logger.info('Inicialización de PreValidPatmEMA en directorio: %s', dir_files)\n",
    "\n",
    "    def p_transm(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si existe al menos el 70% de datos esperados por día y hora\n",
    "        en la serie de datos; aquellos que no superen la prueba, son marcados como sospechosos'''\n",
    "        # Se encontraron diferentes frecuencias en la transmisión de Patm, por lo tanto:\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1') #, sep=';')\n",
    "        \n",
    "        # Se define un diccionario de frecuencias y cantidades esperadas\n",
    "        frecuencias = {\n",
    "            'T': {'cant_esperd_h': 60, 'cant_esperd_d': 1440},\n",
    "            '5T': {'cant_esperd_h': 12, 'cant_esperd_d': 288},\n",
    "            '10T': {'cant_esperd_h': 6, 'cant_esperd_d': 144},\n",
    "            'H': {'cant_esperd_h': 1, 'cant_esperd_d': 24}\n",
    "        }\n",
    "        \n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        station_value = chunk['Station'].values[0]\n",
    "        if pd.isna(station_value):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == station_value]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {station_value} en freqinst200b\")\n",
    "                return chunk\n",
    "    \n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "    \n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    print(periodos)\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk\n",
    "    \n",
    "        # Obtener las cantidades esperadas de acuerdo a la frecuencia\n",
    "        cant_esperd_h = frecuencias[periodos]['cant_esperd_h']\n",
    "        cant_esperd_d = frecuencias[periodos]['cant_esperd_d']\n",
    "    \n",
    "        # Se establecen los aceptables\n",
    "        cant_aceptab_hora = 0.7 * cant_esperd_h\n",
    "        cant_aceptab_dia = 0.7 * cant_esperd_d\n",
    "    \n",
    "        # Agregar columna de etiquetas al dataframe original\n",
    "        chunk['Estado'] = np.nan\n",
    "        \n",
    "        # Definir función para asignar etiquetas\n",
    "        def asignar_etiqueta(row):\n",
    "            if row['count'] < cant_aceptab_hora:\n",
    "                chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
    "        \n",
    "        # Evaluar por cada grupo de datos por hora y asignar la etiqueta\n",
    "        canthora = chunk.groupby(chunk['Fecha'].dt.floor('H')).size().reset_index(name='count')\n",
    "        canthora.apply(asignar_etiqueta, axis=1)\n",
    "        \n",
    "        # Definir función para asignar etiquetas de acumulado diario\n",
    "        def asignar_etiqueta_diaria(row):\n",
    "            if row['count'] < cant_aceptab_dia:\n",
    "                chunk.loc[chunk['Fecha'].dt.floor('D') == row['Fecha'].floor('D'), 'Estado'] = '0PSO0'\n",
    "        \n",
    "        # Evaluar por cada grupo de datos por día y asignar la etiqueta\n",
    "        cantdia = chunk.groupby(chunk['Fecha'].dt.floor('D')).size().reset_index(name='count')\n",
    "        cantdia.apply(asignar_etiqueta_diaria, axis=1)\n",
    "        \n",
    "        return chunk, _\n",
    "        \n",
    "    #@log_failures\n",
    "    def p_estruct(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si los datos fueron transmitidos en horas y minutos exactos al ser el\n",
    "        comportamiento esperado'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1') #, sep=';')\n",
    "        \n",
    "        # Define un diccionario de frecuencias y cantidades esperadas\n",
    "        frecuencias = {\n",
    "            '5T': {'num_para_modulo': 5},\n",
    "            '10T': {'num_para_modulo': 10}\n",
    "        }\n",
    "        \n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        station_value = chunk['Station'].values[0]\n",
    "        if pd.isna(station_value):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == station_value]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {station_value} en freqinst200b\")\n",
    "                return chunk\n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "    \n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    print(periodos)\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        # Se hace frente al caso de no encontrar la estación\n",
    "        if periodos is not None:\n",
    "            \n",
    "            # Generar la operación para observar si la estructura es exacta en minutos\n",
    "            fecha = chunk['Fecha']\n",
    "    \n",
    "            # Se vectoriza la evaluación de la estructura por minuto\n",
    "            # Para cada chunk:\n",
    "            if periodos == 'T':\n",
    "                mask = fecha.dt.second != 0\n",
    "            elif periodos == 'H':\n",
    "                mask = (fecha.dt.minute != 0) | (fecha.dt.second != 0)\n",
    "            else:\n",
    "                # Se obtiene num_para_modulo\n",
    "                num_para_modulo = frecuencias[periodos]['num_para_modulo']\n",
    "                mask = fecha.dt.minute % num_para_modulo != 0\n",
    "    \n",
    "            # Cambiar '0PSO0' a '0PSO1' donde la máscara se cumple\n",
    "            chunk.loc[mask & (chunk['Estado'] == '0PSO0'), 'Estado'] = '0PSO1'\n",
    "            # Asignar '0PSO0' a los NaN donde la máscara se cumple\n",
    "            chunk.loc[mask & chunk['Estado'].isnull(), 'Estado'] = '0PSO0'\n",
    "        \n",
    "        else:  # Si el periodo es None, no se hace ninguna modificación al chunk, pero puedes imprimir un mensaje si quieres\n",
    "            print(f\"No se encontró la frec de la estac.{station_value} ni un proyecto respectivo en freqinst200b\")\n",
    "            \n",
    "        return chunk, mask\n",
    "\n",
    "    #@log_failures\n",
    "    def p_limrig(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si los datos crudos se encuentran fuera del umbral físico inferior o superior'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "            \n",
    "        # Se genera la columna de estado anterior\n",
    "        chunk['Estado_Anterior'] = np.nan\n",
    "        \n",
    "        # Se establecen los umbrales físicos/rígidos a datos crudos en nuevas colummnas para vectorizar\n",
    "        chunk['umbr_crud_inf'] = 0.0\n",
    "        chunk['umbr_crud_sup'] = 100.0\n",
    "\n",
    "        # Compara el dato con umbrales inferiores y superiores \n",
    "        mask_outbounds = (chunk['Valor'] < chunk['umbr_crud_inf']) | (chunk['Valor'] > chunk['umbr_crud_sup'])\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado_Anterior'\n",
    "        condicion_0PSO0 = mask_outbounds & chunk['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado'\n",
    "        condicion_0PER0 = mask_outbounds & (chunk['Estado'].isnull() | chunk['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk.loc[condicion_0PER0, 'Estado'] = '0PER0'\n",
    "        \n",
    "        # Se eliminan las columnas no deseadas\n",
    "        if 'umbr_crud_inf' in chunk.columns:\n",
    "            chunk.drop(columns=['umbr_crud_inf', 'umbr_crud_sup'], axis=1, inplace=True)\n",
    "                \n",
    "        return chunk, mask_outbounds\n",
    "\n",
    "    def p_persist(self, chunk, archivo):\n",
    "        '''Esta prueba detecta los datos que se repiten por más de cuatro horas consecutivas'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "                \n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "\n",
    "        # Verificar si el archivo ha cambiado\n",
    "        if self.current_file != archivo:\n",
    "            # Si el archivo cambió, resetea self.last_rows y actualiza self.current_file\n",
    "            self.last_rows = None\n",
    "            self.current_file = archivo\n",
    "            \n",
    "        # Usar self.last_rows para concatenar con el chunk actual\n",
    "        if self.last_rows is not None:\n",
    "            chunk = pd.concat([self.last_rows, chunk])\n",
    "            chunk.reset_index(drop=True)\n",
    "\n",
    "        # Se crean máscaras para el intervalo del día con radiación solar que puede afectar la humedad\n",
    "        mask_sunny = (chunk['Fecha'].dt.hour >= 4) & (chunk['Fecha'].dt.hour <= 20)\n",
    "        # Se filtran los datos para esas horas\n",
    "        mask_sun = chunk[mask_sunny]\n",
    "            \n",
    "        # Crear máscaras para cada comparación de las 4 filas consecutivas\n",
    "        mask_1 = (mask_sun['Valor'] == mask_sun['Valor'].shift(1))\n",
    "        mask_2 = (mask_sun['Valor'] == mask_sun['Valor'].shift(2))\n",
    "        mask_3 = (mask_sun['Valor'] == mask_sun['Valor'].shift(3))\n",
    "        mask_4 = (mask_sun['Valor'] == mask_sun['Valor'].shift(4))\n",
    "        \n",
    "        # Combinar todas las máscaras para obtener la condición deseada\n",
    "        mask_pers4datos = mask_1 & mask_2 & mask_3 & mask_4\n",
    "        \n",
    "        # Etiquetado de valores, se inicia con el Estado Anterior\n",
    "        condicion_0PSO0 = mask_pers4datos & chunk['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado'\n",
    "        condicion_0PER0 = mask_pers4datos & (chunk['Estado'].isnull() | chunk['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk.loc[condicion_0PER0, 'Estado'] = '0PER0'\n",
    "        mask_pers4datos = mask_pers4datos & ~condicion_0PER0\n",
    "\n",
    "        condicion_0PER1 = mask_pers4datos & (chunk['Estado'] == '0PER0')\n",
    "        chunk.loc[condicion_0PER1, 'Estado'] = '0PER1'\n",
    "\n",
    "        self.last_rows = chunk.tail(4)\n",
    "        \n",
    "        return chunk, mask_pers4datos\n",
    "\n",
    "    def p_salto(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si la variación entre valores consecutivos excede 45.0 %'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "            \n",
    "        # Se toma nuevamente el archivo de frecuencias para analizar datos estrictamente consecutivos\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1') #, sep=';')\n",
    "\n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        sttn_code = chunk['Station'].values[0]\n",
    "        if pd.isna(sttn_code):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == sttn_code]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {sttn_code} en freqinst200b\")\n",
    "                return chunk\n",
    "            # Se toma el valor inferido de la frecuencia\n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "            # Si el valor inferido es un NaN, se infiere dentro del código (esto porque hay estaciones con )\n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    print(periodos)\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk\n",
    "\n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "        \n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "\n",
    "        # Crear una columna de diferencia temporal\n",
    "        chunk['Fecha_anterior'] = chunk['Fecha'].shift(1)\n",
    "        chunk['Delta_tiempo'] = chunk['Fecha'] - chunk['Fecha_anterior']\n",
    "        \n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        mask_consecutivo = chunk['Delta_tiempo'] == pd.to_timedelta(periodos)\n",
    "        \n",
    "        # Calcular la diferencia absoluta entre los valores consecutivos\n",
    "        chunk['Delta'] = chunk['Valor'].diff().abs()\n",
    "        chunk['Delta'] = chunk['Delta'].where(mask_consecutivo)\n",
    "\n",
    "        # Máscara para identificar variaciones mayores a 45.0\n",
    "        mask_variacion = chunk['Delta'] > 45.0\n",
    "      \n",
    "        # Etiquetado de valores, se inicia con el Estado Anterior\n",
    "        condicion_0PSO0 = mask_variacion & chunk['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado' - '0PER0'\n",
    "        condicion_0PER0 = mask_variacion & (chunk['Estado'].isnull() | chunk['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk.loc[condicion_0PER0, 'Estado'] = '0PER0'\n",
    "        mask_variacion = mask_variacion & ~condicion_0PER0\n",
    "        # '0PER1'\n",
    "        condicion_0PER1 = mask_variacion & (chunk['Estado'] == '0PER0')\n",
    "        chunk.loc[condicion_0PER1, 'Estado'] = '0PER1'\n",
    "        mask_variacion = mask_variacion & ~condicion_0PER1\n",
    "        # '0PER2'\n",
    "        condicion_0PER2 = mask_variacion & (chunk['Estado'] == '0PER1')\n",
    "        chunk.loc[condicion_0PER2, 'Estado'] = '0PER2'\n",
    "\n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        chunk.drop(columns=['Delta', 'Fecha_anterior', 'Delta_tiempo'], axis=1, inplace=True)\n",
    "\n",
    "        return chunk, mask_variacion\n",
    "\n",
    "    def p_horavmaxmin(self, chunk, archivo):\n",
    "        '''Esta prueba detecta los datos que son máximos y mínimos en horarios distintos a los posibles por la temperatura máxima en el\n",
    "        día según la radiación solar'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "\n",
    "        if chunk['Estado'].notna().all(): # Se verifica que no hayan valores nulos en tal columna\n",
    "            chunk_hmm = chunk[~chunk['Estado'].str.startswith('0PER', na=False)].copy()\n",
    "        else:\n",
    "            # Si todos los valores son NaN, simplemente copia el chunk\n",
    "            chunk_hmm = chunk.copy()\n",
    "            \n",
    "        # Se crean máscaras para los intervalos de tiempo conocidos para valores máximos y mínimos\n",
    "        mask_max_morning = (chunk_hmm['Fecha'].dt.hour >= 0) & (chunk_hmm['Fecha'].dt.hour < 10) \n",
    "        mask_max_afternoon = (chunk_hmm['Fecha'].dt.hour > 17) & (chunk_hmm['Fecha'].dt.hour <= 23)\n",
    "        mask_min_afternoon = (chunk_hmm['Fecha'].dt.hour >= 10) & (chunk_hmm['Fecha'].dt.hour <= 17)\n",
    "        \n",
    "        # Se filtran los datos para esas horas\n",
    "        max_validdata = chunk_hmm[mask_max_morning | mask_max_afternoon]\n",
    "        min_validdata = chunk_hmm[mask_min_afternoon]\n",
    "\n",
    "        # Encontrar dos valores máximos por día\n",
    "        max_values = chunk_hmm.groupby(chunk_hmm['Fecha'].dt.date).apply(lambda x: x.nlargest(2, 'Valor')).reset_index(level=0, drop=True)\n",
    "        \n",
    "        # Encontrar dos valores mínimos por día\n",
    "        min_values = chunk_hmm.groupby(chunk_hmm['Fecha'].dt.date).apply(lambda x: x.nsmallest(2, 'Valor')).reset_index(level=0, drop=True)\n",
    "\n",
    "        # Verificar los máximos y mínimos y obtener las horas correspondientes\n",
    "        notvalid_max_values = max_values[~max_values.index.isin(max_validdata.index)]\n",
    "        notvalid_min_values = min_values[~min_values.index.isin(min_validdata.index)]\n",
    "\n",
    "        # Combinar los valores no válidos en un solo DataFrame\n",
    "        notvalid_values = pd.concat([notvalid_max_values, notvalid_min_values])\n",
    "        # Crear una máscara para identificar los índices de los valores no válidos\n",
    "        notval_maxmin = chunk_hmm.index.isin(notvalid_values.index)\n",
    "\n",
    "        ## Actualización de estado\n",
    "        # Condición llenado de 'Estado_Anterior', si aplica\n",
    "        condicion_0PSO0 = notval_maxmin & chunk_hmm['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk_hmm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hmm.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Se etiquetan los atípicos\n",
    "        condicion_0PAT0 = notval_maxmin & (chunk_hmm['Estado'].isnull() | chunk_hmm['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk_hmm.loc[condicion_0PAT0, 'Estado'] = '0PAT0'\n",
    "\n",
    "        # Se copia al chunk original\n",
    "        chunk.loc[chunk_hmm.index] = chunk_hmm\n",
    "        return chunk, notval_maxmin\n",
    "\n",
    "    def p_sigma(self, chunk, archivo):\n",
    "        '''Esta prueba calcula, con los datos no etiquetados en la anterior prueba, la 4sigmas +- la media para detectar\n",
    "        datos atípicos en los conjuntos de los datos'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "\n",
    "        if chunk['Estado'].notna().all(): # Se verifica que no hayan valores nulos en tal columna\n",
    "            chunk_sgm = chunk[~chunk['Estado'].str.startswith('0PER', na=False)].copy()\n",
    "        else:\n",
    "            # Si todos los valores son NaN, simplemente copia el chunk\n",
    "            chunk_sgm = chunk.copy()\n",
    "\n",
    "        # Se calculan los estadísticos para sigma\n",
    "        mean = chunk_sgm['Valor'].mean()\n",
    "        std = chunk_sgm['Valor'].std()\n",
    "        # Con ellos, se establecen los límites superior e inferior\n",
    "        chunk_sgm['LimSup_Sigma'] = (mean + (4 * std))\n",
    "        chunk_sgm['LimInf_Sigma'] = (mean - (4 * std))\n",
    "\n",
    "        # Se etiquetan los valores que sobrepasen el límite\n",
    "        mask_outbsigma = (chunk_sgm['Valor'] < chunk_sgm['LimInf_Sigma']) | (chunk_sgm['Valor'] > chunk_sgm['LimSup_Sigma'])\n",
    "        \n",
    "        ## Actualización de estado\n",
    "        # Condición llenado de 'Estado_Anterior', si aplica\n",
    "        condicion_0PSO0 = mask_outbsigma & chunk_sgm['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk_sgm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_sgm.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Se etiquetan los atípicos - '0PAT0'\n",
    "        condicion_0PAT0 = mask_outbsigma & (chunk_sgm['Estado'].isnull() | chunk_sgm['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk_sgm.loc[condicion_0PAT0, 'Estado'] = '0PAT0'\n",
    "        mask_outbsigma = mask_outbsigma & ~condicion_0PAT0\n",
    "        # 0PAT1\n",
    "        condicion_0PAT1 = mask_outbsigma & (chunk_sgm['Estado'] == '0PAT0')\n",
    "        chunk_sgm.loc[condicion_0PAT1, 'Estado'] = '0PAT1'\n",
    "        # mask_outbsigma = mask_outbsigma & ~condicion_0PAT1\n",
    "        # # 0PAT2\n",
    "        # condicion_0PAT2 = mask_outbsigma & (chunk_sgm['Estado'] == '0PAT1')\n",
    "        # chunk_sgm.loc[condicion_0PAT2, 'Estado'] = '0PAT2'\n",
    "                    \n",
    "        # Se eliminan las columnas no deseadas\n",
    "        if 'LimSup_Sigma' in chunk.columns:\n",
    "            chunk.drop(columns=['LimSup_Sigma', 'LimInf_Sigma'], axis=1, inplace=True)\n",
    "    \n",
    "        chunk.loc[chunk_sgm.index] = chunk_sgm\n",
    "        return chunk, mask_outbsigma\n",
    "\n",
    "    def p_coher5vals(self, chunk, archivo):\n",
    "        '''Esta prueba verifica que un valor tenga coherencia con los 5 anteriores según su desviación estándar y media'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None    \n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "            \n",
    "        ## Trabajo con frecuencias\n",
    "        # Se toma nuevamente el archivo de frecuencias para analizar datos estrictamente consecutivos\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1')\n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        sttn_code = chunk['Station'].values[0]\n",
    "        if pd.isna(sttn_code):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == sttn_code]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {sttn_code} en freqinst200b\")\n",
    "                return chunk, None\n",
    "            # Se toma el valor inferido de la frecuencia\n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "            # Si el valor inferido es un NaN, se infiere dentro del código\n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk, None\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk, None\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk, None\n",
    "\n",
    "        ## Se asegura la revisión de 5 datos anteriores aún si cambia el chunk\n",
    "        # Verificar si el archivo ha cambiado\n",
    "        if self.current_file != archivo:\n",
    "            # Si el archivo cambió, resetea self.last_rows y actualiza self.current_file\n",
    "            self.last_rows = None\n",
    "            self.current_file = archivo\n",
    "        # Usar self.last_rows para concatenar con el chunk actual\n",
    "        if self.last_rows is not None:\n",
    "            chunk = pd.concat([self.last_rows, chunk])\n",
    "            chunk.reset_index(drop=True)\n",
    "    \n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "\n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "\n",
    "        # Crear una columna de diferencia temporal\n",
    "        chunk['Fecha_anterior'] = chunk['Fecha'].shift(1)\n",
    "        chunk['Delta_tiempo'] = chunk['Fecha'] - chunk['Fecha_anterior']\n",
    "    \n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos\n",
    "        if 'Estado' not in chunk.columns or chunk['Estado'].isnull().all():\n",
    "            chunk_5vals = chunk.copy()\n",
    "        else:\n",
    "            chunk_5vals = chunk[~chunk['Estado'].str.startswith(('0PER','0PAT'), na=False)].copy()\n",
    "\n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        mask_consecutivo = chunk_5vals['Delta_tiempo'] == pd.to_timedelta(periodos)\n",
    "        chnk_coh5vl = chunk_5vals[mask_consecutivo]\n",
    "\n",
    "        # Se establecen diferentes ventanas según frecuencias\n",
    "        windows = {'T': {'window': 240}, '5T': {'window': 72}, '10T': {'window': 48}, 'H': {'window': 11}}\n",
    "\n",
    "        window_size = windows[periodos]['window']\n",
    "        print(window_size)\n",
    "        \n",
    "        # Calcular el promedio y desviación estándar de los 5 registros anteriores y posteriores\n",
    "        chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
    "        chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
    "    \n",
    "        # Calcular los límites superior e inferior\n",
    "        chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
    "        chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n",
    "        chnk_coh5vl.to_csv('pruebita.csv')\n",
    "\n",
    "        # Máscara para identificar valores fuera de los límites\n",
    "        mask_var5prev = (chnk_coh5vl['Valor'] < chnk_coh5vl['lim_inf']) | (chnk_coh5vl['Valor'] > chnk_coh5vl['lim_sup'])\n",
    "        #print(chnk_coh5vl[mask_var5prev])\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado', sospechoso, '0PSO0'\n",
    "        condicion_0PSO0 = mask_var5prev & (chnk_coh5vl['Estado'].isnull())\n",
    "        chnk_coh5vl.loc[condicion_0PSO0, 'Estado'] = '0PSO0'\n",
    "        mask_var5prev = mask_var5prev & ~condicion_0PSO0\n",
    "        # 0PSO1\n",
    "        condicion_0PSO1 = mask_var5prev & (chnk_coh5vl['Estado'] == '0PSO0')\n",
    "        chnk_coh5vl.loc[condicion_0PSO1, 'Estado'] = '0PSO1'\n",
    "        mask_var5prev = mask_var5prev & ~condicion_0PSO1\n",
    "        # 0PSO2\n",
    "        condicion_0PSO2 = mask_var5prev & (chnk_coh5vl['Estado'] == '0PSO1')\n",
    "        chnk_coh5vl.loc[condicion_0PSO2, 'Estado'] = '0PSO2'\n",
    "    \n",
    "        # Se asegura la verificación de los valores anteriores si hubo cambio de chunk\n",
    "        self.last_rows = chnk_coh5vl.tail(5)\n",
    "\n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        if 'Fecha_anterior' in chunk.columns:\n",
    "            chunk.drop(columns=['Fecha_anterior','Delta_tiempo'], axis=1, inplace=True)\n",
    "            \n",
    "        # Copiar datos de chunk_coher al chunk original\n",
    "        chunk.loc[chnk_coh5vl.index] = chnk_coh5vl\n",
    "        # Continuar eliminando filas\n",
    "        if 'mean_5' in chunk.columns:\n",
    "            chunk.drop(columns=['mean_5','std_5','lim_inf','lim_sup'], axis=1, inplace=True)\n",
    "        \n",
    "        return chunk, mask_var5prev\n",
    "\n",
    "    def p_varminh(self, chunk, archivo):\n",
    "        '''Esta prueba detecta los valores horarios que no varían en 1.0 % durante la hora'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "        # Se genera la columna 'Estado_Anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "    \n",
    "        # Se toma nuevamente el archivo de frecuencias para analizar datos estrictamente consecutivos\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1')\n",
    "    \n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        sttn_code = chunk['Station'].values[0]\n",
    "        if pd.isna(sttn_code):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == sttn_code]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {sttn_code} en freqinst200b\")\n",
    "                return chunk, None\n",
    "            # Se toma el valor inferido de la frecuencia\n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "            # Si el valor inferido es un NaN, se infiere dentro del código\n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk, None\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk, None\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk, None\n",
    "    \n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "    \n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "    \n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos o atípicos\n",
    "        if 'Estado' in chunk.columns and chunk['Estado'].notna().all():\n",
    "            chunk_varhmn = chunk[~chunk['Estado'].str.startswith(('0PER', '0PAT'), na=False)].copy()\n",
    "        else:\n",
    "            chunk_varhmn = chunk.copy()\n",
    "    \n",
    "        # Crear una columna de diferencia temporal y otras columnas temporales\n",
    "        chunk_varhmn['Fecha_anterior'] = chunk_varhmn['Fecha'].shift(1)\n",
    "        chunk_varhmn['Delta_tiempo'] = chunk_varhmn['Fecha'] - chunk_varhmn['Fecha_anterior']\n",
    "    \n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        freq_map = {'H': '1H', 'T': '1T', '5T': '5T', '10T': '10T'}\n",
    "        expected_delta = pd.to_timedelta(freq_map.get(periodos, '1H'))\n",
    "        mask_consecut = chunk_varhmn['Delta_tiempo'] == expected_delta\n",
    "    \n",
    "        # Calcular la diferencia absoluta entre los valores consecutivos\n",
    "        chunk_varhmn['Delta'] = chunk_varhmn['Valor'].diff().abs()\n",
    "        chunk_varhmn['Delta'] = chunk_varhmn['Delta'].where(mask_consecut)\n",
    "    \n",
    "        # Aplicar la máscara de las horas soleadas después de crear las columnas temporales\n",
    "        mask_sunny2 = (chunk_varhmn['Fecha'].dt.hour >= 6) & (chunk_varhmn['Fecha'].dt.hour <= 18)\n",
    "        mask_sun2 = chunk_varhmn[mask_sunny2]\n",
    "    \n",
    "        if periodos == 'H':\n",
    "            # Máscara para identificar variaciones menores a 1.0\n",
    "            mask_varhmin = mask_sun2['Delta'] < 1.0\n",
    "        else:\n",
    "            # Agrupar por horas y verificar si alguna variación dentro de la hora excede 1.0\n",
    "            mask_sun2['Fecha_hora'] = mask_sun2['Fecha'].dt.floor('H')\n",
    "            hora_groups = mask_sun2.groupby('Fecha_hora')\n",
    "            mask_varhmin = hora_groups['Delta'].transform(lambda x: (x < 1.0).any())\n",
    "            \n",
    "        # Lógica de etiquetado para 'Estado', sospechoso, '0PSO0'\n",
    "        condicion_0PSO0 = mask_varhmin & (mask_sun2['Estado'].isnull())\n",
    "        mask_sun2.loc[condicion_0PSO0, 'Estado'] = '0PSO0'\n",
    "        mask_varhmin = mask_varhmin & ~condicion_0PSO0\n",
    "        # 0PSO1\n",
    "        condicion_0PSO1 = mask_varhmin & (mask_sun2['Estado'] == '0PSO0')\n",
    "        mask_sun2.loc[condicion_0PSO1, 'Estado'] = '0PSO1'\n",
    "        mask_varhmin = mask_varhmin & ~condicion_0PSO1\n",
    "        # 0PSO2\n",
    "        condicion_0PSO2 = mask_varhmin & (mask_sun2['Estado'] == '0PSO1')\n",
    "        mask_sun2.loc[condicion_0PSO2, 'Estado'] = '0PSO2'\n",
    "        mask_varhmin = mask_varhmin & ~condicion_0PSO2\n",
    "        # 0PSO2\n",
    "        condicion_0PSO3 = mask_varhmin & (mask_sun2['Estado'] == '0PSO2')\n",
    "        mask_sun2.loc[condicion_0PSO3, 'Estado'] = '0PSO3'\n",
    "    \n",
    "        # Copiar datos de chunk_jmp al chunk original\n",
    "        chunk.loc[mask_sun2.index] = mask_sun2\n",
    "    \n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        columns_to_drop = ['Delta', 'Fecha_anterior', 'Delta_tiempo', 'Fecha_hora']\n",
    "        columns_to_drop = [col for col in columns_to_drop if col in chunk.columns]\n",
    "        chunk.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "        return chunk, mask_varhmin\n",
    "\n",
    "    def procesar_archivos(self, funcion_evaluacion):\n",
    "        '''Este método procesa la lectura y guardado de los archivos para todas las pruebas'''\n",
    "        archivos = self.ruta_archivos\n",
    "\n",
    "        archivos_salida = []  # Lista para almacenar nombres de archivos de salida\n",
    "\n",
    "        # Se recorre cada archivo en la carpeta\n",
    "        for archivo in archivos:\n",
    "            if archivo.endswith('.csv'):\n",
    "                ruta_archivo = os.path.join(self.dir_files, archivo)\n",
    "\n",
    "                reader = pd.read_csv(ruta_archivo, encoding='latin-1', chunksize=self.chunk_size)#,dtype={7: 'str'}, low_memory=False)\n",
    "                resultados = []\n",
    "\n",
    "                for chunk in reader:\n",
    "                    try:\n",
    "                        chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                    except ValueError:\n",
    "                        chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                    chunk['Station'] = chunk['Station'].astype('int64')\n",
    "                    chunk_resultado, _ = funcion_evaluacion(chunk, archivo)  # Desempaqueta solo el DataFrame\n",
    "                    resultados.append(chunk_resultado)\n",
    "\n",
    "                if not resultados:  # Se verifica si la lista está vacía\n",
    "                    self.logger.warning('No hay resultados válidos para concatenar en el archivo %s. Continuando con el siguiente archivo.', archivo)\n",
    "                    continue\n",
    "                    \n",
    "                resultados_consolidados = pd.concat(resultados)\n",
    "\n",
    "                # Genera el nombre del archivo de salida conservando los primeros 19 caracteres del nombre del archivo original\n",
    "                nombre_archivo_salida = archivo[:19] + '_qc.csv'\n",
    "\n",
    "                resultados_consolidados.to_csv(os.path.join(self.dir_files, nombre_archivo_salida), encoding='latin-1', index=False)\n",
    "\n",
    "                archivos_salida.append(nombre_archivo_salida)  # Agregar el nombre del archivo a la lista\n",
    "            \n",
    "        # Actualiza self.ruta_archivos para que la próxima prueba procese los resultados de esta prueba\n",
    "        self.ruta_archivos = archivos_salida\n",
    "        # Se fija el log de procesamiento completo de archivos\n",
    "        self.logger.info('Procesamiento completo de archivos de estaciones HR. Archivos generados: %s', archivos_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58f92b9d-0c3a-4652-aa4b-f41a66ab8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador = AutomatHREMA('Test_QC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d4348e0-435a-4f34-ad20-e1d5d8da9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_transm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d2d470b-c286-4289-90e5-8d9148c65a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_estruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7c17071-31e8-4484-9ae9-7ce1af648709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_limrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ea10b68-a8cb-4b67-b977-65d83029a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:223: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_persist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a4b8d2a-8da3-4629-8884-bdc299e12d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:301: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:301: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:301: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:301: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:301: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:301: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_salto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aafcc6e5-8bee-4f94-9d04-14d4dd4d97e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:363: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hmm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hmm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:370: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hmm.index] = chunk_hmm\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:363: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hmm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hmm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:370: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[nan nan nan ... nan nan '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hmm.index] = chunk_hmm\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:363: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hmm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hmm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:370: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hmm.index] = chunk_hmm\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:363: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hmm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hmm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:370: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hmm.index] = chunk_hmm\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:363: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hmm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hmm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:370: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hmm.index] = chunk_hmm\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:363: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hmm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hmm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:370: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[nan nan nan ... nan '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hmm.index] = chunk_hmm\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_horavmaxmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aca86b59-71b3-4471-87b3-150eb60eae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43d3f1d7-4219-42d7-b574-e61723082392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7792\\307870339.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_coher5vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1add052-3700-456b-b350-ffbb7610289f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_varminh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449b253-9dcb-4b22-896d-a898101a2cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffae449-bdf5-43d3-8a79-d968c7460a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
