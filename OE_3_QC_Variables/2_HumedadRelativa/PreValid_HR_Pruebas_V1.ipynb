{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f2b16b-912e-4a9b-98c0-5a393e545013",
   "metadata": {},
   "source": [
    "# Pruebas automatizadas datos humedad relativa - Clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885f6f6",
   "metadata": {},
   "source": [
    "> Elaborado por Paola Álvarez, profesional contratista IDEAM, contrato 196 de 2024. Comentarios o inquietudes, remitir a *palvarez@ideam.gov.co* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ebabc-ed05-4660-a06e-7c242cb0ffeb",
   "metadata": {},
   "source": [
    "**Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28398810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14c1a4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7267c",
   "metadata": {},
   "source": [
    "A continuación, se encuentran las pruebas de pre-validación de datos de EMA para verificar su capacidad de detección de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2be3c",
   "metadata": {},
   "source": [
    "## Clase con métodos de aplicación de QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9474e9-bcdb-4d60-a03d-7e72ebdf588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del logger para guardar en el directorio de archivos y sobrescribir cada vez\n",
    "def setup_logger(log_file_path):\n",
    "    logger = logging.getLogger('Test_QC')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    # Clear existing handlers to avoid duplicate logs\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    file_handler = logging.FileHandler(log_file_path, mode='a')\n",
    "    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(file_handler)\n",
    "    return logger\n",
    "\n",
    "def log_failures(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(self, chunk, archivo):\n",
    "        try:\n",
    "            result, mask = func(self, chunk, archivo)\n",
    "            if mask is not None:\n",
    "                try:\n",
    "                    aligned_mask = mask.reindex(chunk.index, fill_value=False)  # Asegura que la máscara esté alineada con el índice del DataFrame\n",
    "                except AttributeError:\n",
    "                    aligned_mask = mask  # Si no se puede reindexar, usa la máscara tal como está\n",
    "                for index, row in chunk[aligned_mask].iterrows():\n",
    "                    self.logger.info('Archivo: %s - Fila: %s - Valor fallido en %s: %s', archivo, index, func.__name__, row['Valor'])\n",
    "            return result\n",
    "        except ValueError as e:\n",
    "            self.logger.error('Error procesando el archivo %s: %s', archivo, str(e))\n",
    "            return chunk  # Devuelve una máscara falsa para manejar el error\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb424af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutomatHREMA:\n",
    "    \n",
    "    def __init__(self, dir_files, chunk_size=54000):\n",
    "        self.dir_files = dir_files\n",
    "        self.ruta_archivos = os.listdir(dir_files)\n",
    "        self.chunk_size = chunk_size\n",
    "        self.last_rows = None\n",
    "        self.current_file = None\n",
    "        # Sección configuración de logs\n",
    "        log_file_path = os.path.join(dir_files, 'QC_HR.log')\n",
    "        self.logger = setup_logger(log_file_path)\n",
    "        self.logger.info('Inicialización de PreValidPatmEMA en directorio: %s', dir_files)\n",
    "\n",
    "    def p_transm(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si existe al menos el 70% de datos esperados por día y hora\n",
    "        en la serie de datos; aquellos que no superen la prueba, son marcados como sospechosos'''\n",
    "        # Se encontraron diferentes frecuencias en la transmisión de Patm, por lo tanto:\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1') #, sep=';')\n",
    "        \n",
    "        # Se define un diccionario de frecuencias y cantidades esperadas\n",
    "        frecuencias = {\n",
    "            'T': {'cant_esperd_h': 60, 'cant_esperd_d': 1440},\n",
    "            '5T': {'cant_esperd_h': 12, 'cant_esperd_d': 288},\n",
    "            '10T': {'cant_esperd_h': 6, 'cant_esperd_d': 144},\n",
    "            'H': {'cant_esperd_h': 1, 'cant_esperd_d': 24}\n",
    "        }\n",
    "        \n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        station_value = chunk['Station'].values[0]\n",
    "        if pd.isna(station_value):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == station_value]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {station_value} en freqinst200b\")\n",
    "                return chunk\n",
    "    \n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "    \n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    print(periodos)\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk\n",
    "    \n",
    "        # Obtener las cantidades esperadas de acuerdo a la frecuencia\n",
    "        cant_esperd_h = frecuencias[periodos]['cant_esperd_h']\n",
    "        cant_esperd_d = frecuencias[periodos]['cant_esperd_d']\n",
    "    \n",
    "        # Se establecen los aceptables\n",
    "        cant_aceptab_hora = 0.7 * cant_esperd_h\n",
    "        cant_aceptab_dia = 0.7 * cant_esperd_d\n",
    "    \n",
    "        # Agregar columna de etiquetas al dataframe original\n",
    "        chunk['Estado'] = np.nan\n",
    "        \n",
    "        # Definir función para asignar etiquetas\n",
    "        def asignar_etiqueta(row):\n",
    "            if row['count'] < cant_aceptab_hora:\n",
    "                chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
    "        \n",
    "        # Evaluar por cada grupo de datos por hora y asignar la etiqueta\n",
    "        canthora = chunk.groupby(chunk['Fecha'].dt.floor('H')).size().reset_index(name='count')\n",
    "        canthora.apply(asignar_etiqueta, axis=1)\n",
    "        \n",
    "        # Definir función para asignar etiquetas de acumulado diario\n",
    "        def asignar_etiqueta_diaria(row):\n",
    "            if row['count'] < cant_aceptab_dia:\n",
    "                chunk.loc[chunk['Fecha'].dt.floor('D') == row['Fecha'].floor('D'), 'Estado'] = '0PSO0'\n",
    "        \n",
    "        # Evaluar por cada grupo de datos por día y asignar la etiqueta\n",
    "        cantdia = chunk.groupby(chunk['Fecha'].dt.floor('D')).size().reset_index(name='count')\n",
    "        cantdia.apply(asignar_etiqueta_diaria, axis=1)\n",
    "        \n",
    "        return chunk, _\n",
    "        \n",
    "    @log_failures\n",
    "    def p_estruct(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si los datos fueron transmitidos en horas y minutos exactos al ser el\n",
    "        comportamiento esperado'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1') #, sep=';')\n",
    "        \n",
    "        # Define un diccionario de frecuencias y cantidades esperadas\n",
    "        frecuencias = {\n",
    "            '5T': {'num_para_modulo': 5},\n",
    "            '10T': {'num_para_modulo': 10}\n",
    "        }\n",
    "        \n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        station_value = chunk['Station'].values[0]\n",
    "        if pd.isna(station_value):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == station_value]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {station_value} en freqinst200b\")\n",
    "                return chunk\n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "    \n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    print(periodos)\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        # Se hace frente al caso de no encontrar la estación\n",
    "        if periodos is not None:\n",
    "            \n",
    "            # Generar la operación para observar si la estructura es exacta en minutos\n",
    "            fecha = chunk['Fecha']\n",
    "    \n",
    "            # Se vectoriza la evaluación de la estructura por minuto\n",
    "            # Para cada chunk:\n",
    "            if periodos == 'T':\n",
    "                mask = fecha.dt.second != 0\n",
    "            elif periodos == 'H':\n",
    "                mask = (fecha.dt.minute != 0) | (fecha.dt.second != 0)\n",
    "            else:\n",
    "                # Se obtiene num_para_modulo\n",
    "                num_para_modulo = frecuencias[periodos]['num_para_modulo']\n",
    "                mask = fecha.dt.minute % num_para_modulo != 0\n",
    "    \n",
    "            # Cambiar '0PSO0' a '0PSO1' donde la máscara se cumple\n",
    "            chunk.loc[mask & (chunk['Estado'] == '0PSO0'), 'Estado'] = '0PSO1'\n",
    "            # Asignar '0PSO0' a los NaN donde la máscara se cumple\n",
    "            chunk.loc[mask & chunk['Estado'].isnull(), 'Estado'] = '0PSO0'\n",
    "        \n",
    "        else:  # Si el periodo es None, no se hace ninguna modificación al chunk, pero puedes imprimir un mensaje si quieres\n",
    "            print(f\"No se encontró la frec de la estac.{station_value} ni un proyecto respectivo en freqinst200b\")\n",
    "            \n",
    "        return chunk, mask\n",
    "\n",
    "    @log_failures\n",
    "    def p_limrig(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si los datos crudos se encuentran fuera del umbral físico inferior o superior'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "            \n",
    "        # Se genera la columna de estado anterior\n",
    "        chunk['Estado_Anterior'] = np.nan\n",
    "        \n",
    "        # Se establecen los umbrales físicos/rígidos a datos crudos en nuevas colummnas para vectorizar\n",
    "        chunk['umbr_crud_inf'] = 0.0\n",
    "        chunk['umbr_crud_sup'] = 100.0\n",
    "\n",
    "        # Compara el dato con umbrales inferiores y superiores \n",
    "        mask_outbounds = (chunk['Valor'] < chunk['umbr_crud_inf']) | (chunk['Valor'] > chunk['umbr_crud_sup'])\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado_Anterior'\n",
    "        condicion_0PSO0 = mask_outbounds & chunk['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado'\n",
    "        condicion_0PER0 = mask_outbounds & (chunk['Estado'].isnull() | chunk['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk.loc[condicion_0PER0, 'Estado'] = '0PER0'\n",
    "        \n",
    "        # Se eliminan las columnas no deseadas\n",
    "        if 'umbr_crud_inf' in chunk.columns:\n",
    "            chunk.drop(columns=['umbr_crud_inf', 'umbr_crud_sup'], axis=1, inplace=True)\n",
    "                \n",
    "        return chunk, mask_outbounds\n",
    "\n",
    "    @log_failures\n",
    "    def p_persist(self, chunk, archivo):\n",
    "        '''Esta prueba detecta los datos que se repiten por más de cuatro horas consecutivas'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "                \n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "\n",
    "        # Verificar si el archivo ha cambiado\n",
    "        if self.current_file != archivo:\n",
    "            # Si el archivo cambió, resetea self.last_rows y actualiza self.current_file\n",
    "            self.last_rows = None\n",
    "            self.current_file = archivo\n",
    "            \n",
    "        # Usar self.last_rows para concatenar con el chunk actual\n",
    "        if self.last_rows is not None:\n",
    "            chunk = pd.concat([self.last_rows, chunk])\n",
    "            chunk.reset_index(drop=True)\n",
    "\n",
    "        # Se crean máscaras para el intervalo del día con radiación solar que puede afectar la humedad\n",
    "        mask_sunny = (chunk['Fecha'].dt.hour >= 4) & (chunk['Fecha'].dt.hour <= 20)\n",
    "        # Se filtran los datos para esas horas\n",
    "        mask_sun = chunk[mask_sunny]\n",
    "            \n",
    "        # Crear máscaras para cada comparación de las 4 filas consecutivas\n",
    "        mask_1 = (mask_sun['Valor'] == mask_sun['Valor'].shift(1))\n",
    "        mask_2 = (mask_sun['Valor'] == mask_sun['Valor'].shift(2))\n",
    "        mask_3 = (mask_sun['Valor'] == mask_sun['Valor'].shift(3))\n",
    "        mask_4 = (mask_sun['Valor'] == mask_sun['Valor'].shift(4))\n",
    "        \n",
    "        # Combinar todas las máscaras para obtener la condición deseada\n",
    "        mask_pers4datos = mask_1 & mask_2 & mask_3 & mask_4\n",
    "        \n",
    "        # Etiquetado de valores, se inicia con el Estado Anterior\n",
    "        condicion_0PSO0 = mask_pers4datos & chunk['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado'\n",
    "        condicion_0PER0 = mask_pers4datos & (chunk['Estado'].isnull() | chunk['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk.loc[condicion_0PER0, 'Estado'] = '0PER0'\n",
    "        mask_pers4datos = mask_pers4datos & ~condicion_0PER0\n",
    "\n",
    "        condicion_0PER1 = mask_pers4datos & (chunk['Estado'] == '0PER0')\n",
    "        chunk.loc[condicion_0PER1, 'Estado'] = '0PER1'\n",
    "\n",
    "        self.last_rows = chunk.tail(4)\n",
    "        \n",
    "        return chunk, mask_pers4datos\n",
    "\n",
    "    def p_salto(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si la variación entre valores consecutivos excede 45.0 %'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "            \n",
    "        # Se toma nuevamente el archivo de frecuencias para analizar datos estrictamente consecutivos\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1') #, sep=';')\n",
    "\n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        sttn_code = chunk['Station'].values[0]\n",
    "        if pd.isna(sttn_code):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == sttn_code]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {sttn_code} en freqinst200b\")\n",
    "                return chunk\n",
    "            # Se toma el valor inferido de la frecuencia\n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "            # Si el valor inferido es un NaN, se infiere dentro del código (esto porque hay estaciones con )\n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    print(periodos)\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk\n",
    "\n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "        \n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "\n",
    "        # Crear una columna de diferencia temporal\n",
    "        chunk['Fecha_anterior'] = chunk['Fecha'].shift(1)\n",
    "        chunk['Delta_tiempo'] = chunk['Fecha'] - chunk['Fecha_anterior']\n",
    "        \n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        mask_consecutivo = chunk['Delta_tiempo'] == pd.to_timedelta(periodos)\n",
    "        \n",
    "        # Calcular la diferencia absoluta entre los valores consecutivos\n",
    "        chunk['Delta'] = chunk['Valor'].diff().abs()\n",
    "        chunk['Delta'] = chunk['Delta'].where(mask_consecutivo)\n",
    "\n",
    "        # Máscara para identificar variaciones mayores a 45.0\n",
    "        mask_variacion = chunk['Delta'] > 45.0\n",
    "      \n",
    "        # Etiquetado de valores, se inicia con el Estado Anterior\n",
    "        condicion_0PSO0 = mask_variacion & chunk['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado' - '0PER0'\n",
    "        condicion_0PER0 = mask_variacion & (chunk['Estado'].isnull() | chunk['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk.loc[condicion_0PER0, 'Estado'] = '0PER0'\n",
    "        mask_variacion = mask_variacion & ~condicion_0PER0\n",
    "        # '0PER1'\n",
    "        condicion_0PER1 = mask_variacion & (chunk['Estado'] == '0PER0')\n",
    "        chunk.loc[condicion_0PER1, 'Estado'] = '0PER1'\n",
    "        mask_variacion = mask_variacion & ~condicion_0PER1\n",
    "        # '0PER2'\n",
    "        condicion_0PER2 = mask_variacion & (chunk['Estado'] == '0PER1')\n",
    "        chunk.loc[condicion_0PER2, 'Estado'] = '0PER2'\n",
    "\n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        chunk.drop(columns=['Delta', 'Fecha_anterior', 'Delta_tiempo'], axis=1, inplace=True)\n",
    "\n",
    "        return chunk, mask_variacion\n",
    "\n",
    "    def p_horavmaxmin(self, chunk, archivo):\n",
    "        '''Esta prueba detecta los datos que son máximos y mínimos en horarios distintos a los posibles por la temperatura máxima en el\n",
    "        día según la radiación solar'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "\n",
    "        if chunk['Estado'].notna().all(): # Se verifica que no hayan valores nulos en tal columna\n",
    "            chunk_hmm = chunk[~chunk['Estado'].str.startswith('0PER', na=False)].copy()\n",
    "        else:\n",
    "            # Si todos los valores son NaN, simplemente copia el chunk\n",
    "            chunk_hmm = chunk.copy()\n",
    "            \n",
    "        # Se crean máscaras para los intervalos de tiempo conocidos para valores máximos y mínimos\n",
    "        mask_max_morning = (chunk_hmm['Fecha'].dt.hour >= 0) & (chunk_hmm['Fecha'].dt.hour < 10) \n",
    "        mask_max_afternoon = (chunk_hmm['Fecha'].dt.hour > 17) & (chunk_hmm['Fecha'].dt.hour <= 23)\n",
    "        mask_min_afternoon = (chunk_hmm['Fecha'].dt.hour >= 10) & (chunk_hmm['Fecha'].dt.hour <= 17)\n",
    "        \n",
    "        # Se filtran los datos para esas horas\n",
    "        max_validdata = chunk_hmm[mask_max_morning | mask_max_afternoon]\n",
    "        min_validdata = chunk_hmm[mask_min_afternoon]\n",
    "\n",
    "        # Encontrar dos valores máximos por día\n",
    "        max_values = chunk_hmm.groupby(chunk_hmm['Fecha'].dt.date).apply(lambda x: x.nlargest(2, 'Valor')).reset_index(level=0, drop=True)\n",
    "        \n",
    "        # Encontrar dos valores mínimos por día\n",
    "        min_values = chunk_hmm.groupby(chunk_hmm['Fecha'].dt.date).apply(lambda x: x.nsmallest(2, 'Valor')).reset_index(level=0, drop=True)\n",
    "\n",
    "        # Verificar los máximos y mínimos y obtener las horas correspondientes\n",
    "        notvalid_max_values = max_values[~max_values.index.isin(max_validdata.index)]\n",
    "        notvalid_min_values = min_values[~min_values.index.isin(min_validdata.index)]\n",
    "\n",
    "        # Combinar los valores no válidos en un solo DataFrame\n",
    "        notvalid_values = pd.concat([notvalid_max_values, notvalid_min_values])\n",
    "        # Crear una máscara para identificar los índices de los valores no válidos\n",
    "        notval_maxmin = chunk_hmm.index.isin(notvalid_values.index)\n",
    "\n",
    "        ## Actualización de estado\n",
    "        # Condición llenado de 'Estado_Anterior', si aplica\n",
    "        condicion_0PSO0 = notval_maxmin & chunk_hmm['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk_hmm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hmm.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Se etiquetan los atípicos\n",
    "        condicion_0PAT0 = notval_maxmin & (chunk_hmm['Estado'].isnull() | chunk_hmm['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk_hmm.loc[condicion_0PAT0, 'Estado'] = '0PAT0'\n",
    "\n",
    "        # Se copia al chunk original\n",
    "        chunk.loc[chunk_hmm.index] = chunk_hmm\n",
    "        return chunk, notval_maxmin\n",
    "\n",
    "    def p_sigma(self, chunk, archivo):\n",
    "        '''Esta prueba calcula, con los datos no etiquetados en la anterior prueba, la 4sigmas +- la media para detectar\n",
    "        datos atípicos en los conjuntos de los datos'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "\n",
    "        if chunk['Estado'].notna().all(): # Se verifica que no hayan valores nulos en tal columna\n",
    "            chunk_sgm = chunk[~chunk['Estado'].str.startswith('0PER', na=False)].copy()\n",
    "        else:\n",
    "            # Si todos los valores son NaN, simplemente copia el chunk\n",
    "            chunk_sgm = chunk.copy()\n",
    "\n",
    "        # Se calculan los estadísticos para sigma\n",
    "        mean = chunk_sgm['Valor'].mean()\n",
    "        std = chunk_sgm['Valor'].std()\n",
    "        # Con ellos, se establecen los límites superior e inferior\n",
    "        chunk_sgm['LimSup_Sigma'] = (mean + (4 * std))\n",
    "        chunk_sgm['LimInf_Sigma'] = (mean - (4 * std))\n",
    "\n",
    "        # Se etiquetan los valores que sobrepasen el límite\n",
    "        mask_outbsigma = (chunk_sgm['Valor'] < chunk_sgm['LimInf_Sigma']) | (chunk_sgm['Valor'] > chunk_sgm['LimSup_Sigma'])\n",
    "        \n",
    "        ## Actualización de estado\n",
    "        # Condición llenado de 'Estado_Anterior', si aplica\n",
    "        condicion_0PSO0 = mask_outbsigma & chunk_sgm['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk_sgm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_sgm.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Se etiquetan los atípicos - '0PAT0'\n",
    "        condicion_0PAT0 = mask_outbsigma & (chunk_sgm['Estado'].isnull() | chunk_sgm['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk_sgm.loc[condicion_0PAT0, 'Estado'] = '0PAT0'\n",
    "        mask_outbsigma = mask_outbsigma & ~condicion_0PAT0\n",
    "        # 0PAT1\n",
    "        condicion_0PAT1 = mask_outbsigma & (chunk_sgm['Estado'] == '0PAT0')\n",
    "        chunk_sgm.loc[condicion_0PAT1, 'Estado'] = '0PAT1'\n",
    "        # mask_outbsigma = mask_outbsigma & ~condicion_0PAT1\n",
    "        # # 0PAT2\n",
    "        # condicion_0PAT2 = mask_outbsigma & (chunk_sgm['Estado'] == '0PAT1')\n",
    "        # chunk_sgm.loc[condicion_0PAT2, 'Estado'] = '0PAT2'\n",
    "                    \n",
    "        # Se eliminan las columnas no deseadas\n",
    "        if 'LimSup_Sigma' in chunk.columns:\n",
    "            chunk.drop(columns=['LimSup_Sigma', 'LimInf_Sigma'], axis=1, inplace=True)\n",
    "    \n",
    "        chunk.loc[chunk_sgm.index] = chunk_sgm\n",
    "        return chunk, mask_outbsigma\n",
    "\n",
    "    @log_failures\n",
    "    def p_coherPFvals(self, chunk, archivo):\n",
    "        '''Esta prueba verifica que un valor tenga coherencia con los 5 anteriores según su desviación estándar y media'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None    \n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "            \n",
    "        ## Trabajo con frecuencias\n",
    "        # Se toma nuevamente el archivo de frecuencias para analizar datos estrictamente consecutivos\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1')\n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        sttn_code = chunk['Station'].values[0]\n",
    "        if pd.isna(sttn_code):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == sttn_code]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {sttn_code} en freqinst200b\")\n",
    "                return chunk, None\n",
    "            # Se toma el valor inferido de la frecuencia\n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "            # Si el valor inferido es un NaN, se infiere dentro del código\n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk, None\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk, None\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk, None\n",
    "\n",
    "        ## Se asegura la revisión de 5 datos anteriores aún si cambia el chunk\n",
    "        # Verificar si el archivo ha cambiado\n",
    "        if self.current_file != archivo:\n",
    "            # Si el archivo cambió, resetea self.last_rows y actualiza self.current_file\n",
    "            self.last_rows = None\n",
    "            self.current_file = archivo\n",
    "        # Usar self.last_rows para concatenar con el chunk actual\n",
    "        if self.last_rows is not None:\n",
    "            chunk = pd.concat([self.last_rows, chunk])\n",
    "            chunk.reset_index(drop=True)\n",
    "    \n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "\n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "\n",
    "        # Crear una columna de diferencia temporal\n",
    "        chunk['Fecha_anterior'] = chunk['Fecha'].shift(1)\n",
    "        chunk['Delta_tiempo'] = chunk['Fecha'] - chunk['Fecha_anterior']\n",
    "\n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos\n",
    "        if 'Estado' not in chunk.columns or chunk['Estado'].isnull().all():\n",
    "            chunk_PFvals = chunk.copy()\n",
    "        else:\n",
    "            chunk_PFvals = chunk[~chunk['Estado'].str.startswith(('0PER','0PAT'), na=False)].copy()\n",
    "\n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        mask_consecutivo = chunk_PFvals['Delta_tiempo'] == pd.to_timedelta(periodos)\n",
    "        chunk_PFvals['consec_group'] = (~mask_consecutivo).cumsum()\n",
    "\n",
    "        # Se establecen diferentes ventanas según frecuencias\n",
    "        windows = {'T': {'window': 240}, '5T': {'window': 72}, '10T': {'window': 48}, 'H': {'window': 11}}\n",
    "        window_size = windows[periodos]['window']\n",
    "        half_window = window_size // 2\n",
    "\n",
    "        # Filtrar grupos que tienen al menos el tamaño de ventana necesario\n",
    "        group_counts = chunk_PFvals['consec_group'].value_counts()\n",
    "        valid_groups = group_counts[group_counts >= window_size].index\n",
    "        chnk_cohPFvl = chunk_PFvals[chunk_PFvals['consec_group'].isin(valid_groups)]\n",
    "\n",
    "        # Verificar que los datos anteriores y posteriores sean consecutivos\n",
    "        valid_indices = []\n",
    "        for i in range(half_window, len(chnk_cohPFvl) - half_window):\n",
    "            if all(mask_consecutivo[i-half_window:i+half_window]):\n",
    "                valid_indices.append(chnk_cohPFvl.index[i])\n",
    "\n",
    "        chnk_cohPFvl = chnk_cohPFvl.loc[valid_indices]\n",
    "\n",
    "        # Calcular el promedio y desviación estándar de los registros anteriores y posteriores\n",
    "        chnk_cohPFvl['mean_PF'] = chnk_cohPFvl['Valor'].rolling(window=window_size, center=True).mean()\n",
    "        chnk_cohPFvl['std_PF'] = chnk_cohPFvl['Valor'].rolling(window=window_size, center=True).std()\n",
    "\n",
    "        # Calcular los límites superior e inferior\n",
    "        chnk_cohPFvl['lim_inf'] = chnk_cohPFvl['mean_PF'] - (3 * chnk_cohPFvl['std_PF'])\n",
    "        chnk_cohPFvl['lim_sup'] = chnk_cohPFvl['mean_PF'] + (3 * chnk_cohPFvl['std_PF'])\n",
    "\n",
    "        # Añadir mensajes de depuración para verificar los límites\n",
    "        print(chnk_cohPFvl[['Fecha', 'Valor', 'mean_PF', 'std_PF', 'lim_inf', 'lim_sup']].head(20))\n",
    "\n",
    "        # Máscara para identificar valores fuera de los límites\n",
    "        mask_var5prev = (chnk_cohPFvl['Valor'] < chnk_cohPFvl['lim_inf']) | (chnk_cohPFvl['Valor'] > chnk_cohPFvl['lim_sup'])\n",
    "        \n",
    "        # Añadir mensajes de depuración para verificar los valores fuera de los límites\n",
    "        print(chnk_cohPFvl[mask_var5prev][['Fecha', 'Valor', 'lim_inf', 'lim_sup']])\n",
    "        \n",
    "        # Lógica de etiquetado para 'Estado', sospechoso, '0PSO0'\n",
    "        condicion_0PSO0 = mask_var5prev & (chnk_cohPFvl['Estado'].isnull())\n",
    "        chnk_cohPFvl.loc[condicion_0PSO0, 'Estado'] = '0PSO0'\n",
    "        mask_var5prev = mask_var5prev & ~condicion_0PSO0\n",
    "        # 0PSO1\n",
    "        condicion_0PSO1 = mask_var5prev & (chnk_cohPFvl['Estado'] == '0PSO0')\n",
    "        chnk_cohPFvl.loc[condicion_0PSO1, 'Estado'] = '0PSO1'\n",
    "        mask_var5prev = mask_var5prev & ~condicion_0PSO1\n",
    "        # 0PSO2\n",
    "        condicion_0PSO2 = mask_var5prev & (chnk_cohPFvl['Estado'] == '0PSO1')\n",
    "        chnk_cohPFvl.loc[condicion_0PSO2, 'Estado'] = '0PSO2'\n",
    "    \n",
    "        # Se asegura la verificación de los valores anteriores si hubo cambio de chunk\n",
    "        self.last_rows = chnk_cohPFvl.tail(5)\n",
    "\n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        if 'Fecha_anterior' in chunk.columns:\n",
    "            chunk.drop(columns=['Fecha_anterior','Delta_tiempo'], axis=1, inplace=True)\n",
    "            \n",
    "        # Copiar datos de chunk_coher al chunk original\n",
    "        chunk.loc[chnk_cohPFvl.index] = chnk_cohPFvl\n",
    "        # Continuar eliminando filas\n",
    "        if 'mean_5' in chunk.columns:\n",
    "            chunk.drop(columns=['mean_5','std_5','lim_inf','lim_sup'], axis=1, inplace=True)\n",
    "        \n",
    "        return chunk, mask_var5prev\n",
    "\n",
    "    def p_varminh(self, chunk, archivo):\n",
    "        '''Esta prueba detecta los valores horarios que no varían en 1.0 % durante la hora'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None\n",
    "        # Se genera la columna 'Estado_Anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "    \n",
    "        # Se toma nuevamente el archivo de frecuencias para analizar datos estrictamente consecutivos\n",
    "        freqinst200b = pd.read_csv('EMAHR_Allinfo_Replcbl.csv', encoding='latin-1')\n",
    "    \n",
    "        # Obtener la frecuencia de 'freqinst200b' basado en 'Station' y asignar a 'periodos'\n",
    "        sttn_code = chunk['Station'].values[0]\n",
    "        if pd.isna(sttn_code):\n",
    "            periodos = None\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == sttn_code]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {sttn_code} en freqinst200b\")\n",
    "                return chunk, None\n",
    "            # Se toma el valor inferido de la frecuencia\n",
    "            freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "            # Si el valor inferido es un NaN, se infiere dentro del código\n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return chunk, None\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return chunk, None\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk, None\n",
    "    \n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "    \n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "    \n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos o atípicos\n",
    "        if 'Estado' in chunk.columns and chunk['Estado'].notna().all():\n",
    "            chunk_varhmn = chunk[~chunk['Estado'].str.startswith(('0PER', '0PAT'), na=False)].copy()\n",
    "        else:\n",
    "            chunk_varhmn = chunk.copy()\n",
    "    \n",
    "        # Crear una columna de diferencia temporal y otras columnas temporales\n",
    "        chunk_varhmn['Fecha_anterior'] = chunk_varhmn['Fecha'].shift(1)\n",
    "        chunk_varhmn['Delta_tiempo'] = chunk_varhmn['Fecha'] - chunk_varhmn['Fecha_anterior']\n",
    "    \n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        freq_map = {'H': '1H', 'T': '1T', '5T': '5T', '10T': '10T'}\n",
    "        expected_delta = pd.to_timedelta(freq_map.get(periodos, '1H'))\n",
    "        mask_consecut = chunk_varhmn['Delta_tiempo'] == expected_delta\n",
    "    \n",
    "        # Calcular la diferencia absoluta entre los valores consecutivos\n",
    "        chunk_varhmn['Delta'] = chunk_varhmn['Valor'].diff().abs()\n",
    "        chunk_varhmn['Delta'] = chunk_varhmn['Delta'].where(mask_consecut)\n",
    "    \n",
    "        # Aplicar la máscara de las horas soleadas después de crear las columnas temporales\n",
    "        mask_sunny2 = (chunk_varhmn['Fecha'].dt.hour >= 6) & (chunk_varhmn['Fecha'].dt.hour <= 18)\n",
    "        mask_sun2 = chunk_varhmn[mask_sunny2]\n",
    "    \n",
    "        if periodos == 'H':\n",
    "            # Máscara para identificar variaciones menores a 1.0\n",
    "            mask_varhmin = mask_sun2['Delta'] < 1.0\n",
    "        else:\n",
    "            # Agrupar por horas y verificar si alguna variación dentro de la hora excede 1.0\n",
    "            mask_sun2['Fecha_hora'] = mask_sun2['Fecha'].dt.floor('H')\n",
    "            hora_groups = mask_sun2.groupby('Fecha_hora')\n",
    "            mask_varhmin = hora_groups['Delta'].transform(lambda x: (x < 1.0).any())\n",
    "            \n",
    "        # Lógica de etiquetado para 'Estado', sospechoso, '0PSO0'\n",
    "        condicion_0PSO0 = mask_varhmin & (mask_sun2['Estado'].isnull())\n",
    "        mask_sun2.loc[condicion_0PSO0, 'Estado'] = '0PSO0'\n",
    "        mask_varhmin = mask_varhmin & ~condicion_0PSO0\n",
    "        # 0PSO1\n",
    "        condicion_0PSO1 = mask_varhmin & (mask_sun2['Estado'] == '0PSO0')\n",
    "        mask_sun2.loc[condicion_0PSO1, 'Estado'] = '0PSO1'\n",
    "        mask_varhmin = mask_varhmin & ~condicion_0PSO1\n",
    "        # 0PSO2\n",
    "        condicion_0PSO2 = mask_varhmin & (mask_sun2['Estado'] == '0PSO1')\n",
    "        mask_sun2.loc[condicion_0PSO2, 'Estado'] = '0PSO2'\n",
    "        mask_varhmin = mask_varhmin & ~condicion_0PSO2\n",
    "        # 0PSO2\n",
    "        condicion_0PSO3 = mask_varhmin & (mask_sun2['Estado'] == '0PSO2')\n",
    "        mask_sun2.loc[condicion_0PSO3, 'Estado'] = '0PSO3'\n",
    "    \n",
    "        # Copiar datos de chunk_jmp al chunk original\n",
    "        chunk.loc[mask_sun2.index] = mask_sun2\n",
    "    \n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        columns_to_drop = ['Delta', 'Fecha_anterior', 'Delta_tiempo', 'Fecha_hora']\n",
    "        columns_to_drop = [col for col in columns_to_drop if col in chunk.columns]\n",
    "        chunk.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "        return chunk, mask_varhmin\n",
    "\n",
    "    def procesar_archivos(self, funcion_evaluacion):\n",
    "        '''Este método procesa la lectura y guardado de los archivos para todas las pruebas'''\n",
    "        archivos = self.ruta_archivos\n",
    "\n",
    "        archivos_salida = []  # Lista para almacenar nombres de archivos de salida\n",
    "\n",
    "        # Se recorre cada archivo en la carpeta\n",
    "        for archivo in archivos:\n",
    "            if archivo.endswith('.csv'):\n",
    "                ruta_archivo = os.path.join(self.dir_files, archivo)\n",
    "\n",
    "                reader = pd.read_csv(ruta_archivo, encoding='latin-1', chunksize=self.chunk_size)#,dtype={7: 'str'}, low_memory=False)\n",
    "                resultados = []\n",
    "\n",
    "                for chunk in reader:\n",
    "                    try:\n",
    "                        chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                    except ValueError:\n",
    "                        chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                    chunk['Station'] = chunk['Station'].astype('int64')\n",
    "                    try:\n",
    "                        chunk_resultado, _ = funcion_evaluacion(chunk, archivo)  # Desempaqueta solo el DataFrame\n",
    "                    except ValueError:\n",
    "                        chunk_resultado = funcion_evaluacion(chunk, archivo)  # Desempaqueta solo el DataFrame\n",
    "                    resultados.append(chunk_resultado)\n",
    "\n",
    "                if not resultados:  # Se verifica si la lista está vacía\n",
    "                    self.logger.warning('No hay resultados válidos para concatenar en el archivo %s. Continuando con el siguiente archivo.', archivo)\n",
    "                    continue\n",
    "                    \n",
    "                resultados_consolidados = pd.concat(resultados)\n",
    "\n",
    "                # Genera el nombre del archivo de salida conservando los primeros 19 caracteres del nombre del archivo original\n",
    "                nombre_archivo_salida = archivo[:19] + '_qc.csv'\n",
    "\n",
    "                resultados_consolidados.to_csv(os.path.join(self.dir_files, nombre_archivo_salida), encoding='latin-1', index=False)\n",
    "\n",
    "                archivos_salida.append(nombre_archivo_salida)  # Agregar el nombre del archivo a la lista\n",
    "            \n",
    "        # Actualiza self.ruta_archivos para que la próxima prueba procese los resultados de esta prueba\n",
    "        self.ruta_archivos = archivos_salida\n",
    "        # Se fija el log de procesamiento completo de archivos\n",
    "        self.logger.info('Procesamiento completo de archivos de estaciones HR. Archivos generados: %s', archivos_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f92b9d-0c3a-4652-aa4b-f41a66ab8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador = AutomatHREMA('Test_QC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4348e0-435a-4f34-ad20-e1d5d8da9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0PSO0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk['Fecha'].dt.floor('H') == row['Fecha'].floor('H'), 'Estado'] = '0PSO0'\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_transm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2d470b-c286-4289-90e5-8d9148c65a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_estruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c17071-31e8-4484-9ae9-7ce1af648709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9636\\71176568.py:174: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_limrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ea10b68-a8cb-4b67-b977-65d83029a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8248\\2349811916.py:224: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 54004 but corresponding boolean dimension is 54028",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 670\u001b[0m, in \u001b[0;36mAutomatHREMA.procesar_archivos\u001b[1;34m(self, funcion_evaluacion)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     chunk_resultado, _ \u001b[38;5;241m=\u001b[39m funcion_evaluacion(chunk, archivo)  \u001b[38;5;66;03m# Desempaqueta solo el DataFrame\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m procesador\u001b[38;5;241m.\u001b[39mprocesar_archivos(procesador\u001b[38;5;241m.\u001b[39mp_persist)\n",
      "Cell \u001b[1;32mIn[15], line 672\u001b[0m, in \u001b[0;36mAutomatHREMA.procesar_archivos\u001b[1;34m(self, funcion_evaluacion)\u001b[0m\n\u001b[0;32m    670\u001b[0m         chunk_resultado, _ \u001b[38;5;241m=\u001b[39m funcion_evaluacion(chunk, archivo)  \u001b[38;5;66;03m# Desempaqueta solo el DataFrame\u001b[39;00m\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 672\u001b[0m         chunk_resultado \u001b[38;5;241m=\u001b[39m funcion_evaluacion(chunk, archivo)  \u001b[38;5;66;03m# Desempaqueta solo el DataFrame\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     resultados\u001b[38;5;241m.\u001b[39mappend(chunk_resultado)\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resultados:  \u001b[38;5;66;03m# Se verifica si la lista está vacía\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m, in \u001b[0;36mlog_failures.<locals>.wrapper\u001b[1;34m(self, chunk, archivo)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk, archivo):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m         result, mask \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, chunk, archivo)\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[15], line 224\u001b[0m, in \u001b[0;36mAutomatHREMA.p_persist\u001b[1;34m(self, chunk, archivo)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Etiquetado de valores, se inicia con el Estado Anterior\u001b[39;00m\n\u001b[0;32m    223\u001b[0m condicion_0PSO0 \u001b[38;5;241m=\u001b[39m mask_pers4datos \u001b[38;5;241m&\u001b[39m chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstado\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0PSO0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0PSO1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 224\u001b[0m chunk\u001b[38;5;241m.\u001b[39mloc[condicion_0PSO0, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstado_Anterior\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mloc[condicion_0PSO0, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstado\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# Lógica de etiquetado para 'Estado'\u001b[39;00m\n\u001b[0;32m    227\u001b[0m condicion_0PER0 \u001b[38;5;241m=\u001b[39m mask_pers4datos \u001b[38;5;241m&\u001b[39m (chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstado\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull() \u001b[38;5;241m|\u001b[39m chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstado\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0PSO0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0PSO1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:885\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    884\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 885\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1893\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1892\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1914\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(value, ABCSeries) \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1912\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[1;32m-> 1914\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_series(indexer, Series(value))\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;66;03m# Ensure we have something we can iterate over\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m info_axis \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:2330\u001b[0m, in \u001b[0;36m_iLocIndexer._align_series\u001b[1;34m(self, indexer, ser, multiindex_indexer, using_cow)\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_aligner \u001b[38;5;129;01mand\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(idx):\n\u001b[0;32m   2329\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 2330\u001b[0m new_ix \u001b[38;5;241m=\u001b[39m ax[idx]\n\u001b[0;32m   2331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like_indexer(new_ix):\n\u001b[0;32m   2332\u001b[0m     new_ix \u001b[38;5;241m=\u001b[39m Index([new_ix])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5383\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5380\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5381\u001b[0m         key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m-> 5383\u001b[0m result \u001b[38;5;241m=\u001b[39m getitem(key)\n\u001b[0;32m   5384\u001b[0m \u001b[38;5;66;03m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[0;32m   5385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 54004 but corresponding boolean dimension is 54028"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_persist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b8d2a-8da3-4629-8884-bdc299e12d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_salto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcc6e5-8bee-4f94-9d04-14d4dd4d97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_horavmaxmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca86b59-71b3-4471-87b3-150eb60eae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d3f1d7-4219-42d7-b574-e61723082392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Fecha  Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2016-06-02 17:40:00   90.0      NaN     NaN      NaN      NaN\n",
      "38 2016-06-02 17:45:00   90.0      NaN     NaN      NaN      NaN\n",
      "39 2016-06-02 17:50:00   89.0      NaN     NaN      NaN      NaN\n",
      "40 2016-06-02 17:55:00   89.0      NaN     NaN      NaN      NaN\n",
      "41 2016-06-02 18:00:00   89.0      NaN     NaN      NaN      NaN\n",
      "42 2016-06-02 18:05:00   90.0      NaN     NaN      NaN      NaN\n",
      "43 2016-06-02 18:10:00   90.0      NaN     NaN      NaN      NaN\n",
      "44 2016-06-02 18:15:00   91.0      NaN     NaN      NaN      NaN\n",
      "45 2016-06-02 18:20:00   91.0      NaN     NaN      NaN      NaN\n",
      "46 2016-06-02 18:25:00   92.0      NaN     NaN      NaN      NaN\n",
      "47 2016-06-02 18:30:00   92.0      NaN     NaN      NaN      NaN\n",
      "48 2016-06-02 18:35:00   92.0      NaN     NaN      NaN      NaN\n",
      "49 2016-06-02 18:40:00   93.0      NaN     NaN      NaN      NaN\n",
      "50 2016-06-02 18:45:00   93.0      NaN     NaN      NaN      NaN\n",
      "51 2016-06-02 18:50:00   93.0      NaN     NaN      NaN      NaN\n",
      "52 2016-06-02 18:55:00   93.0      NaN     NaN      NaN      NaN\n",
      "53 2016-06-02 19:00:00   93.0      NaN     NaN      NaN      NaN\n",
      "54 2016-06-02 19:05:00   93.0      NaN     NaN      NaN      NaN\n",
      "55 2016-06-02 19:10:00   93.0      NaN     NaN      NaN      NaN\n",
      "56 2016-06-02 19:15:00   93.0      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "12734 2016-07-20 12:40:00  48.00000  54.202448   82.964219\n",
      "12735 2016-07-20 12:45:00  51.00000  54.202448   82.964219\n",
      "13738 2016-07-24 00:20:00  93.00000  93.073159   97.121285\n",
      "13739 2016-07-24 00:25:00  93.00000  93.073159   97.121285\n",
      "13740 2016-07-24 00:30:00  93.00000  93.073159   97.121285\n",
      "14243 2016-07-25 21:50:00  69.00000  72.307528  104.720250\n",
      "14244 2016-07-25 21:55:00  67.00000  72.299407  104.617260\n",
      "14245 2016-07-25 22:00:00  70.00000  72.272237  104.505541\n",
      "14246 2016-07-25 22:05:00  72.00000  72.247916  104.390973\n",
      "15698 2016-07-30 23:05:00  89.00000  89.017267   97.843844\n",
      "19704 2016-08-13 22:25:00  87.00000  87.519341   98.008437\n",
      "19705 2016-08-13 22:30:00  87.00000  87.455433   98.016789\n",
      "27846 2016-09-13 02:55:00  88.00000  88.635112   98.170443\n",
      "32107 2016-09-27 22:00:00  88.00000  88.440534   97.559466\n",
      "32108 2016-09-27 22:05:00  87.00000  88.525849   97.557484\n",
      "39424 2017-03-12 01:45:00  93.00000  93.006971   97.937474\n",
      "43439 2017-05-12 02:15:00  92.00000  92.183843   97.621712\n",
      "49130 2017-05-31 22:30:00  91.11504  91.536854   97.301495\n",
      "49131 2017-05-31 22:35:00  91.23460  91.512300   97.351466\n",
      "                 Fecha  Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2016-06-02 17:40:00   90.0      NaN     NaN      NaN      NaN\n",
      "38 2016-06-02 17:45:00   90.0      NaN     NaN      NaN      NaN\n",
      "39 2016-06-02 17:50:00   89.0      NaN     NaN      NaN      NaN\n",
      "40 2016-06-02 17:55:00   89.0      NaN     NaN      NaN      NaN\n",
      "41 2016-06-02 18:00:00   89.0      NaN     NaN      NaN      NaN\n",
      "42 2016-06-02 18:05:00   90.0      NaN     NaN      NaN      NaN\n",
      "43 2016-06-02 18:10:00   90.0      NaN     NaN      NaN      NaN\n",
      "44 2016-06-02 18:15:00   91.0      NaN     NaN      NaN      NaN\n",
      "45 2016-06-02 18:20:00   91.0      NaN     NaN      NaN      NaN\n",
      "46 2016-06-02 18:25:00   92.0      NaN     NaN      NaN      NaN\n",
      "47 2016-06-02 18:30:00   92.0      NaN     NaN      NaN      NaN\n",
      "48 2016-06-02 18:35:00   92.0      NaN     NaN      NaN      NaN\n",
      "49 2016-06-02 18:40:00   93.0      NaN     NaN      NaN      NaN\n",
      "50 2016-06-02 18:45:00   93.0      NaN     NaN      NaN      NaN\n",
      "51 2016-06-02 18:50:00   93.0      NaN     NaN      NaN      NaN\n",
      "52 2016-06-02 18:55:00   93.0      NaN     NaN      NaN      NaN\n",
      "53 2016-06-02 19:00:00   93.0      NaN     NaN      NaN      NaN\n",
      "54 2016-06-02 19:05:00   93.0      NaN     NaN      NaN      NaN\n",
      "55 2016-06-02 19:10:00   93.0      NaN     NaN      NaN      NaN\n",
      "56 2016-06-02 19:15:00   93.0      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "12734 2016-07-20 12:40:00  48.00000  54.202448   82.964219\n",
      "12735 2016-07-20 12:45:00  51.00000  54.202448   82.964219\n",
      "13738 2016-07-24 00:20:00  93.00000  93.073159   97.121285\n",
      "13739 2016-07-24 00:25:00  93.00000  93.073159   97.121285\n",
      "13740 2016-07-24 00:30:00  93.00000  93.073159   97.121285\n",
      "14243 2016-07-25 21:50:00  69.00000  72.307528  104.720250\n",
      "14244 2016-07-25 21:55:00  67.00000  72.299407  104.617260\n",
      "14245 2016-07-25 22:00:00  70.00000  72.272237  104.505541\n",
      "14246 2016-07-25 22:05:00  72.00000  72.247916  104.390973\n",
      "15698 2016-07-30 23:05:00  89.00000  89.017267   97.843844\n",
      "19704 2016-08-13 22:25:00  87.00000  87.519341   98.008437\n",
      "19705 2016-08-13 22:30:00  87.00000  87.455433   98.016789\n",
      "27846 2016-09-13 02:55:00  88.00000  88.635112   98.170443\n",
      "32107 2016-09-27 22:00:00  88.00000  88.440534   97.559466\n",
      "32108 2016-09-27 22:05:00  87.00000  88.525849   97.557484\n",
      "39424 2017-03-12 01:45:00  93.00000  93.006971   97.937474\n",
      "43439 2017-05-12 02:15:00  92.00000  92.183843   97.621712\n",
      "49130 2017-05-31 22:30:00  91.11504  91.536854   97.301495\n",
      "49131 2017-05-31 22:35:00  91.23460  91.512300   97.351466\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47 2017-06-18 15:25:00  82.39756      NaN     NaN      NaN      NaN\n",
      "48 2017-06-18 15:30:00  83.91421      NaN     NaN      NaN      NaN\n",
      "49 2017-06-18 15:35:00  84.01986      NaN     NaN      NaN      NaN\n",
      "50 2017-06-18 15:40:00  83.49125      NaN     NaN      NaN      NaN\n",
      "51 2017-06-18 15:45:00  83.08217      NaN     NaN      NaN      NaN\n",
      "52 2017-06-18 15:50:00  82.21972      NaN     NaN      NaN      NaN\n",
      "53 2017-06-18 15:55:00  81.30480      NaN     NaN      NaN      NaN\n",
      "54 2017-06-18 16:00:00  81.38290      NaN     NaN      NaN      NaN\n",
      "55 2017-06-18 16:05:00  81.72632      NaN     NaN      NaN      NaN\n",
      "56 2017-06-18 16:10:00  81.30973      NaN     NaN      NaN      NaN\n",
      "57 2017-06-18 16:15:00  80.58915      NaN     NaN      NaN      NaN\n",
      "58 2017-06-18 16:20:00  80.40736      NaN     NaN      NaN      NaN\n",
      "59 2017-06-18 16:25:00  81.06331      NaN     NaN      NaN      NaN\n",
      "60 2017-06-18 16:30:00  80.78371      NaN     NaN      NaN      NaN\n",
      "61 2017-06-18 16:35:00  80.82573      NaN     NaN      NaN      NaN\n",
      "62 2017-06-18 16:40:00  81.68697      NaN     NaN      NaN      NaN\n",
      "63 2017-06-18 16:45:00  82.20377      NaN     NaN      NaN      NaN\n",
      "64 2017-06-18 16:50:00  82.10920      NaN     NaN      NaN      NaN\n",
      "65 2017-06-18 16:55:00  82.75938      NaN     NaN      NaN      NaN\n",
      "66 2017-06-18 17:00:00  83.18204      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "4077  2017-07-02 15:15:00  76.02529  76.172635   95.941784\n",
      "15666 2017-08-18 00:10:00  78.32793  79.222266  102.031473\n",
      "20363 2017-09-04 02:10:00  88.93796  89.105144   97.478277\n",
      "26391 2017-09-25 00:30:00  91.82584  91.840476  100.090497\n",
      "26392 2017-09-25 00:35:00  91.52583  91.839617  100.066017\n",
      "27813 2017-09-29 23:00:00  93.23377  93.753714   98.089661\n",
      "27814 2017-09-29 23:05:00  93.66039  93.964645   97.948104\n",
      "35842 2017-10-28 01:00:00  91.95236  92.045902   97.474262\n",
      "37076 2017-11-02 23:50:00  92.29080  92.302222   97.979973\n",
      "40008 2017-11-13 06:00:00  95.53233  95.616677   98.427187\n",
      "40009 2017-11-13 06:05:00  95.47453  95.616276   98.421735\n",
      "40843 2017-11-18 21:05:00  96.50921  96.538114   97.579166\n",
      "44073 2017-11-30 02:15:00  95.80400  95.945663   98.705773\n",
      "46988 2017-12-10 21:35:00  94.82302  95.003934   97.535454\n",
      "47277 2017-12-11 21:40:00  94.66200  94.694870   98.989933\n",
      "47278 2017-12-11 21:45:00  94.68008  94.774551   98.964080\n",
      "52015 2018-01-01 03:00:00  95.72587  95.899101   98.314191\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2017-06-18 15:00:00  80.92006      NaN     NaN      NaN      NaN\n",
      "38 2017-06-18 15:05:00  77.51939      NaN     NaN      NaN      NaN\n",
      "39 2017-06-18 15:10:00  75.66967      NaN     NaN      NaN      NaN\n",
      "40 2017-06-18 15:15:00  77.52244      NaN     NaN      NaN      NaN\n",
      "41 2017-06-18 15:20:00  81.40794      NaN     NaN      NaN      NaN\n",
      "42 2017-06-18 15:25:00  82.39756      NaN     NaN      NaN      NaN\n",
      "43 2017-06-18 15:30:00  83.91421      NaN     NaN      NaN      NaN\n",
      "44 2017-06-18 15:35:00  84.01986      NaN     NaN      NaN      NaN\n",
      "45 2017-06-18 15:40:00  83.49125      NaN     NaN      NaN      NaN\n",
      "46 2017-06-18 15:45:00  83.08217      NaN     NaN      NaN      NaN\n",
      "47 2017-06-18 15:50:00  82.21972      NaN     NaN      NaN      NaN\n",
      "48 2017-06-18 15:55:00  81.30480      NaN     NaN      NaN      NaN\n",
      "49 2017-06-18 16:00:00  81.38290      NaN     NaN      NaN      NaN\n",
      "50 2017-06-18 16:05:00  81.72632      NaN     NaN      NaN      NaN\n",
      "51 2017-06-18 16:10:00  81.30973      NaN     NaN      NaN      NaN\n",
      "52 2017-06-18 16:15:00  80.58915      NaN     NaN      NaN      NaN\n",
      "53 2017-06-18 16:20:00  80.40736      NaN     NaN      NaN      NaN\n",
      "54 2017-06-18 16:25:00  81.06331      NaN     NaN      NaN      NaN\n",
      "55 2017-06-18 16:30:00  80.78371      NaN     NaN      NaN      NaN\n",
      "56 2017-06-18 16:35:00  80.82573      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "4072  2017-07-02 15:15:00  76.02529  76.172635   95.941784\n",
      "15661 2017-08-18 00:10:00  78.32793  79.222266  102.031473\n",
      "20358 2017-09-04 02:10:00  88.93796  89.105144   97.478277\n",
      "26386 2017-09-25 00:30:00  91.82584  91.840476  100.090497\n",
      "26387 2017-09-25 00:35:00  91.52583  91.839617  100.066017\n",
      "27808 2017-09-29 23:00:00  93.23377  93.753714   98.089661\n",
      "27809 2017-09-29 23:05:00  93.66039  93.964645   97.948104\n",
      "35837 2017-10-28 01:00:00  91.95236  92.045902   97.474262\n",
      "37071 2017-11-02 23:50:00  92.29080  92.302222   97.979973\n",
      "40003 2017-11-13 06:00:00  95.53233  95.616677   98.427187\n",
      "40004 2017-11-13 06:05:00  95.47453  95.616276   98.421735\n",
      "40838 2017-11-18 21:05:00  96.50921  96.538114   97.579166\n",
      "44068 2017-11-30 02:15:00  95.80400  95.945663   98.705773\n",
      "46983 2017-12-10 21:35:00  94.82302  95.003934   97.535454\n",
      "47272 2017-12-11 21:40:00  94.66200  94.694870   98.989933\n",
      "47273 2017-12-11 21:45:00  94.68008  94.774551   98.964080\n",
      "52010 2018-01-01 03:00:00  95.72587  95.899101   98.314191\n",
      "                  Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47  2018-01-09 07:30:00  98.55269      NaN     NaN      NaN      NaN\n",
      "48  2018-01-09 07:35:00  98.59152      NaN     NaN      NaN      NaN\n",
      "49  2018-01-09 07:40:00  98.68781      NaN     NaN      NaN      NaN\n",
      "50  2018-01-09 07:45:00  98.58768      NaN     NaN      NaN      NaN\n",
      "51  2018-01-09 07:50:00  98.30529      NaN     NaN      NaN      NaN\n",
      "318 2018-01-11 00:55:00  96.33347      NaN     NaN      NaN      NaN\n",
      "319 2018-01-11 01:00:00  96.30241      NaN     NaN      NaN      NaN\n",
      "320 2018-01-11 01:05:00  96.25668      NaN     NaN      NaN      NaN\n",
      "321 2018-01-11 01:10:00  96.07484      NaN     NaN      NaN      NaN\n",
      "322 2018-01-11 01:15:00  96.00935      NaN     NaN      NaN      NaN\n",
      "323 2018-01-11 01:20:00  96.08897      NaN     NaN      NaN      NaN\n",
      "324 2018-01-11 01:25:00  96.12511      NaN     NaN      NaN      NaN\n",
      "325 2018-01-11 01:30:00  96.10421      NaN     NaN      NaN      NaN\n",
      "326 2018-01-11 01:35:00  96.10252      NaN     NaN      NaN      NaN\n",
      "327 2018-01-11 01:40:00  96.10421      NaN     NaN      NaN      NaN\n",
      "328 2018-01-11 01:45:00  95.99522      NaN     NaN      NaN      NaN\n",
      "329 2018-01-11 01:50:00  95.94836      NaN     NaN      NaN      NaN\n",
      "330 2018-01-11 01:55:00  95.71006      NaN     NaN      NaN      NaN\n",
      "331 2018-01-11 02:00:00  95.35600      NaN     NaN      NaN      NaN\n",
      "332 2018-01-11 02:05:00  95.11433      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "2113  2018-01-18 12:35:00  69.30071  69.560217   90.252106\n",
      "4436  2018-01-28 03:10:00  94.71740  94.766763   97.432660\n",
      "4437  2018-01-28 03:15:00  94.43098  94.764146   97.442400\n",
      "4778  2018-01-29 07:40:00  85.96783 -41.385840   53.969677\n",
      "8820  2018-02-17 03:20:00  96.40172  96.505955   98.574478\n",
      "16366 2018-03-21 01:55:00  82.50887  84.630087  102.445942\n",
      "16367 2018-03-21 02:00:00  84.00020  84.635848  102.474821\n",
      "18949 2018-04-02 04:30:00  94.58416  94.615447   98.596688\n",
      "24539 2018-06-17 10:55:00  52.21367  52.551802   79.066530\n",
      "31242 2018-07-12 12:15:00  94.69814  32.567505   89.785665\n",
      "33164 2018-07-20 10:30:00  64.07980  65.888013  104.096663\n",
      "                  Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37  2018-01-09 07:05:00  98.61607      NaN     NaN      NaN      NaN\n",
      "38  2018-01-09 07:10:00  98.59040      NaN     NaN      NaN      NaN\n",
      "39  2018-01-09 07:15:00  98.57408      NaN     NaN      NaN      NaN\n",
      "40  2018-01-09 07:20:00  98.61356      NaN     NaN      NaN      NaN\n",
      "41  2018-01-09 07:25:00  98.58091      NaN     NaN      NaN      NaN\n",
      "308 2018-01-11 00:30:00  96.84734      NaN     NaN      NaN      NaN\n",
      "309 2018-01-11 00:35:00  96.98399      NaN     NaN      NaN      NaN\n",
      "310 2018-01-11 00:40:00  96.89986      NaN     NaN      NaN      NaN\n",
      "311 2018-01-11 00:45:00  96.66776      NaN     NaN      NaN      NaN\n",
      "312 2018-01-11 00:50:00  96.37922      NaN     NaN      NaN      NaN\n",
      "313 2018-01-11 00:55:00  96.33347      NaN     NaN      NaN      NaN\n",
      "314 2018-01-11 01:00:00  96.30241      NaN     NaN      NaN      NaN\n",
      "315 2018-01-11 01:05:00  96.25668      NaN     NaN      NaN      NaN\n",
      "316 2018-01-11 01:10:00  96.07484      NaN     NaN      NaN      NaN\n",
      "317 2018-01-11 01:15:00  96.00935      NaN     NaN      NaN      NaN\n",
      "318 2018-01-11 01:20:00  96.08897      NaN     NaN      NaN      NaN\n",
      "319 2018-01-11 01:25:00  96.12511      NaN     NaN      NaN      NaN\n",
      "320 2018-01-11 01:30:00  96.10421      NaN     NaN      NaN      NaN\n",
      "321 2018-01-11 01:35:00  96.10252      NaN     NaN      NaN      NaN\n",
      "322 2018-01-11 01:40:00  96.10421      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "2108  2018-01-18 12:35:00  69.30071  69.560217   90.252106\n",
      "4431  2018-01-28 03:10:00  94.71740  94.766763   97.432660\n",
      "4432  2018-01-28 03:15:00  94.43098  94.764146   97.442400\n",
      "4773  2018-01-29 07:40:00  85.96783 -41.385840   53.969677\n",
      "8815  2018-02-17 03:20:00  96.40172  96.505955   98.574478\n",
      "12984 2018-03-08 11:05:00  56.11774  57.885322   92.361847\n",
      "16361 2018-03-21 01:55:00  82.50887  84.630087  102.445942\n",
      "16362 2018-03-21 02:00:00  84.00020  84.635848  102.474821\n",
      "18490 2018-03-31 13:40:00  74.43049  75.012701  102.716681\n",
      "18491 2018-03-31 13:45:00  74.04713  74.980663  102.776587\n",
      "18944 2018-04-02 04:30:00  94.58416  94.615447   98.596688\n",
      "24534 2018-06-17 10:55:00  52.21367  52.551802   79.066530\n",
      "31237 2018-07-12 12:15:00  94.69814  32.567505   89.785665\n",
      "33159 2018-07-20 10:30:00  64.07980  65.888013  104.096663\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47 2019-02-12 18:40:00  92.78879      NaN     NaN      NaN      NaN\n",
      "48 2019-02-12 18:45:00  93.12980      NaN     NaN      NaN      NaN\n",
      "49 2019-02-12 18:50:00  93.76826      NaN     NaN      NaN      NaN\n",
      "50 2019-02-12 18:55:00  94.18401      NaN     NaN      NaN      NaN\n",
      "51 2019-02-12 19:00:00  94.68588      NaN     NaN      NaN      NaN\n",
      "52 2019-02-12 19:05:00  94.84859      NaN     NaN      NaN      NaN\n",
      "53 2019-02-12 19:10:00  94.95536      NaN     NaN      NaN      NaN\n",
      "54 2019-02-12 19:15:00  94.94234      NaN     NaN      NaN      NaN\n",
      "55 2019-02-12 19:20:00  95.08372      NaN     NaN      NaN      NaN\n",
      "56 2019-02-12 19:25:00  94.89548      NaN     NaN      NaN      NaN\n",
      "57 2019-02-12 19:30:00  94.72505      NaN     NaN      NaN      NaN\n",
      "58 2019-02-12 19:35:00  94.38140      NaN     NaN      NaN      NaN\n",
      "59 2019-02-12 19:40:00  94.09448      NaN     NaN      NaN      NaN\n",
      "60 2019-02-12 19:45:00  93.72652      NaN     NaN      NaN      NaN\n",
      "61 2019-02-12 19:50:00  93.59549      NaN     NaN      NaN      NaN\n",
      "62 2019-02-12 19:55:00  93.45004      NaN     NaN      NaN      NaN\n",
      "63 2019-02-12 20:00:00  93.59640      NaN     NaN      NaN      NaN\n",
      "64 2019-02-12 20:05:00  93.57555      NaN     NaN      NaN      NaN\n",
      "65 2019-02-12 20:10:00  94.28536      NaN     NaN      NaN      NaN\n",
      "66 2019-02-12 20:15:00  94.89805      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "3032  2019-02-23 03:40:00  87.49644  88.145783  103.100445\n",
      "3033  2019-02-23 03:45:00  87.65575  88.143069  103.109232\n",
      "5981  2019-03-05 13:55:00  71.93154  79.333808  107.950796\n",
      "8654  2019-03-15 04:15:00  93.91840  93.944551  100.904331\n",
      "8655  2019-03-15 04:20:00  93.52114  93.941131  100.882773\n",
      "16824 2019-04-17 04:10:00  92.60429  93.379231   99.752167\n",
      "16825 2019-04-17 04:15:00  93.22093  93.378799   99.753288\n",
      "18504 2019-04-23 00:10:00  91.95232  91.973416   98.482240\n",
      "24144 2019-05-14 00:05:00  89.20821  89.687127  102.946193\n",
      "24145 2019-05-14 00:10:00  87.98470  89.272216  103.193474\n",
      "35411 2019-07-13 23:10:00  87.66257  89.734035  102.416567\n",
      "39161 2019-07-26 23:40:00  92.08800  92.479571  103.249863\n",
      "40023 2019-07-29 23:30:00  90.76329  91.144754  103.380255\n",
      "44334 2019-08-13 22:45:00  91.41065  91.861723  101.880892\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2019-02-12 18:15:00  90.35434      NaN     NaN      NaN      NaN\n",
      "38 2019-02-12 18:20:00  90.72273      NaN     NaN      NaN      NaN\n",
      "39 2019-02-12 18:25:00  91.16561      NaN     NaN      NaN      NaN\n",
      "40 2019-02-12 18:30:00  91.56808      NaN     NaN      NaN      NaN\n",
      "41 2019-02-12 18:35:00  92.35825      NaN     NaN      NaN      NaN\n",
      "42 2019-02-12 18:40:00  92.78879      NaN     NaN      NaN      NaN\n",
      "43 2019-02-12 18:45:00  93.12980      NaN     NaN      NaN      NaN\n",
      "44 2019-02-12 18:50:00  93.76826      NaN     NaN      NaN      NaN\n",
      "45 2019-02-12 18:55:00  94.18401      NaN     NaN      NaN      NaN\n",
      "46 2019-02-12 19:00:00  94.68588      NaN     NaN      NaN      NaN\n",
      "47 2019-02-12 19:05:00  94.84859      NaN     NaN      NaN      NaN\n",
      "48 2019-02-12 19:10:00  94.95536      NaN     NaN      NaN      NaN\n",
      "49 2019-02-12 19:15:00  94.94234      NaN     NaN      NaN      NaN\n",
      "50 2019-02-12 19:20:00  95.08372      NaN     NaN      NaN      NaN\n",
      "51 2019-02-12 19:25:00  94.89548      NaN     NaN      NaN      NaN\n",
      "52 2019-02-12 19:30:00  94.72505      NaN     NaN      NaN      NaN\n",
      "53 2019-02-12 19:35:00  94.38140      NaN     NaN      NaN      NaN\n",
      "54 2019-02-12 19:40:00  94.09448      NaN     NaN      NaN      NaN\n",
      "55 2019-02-12 19:45:00  93.72652      NaN     NaN      NaN      NaN\n",
      "56 2019-02-12 19:50:00  93.59549      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "3027  2019-02-23 03:40:00  87.49644  88.145783  103.100445\n",
      "3028  2019-02-23 03:45:00  87.65575  88.143069  103.109232\n",
      "5971  2019-03-05 13:30:00  70.43326  79.353507  108.323624\n",
      "8649  2019-03-15 04:15:00  93.91840  93.944551  100.904331\n",
      "8650  2019-03-15 04:20:00  93.52114  93.941131  100.882773\n",
      "11326 2019-03-24 11:20:00  95.27927  66.970113   94.948530\n",
      "11327 2019-03-24 11:25:00  96.25547  67.039842   94.762305\n",
      "11328 2019-03-24 11:30:00  96.47110  67.133974   94.535270\n",
      "16819 2019-04-17 04:10:00  92.60429  93.379231   99.752167\n",
      "16820 2019-04-17 04:15:00  93.22093  93.378799   99.753288\n",
      "18499 2019-04-23 00:10:00  91.95232  91.973416   98.482240\n",
      "24139 2019-05-14 00:05:00  89.20821  89.687127  102.946193\n",
      "24140 2019-05-14 00:10:00  87.98470  89.272216  103.193474\n",
      "35406 2019-07-13 23:10:00  87.66257  89.734035  102.416567\n",
      "39156 2019-07-26 23:40:00  92.08800  92.479571  103.249863\n",
      "40018 2019-07-29 23:30:00  90.76329  91.144754  103.380255\n",
      "44329 2019-08-13 22:45:00  91.41065  91.861723  101.880892\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47 2019-09-17 11:05:00  72.73698      NaN     NaN      NaN      NaN\n",
      "48 2019-09-17 11:10:00  74.02856      NaN     NaN      NaN      NaN\n",
      "49 2019-09-17 11:15:00  74.46848      NaN     NaN      NaN      NaN\n",
      "50 2019-09-17 11:20:00  72.73234      NaN     NaN      NaN      NaN\n",
      "51 2019-09-17 11:25:00  71.69755      NaN     NaN      NaN      NaN\n",
      "52 2019-09-17 11:30:00  74.18398      NaN     NaN      NaN      NaN\n",
      "53 2019-09-17 11:35:00  76.20725      NaN     NaN      NaN      NaN\n",
      "54 2019-09-17 11:40:00  75.98697      NaN     NaN      NaN      NaN\n",
      "55 2019-09-17 11:45:00  74.42233      NaN     NaN      NaN      NaN\n",
      "56 2019-09-17 11:50:00  73.48852      NaN     NaN      NaN      NaN\n",
      "57 2019-09-17 11:55:00  75.59920      NaN     NaN      NaN      NaN\n",
      "58 2019-09-17 12:00:00  77.57317      NaN     NaN      NaN      NaN\n",
      "59 2019-09-17 12:05:00  79.21033      NaN     NaN      NaN      NaN\n",
      "60 2019-09-17 12:10:00  79.61143      NaN     NaN      NaN      NaN\n",
      "61 2019-09-17 12:15:00  79.63505      NaN     NaN      NaN      NaN\n",
      "62 2019-09-17 12:20:00  80.06469      NaN     NaN      NaN      NaN\n",
      "63 2019-09-17 12:25:00  77.96307      NaN     NaN      NaN      NaN\n",
      "64 2019-09-17 12:30:00  77.05612      NaN     NaN      NaN      NaN\n",
      "65 2019-09-17 12:35:00  77.02678      NaN     NaN      NaN      NaN\n",
      "66 2019-09-17 12:40:00  75.76601      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "219   2019-09-18 01:25:00  94.52927  94.651617  102.345570\n",
      "220   2019-09-18 01:30:00  94.66705  94.685102  102.382046\n",
      "3657  2019-09-29 23:55:00  93.86329  94.067512  101.580722\n",
      "15213 2019-11-29 08:00:00  81.07637  81.463481  105.130475\n",
      "18611 2019-12-11 04:05:00  91.96853  92.119927  103.178604\n",
      "46961 2020-04-04 03:25:00  88.73028  88.879897   96.018402\n",
      "46962 2020-04-04 03:30:00  88.57132  88.875911   96.029656\n",
      "50073 2020-04-15 22:05:00  87.68196  87.705753   94.297027\n",
      "52589 2020-04-24 23:15:00  87.46429  87.884610   96.411778\n",
      "53789 2020-04-29 03:15:00  91.54680  91.610249   96.015791\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2019-09-17 10:40:00  77.88953      NaN     NaN      NaN      NaN\n",
      "38 2019-09-17 10:45:00  78.19370      NaN     NaN      NaN      NaN\n",
      "39 2019-09-17 10:50:00  75.23392      NaN     NaN      NaN      NaN\n",
      "40 2019-09-17 10:55:00  73.61325      NaN     NaN      NaN      NaN\n",
      "41 2019-09-17 11:00:00  72.83226      NaN     NaN      NaN      NaN\n",
      "42 2019-09-17 11:05:00  72.73698      NaN     NaN      NaN      NaN\n",
      "43 2019-09-17 11:10:00  74.02856      NaN     NaN      NaN      NaN\n",
      "44 2019-09-17 11:15:00  74.46848      NaN     NaN      NaN      NaN\n",
      "45 2019-09-17 11:20:00  72.73234      NaN     NaN      NaN      NaN\n",
      "46 2019-09-17 11:25:00  71.69755      NaN     NaN      NaN      NaN\n",
      "47 2019-09-17 11:30:00  74.18398      NaN     NaN      NaN      NaN\n",
      "48 2019-09-17 11:35:00  76.20725      NaN     NaN      NaN      NaN\n",
      "49 2019-09-17 11:40:00  75.98697      NaN     NaN      NaN      NaN\n",
      "50 2019-09-17 11:45:00  74.42233      NaN     NaN      NaN      NaN\n",
      "51 2019-09-17 11:50:00  73.48852      NaN     NaN      NaN      NaN\n",
      "52 2019-09-17 11:55:00  75.59920      NaN     NaN      NaN      NaN\n",
      "53 2019-09-17 12:00:00  77.57317      NaN     NaN      NaN      NaN\n",
      "54 2019-09-17 12:05:00  79.21033      NaN     NaN      NaN      NaN\n",
      "55 2019-09-17 12:10:00  79.61143      NaN     NaN      NaN      NaN\n",
      "56 2019-09-17 12:15:00  79.63505      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "214   2019-09-18 01:25:00  94.52927  94.651617  102.345570\n",
      "215   2019-09-18 01:30:00  94.66705  94.685102  102.382046\n",
      "3652  2019-09-29 23:55:00  93.86329  94.067512  101.580722\n",
      "15208 2019-11-29 08:00:00  81.07637  81.463481  105.130475\n",
      "18606 2019-12-11 04:05:00  91.96853  92.119927  103.178604\n",
      "46956 2020-04-04 03:25:00  88.73028  88.879897   96.018402\n",
      "46957 2020-04-04 03:30:00  88.57132  88.875911   96.029656\n",
      "50068 2020-04-15 22:05:00  87.68196  87.705753   94.297027\n",
      "52584 2020-04-24 23:15:00  87.46429  87.884610   96.411778\n",
      "53784 2020-04-29 03:15:00  91.54680  91.610249   96.015791\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47 2020-04-30 00:45:00  93.48898      NaN     NaN      NaN      NaN\n",
      "48 2020-04-30 00:50:00  93.55344      NaN     NaN      NaN      NaN\n",
      "49 2020-04-30 00:55:00  93.55702      NaN     NaN      NaN      NaN\n",
      "50 2020-04-30 01:00:00  93.35294      NaN     NaN      NaN      NaN\n",
      "51 2020-04-30 01:05:00  93.07500      NaN     NaN      NaN      NaN\n",
      "52 2020-04-30 01:10:00  92.71313      NaN     NaN      NaN      NaN\n",
      "53 2020-04-30 01:15:00  93.03630      NaN     NaN      NaN      NaN\n",
      "54 2020-04-30 01:20:00  93.40242      NaN     NaN      NaN      NaN\n",
      "55 2020-04-30 01:25:00  93.37183      NaN     NaN      NaN      NaN\n",
      "56 2020-04-30 01:30:00  93.22191      NaN     NaN      NaN      NaN\n",
      "57 2020-04-30 01:35:00  92.99400      NaN     NaN      NaN      NaN\n",
      "58 2020-04-30 01:40:00  92.85546      NaN     NaN      NaN      NaN\n",
      "59 2020-04-30 01:45:00  93.20525      NaN     NaN      NaN      NaN\n",
      "60 2020-04-30 01:50:00  93.31776      NaN     NaN      NaN      NaN\n",
      "61 2020-04-30 01:55:00  93.14227      NaN     NaN      NaN      NaN\n",
      "62 2020-04-30 02:00:00  93.07421      NaN     NaN      NaN      NaN\n",
      "63 2020-04-30 02:05:00  93.13545      NaN     NaN      NaN      NaN\n",
      "64 2020-04-30 02:10:00  93.76063      NaN     NaN      NaN      NaN\n",
      "65 2020-04-30 02:15:00  93.90250      NaN     NaN      NaN      NaN\n",
      "66 2020-04-30 02:20:00  93.91196      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "4655  2020-05-16 22:20:00  86.32387  86.976540   96.498661\n",
      "4661  2020-05-16 22:50:00  86.83944  87.031513   96.522184\n",
      "5246  2020-05-18 23:40:00  88.90604  88.953363   96.719899\n",
      "8046  2020-05-28 17:05:00  91.02205  91.399582   94.589173\n",
      "8047  2020-05-28 17:10:00  91.01923  91.431037   94.578006\n",
      "9267  2020-06-01 22:50:00  90.63160  90.660084   95.595190\n",
      "9268  2020-06-01 22:55:00  90.22290  90.667524   95.602073\n",
      "14462 2020-06-20 00:45:00  88.43612  88.798666   95.485220\n",
      "14463 2020-06-20 00:50:00  88.56462  88.861958   95.484608\n",
      "14464 2020-06-20 00:55:00  88.17430  88.891136   95.507215\n",
      "15026 2020-06-21 23:45:00  85.69020  85.898672   96.934195\n",
      "15027 2020-06-21 23:50:00  85.80113  85.823995   96.946706\n",
      "18187 2020-07-02 23:10:00  89.69535  89.754836   94.975814\n",
      "18235 2020-07-03 03:10:00  91.61496  91.691237   94.620049\n",
      "18823 2020-07-05 04:10:00  92.55473  92.804748   95.357726\n",
      "18824 2020-07-05 04:15:00  92.63938  92.805425   95.348798\n",
      "18825 2020-07-05 04:20:00  92.50244  92.804999   95.335908\n",
      "23656 2020-07-21 22:55:00  88.86047  88.880970   95.850420\n",
      "23975 2020-07-23 01:30:00  91.95812  92.313770   94.648517\n",
      "29165 2020-08-10 02:00:00  87.85276  89.536492   95.651536\n",
      "29166 2020-08-10 02:05:00  89.10155  89.276137   95.807920\n",
      "32332 2020-08-21 01:55:00  90.19985  90.420247   95.651137\n",
      "32333 2020-08-21 02:00:00  90.30953  90.423391   95.662894\n",
      "33426 2020-08-24 23:30:00  90.37901  90.757562   95.379295\n",
      "33427 2020-08-24 23:35:00  90.33269  90.849443   95.356493\n",
      "36363 2020-09-04 10:45:00  73.40981  73.437570  105.740442\n",
      "36364 2020-09-04 10:50:00  71.90003  73.446605  105.815172\n",
      "36365 2020-09-04 10:55:00  71.79338  73.458274  105.920020\n",
      "36366 2020-09-04 11:00:00  70.57602  73.462435  106.045450\n",
      "39053 2020-09-13 22:20:00  88.13854  88.213555   95.588731\n",
      "39054 2020-09-13 22:25:00  87.95287  88.209944   95.605779\n",
      "42336 2020-09-25 23:35:00  87.22338  87.726699   97.585292\n",
      "42337 2020-09-25 23:40:00  87.46291  87.724129   97.607536\n",
      "42632 2020-09-27 00:15:00  90.61168  90.613196   95.396061\n",
      "43774 2020-10-01 10:50:00  44.29979  44.648896   76.135007\n",
      "44243 2020-10-03 01:55:00  88.15905  88.241151   96.002481\n",
      "44458 2020-10-03 19:50:00  92.41030  92.596707   94.938173\n",
      "47091 2020-10-12 23:15:00  86.20107  86.697279   95.528885\n",
      "47092 2020-10-12 23:20:00  85.59904  86.653355   95.604433\n",
      "50319 2020-10-24 13:15:00  73.83125  74.976487  106.382288\n",
      "50320 2020-10-24 13:20:00  74.45288  74.985282  106.345386\n",
      "50458 2020-10-25 00:50:00  90.61999  91.060328   95.324911\n",
      "50459 2020-10-25 00:55:00  90.49735  91.059182   95.304261\n",
      "52305 2020-11-01 04:05:00  89.05544  89.169730   96.266295\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2020-04-30 00:20:00  93.70702      NaN     NaN      NaN      NaN\n",
      "38 2020-04-30 00:25:00  93.54612      NaN     NaN      NaN      NaN\n",
      "39 2020-04-30 00:30:00  93.22489      NaN     NaN      NaN      NaN\n",
      "40 2020-04-30 00:35:00  93.20046      NaN     NaN      NaN      NaN\n",
      "41 2020-04-30 00:40:00  93.30847      NaN     NaN      NaN      NaN\n",
      "42 2020-04-30 00:45:00  93.48898      NaN     NaN      NaN      NaN\n",
      "43 2020-04-30 00:50:00  93.55344      NaN     NaN      NaN      NaN\n",
      "44 2020-04-30 00:55:00  93.55702      NaN     NaN      NaN      NaN\n",
      "45 2020-04-30 01:00:00  93.35294      NaN     NaN      NaN      NaN\n",
      "46 2020-04-30 01:05:00  93.07500      NaN     NaN      NaN      NaN\n",
      "47 2020-04-30 01:10:00  92.71313      NaN     NaN      NaN      NaN\n",
      "48 2020-04-30 01:15:00  93.03630      NaN     NaN      NaN      NaN\n",
      "49 2020-04-30 01:20:00  93.40242      NaN     NaN      NaN      NaN\n",
      "50 2020-04-30 01:25:00  93.37183      NaN     NaN      NaN      NaN\n",
      "51 2020-04-30 01:30:00  93.22191      NaN     NaN      NaN      NaN\n",
      "52 2020-04-30 01:35:00  92.99400      NaN     NaN      NaN      NaN\n",
      "53 2020-04-30 01:40:00  92.85546      NaN     NaN      NaN      NaN\n",
      "54 2020-04-30 01:45:00  93.20525      NaN     NaN      NaN      NaN\n",
      "55 2020-04-30 01:50:00  93.31776      NaN     NaN      NaN      NaN\n",
      "56 2020-04-30 01:55:00  93.14227      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "4650  2020-05-16 22:20:00  86.32387  86.976540   96.498661\n",
      "4656  2020-05-16 22:50:00  86.83944  87.031513   96.522184\n",
      "5241  2020-05-18 23:40:00  88.90604  88.953363   96.719899\n",
      "8041  2020-05-28 17:05:00  91.02205  91.399582   94.589173\n",
      "8042  2020-05-28 17:10:00  91.01923  91.431037   94.578006\n",
      "9262  2020-06-01 22:50:00  90.63160  90.660084   95.595190\n",
      "9263  2020-06-01 22:55:00  90.22290  90.667524   95.602073\n",
      "14457 2020-06-20 00:45:00  88.43612  88.798666   95.485220\n",
      "14458 2020-06-20 00:50:00  88.56462  88.861958   95.484608\n",
      "14459 2020-06-20 00:55:00  88.17430  88.891136   95.507215\n",
      "15021 2020-06-21 23:45:00  85.69020  85.898672   96.934195\n",
      "15022 2020-06-21 23:50:00  85.80113  85.823995   96.946706\n",
      "18182 2020-07-02 23:10:00  89.69535  89.754836   94.975814\n",
      "18230 2020-07-03 03:10:00  91.61496  91.691237   94.620049\n",
      "18818 2020-07-05 04:10:00  92.55473  92.804748   95.357726\n",
      "18819 2020-07-05 04:15:00  92.63938  92.805425   95.348798\n",
      "18820 2020-07-05 04:20:00  92.50244  92.804999   95.335908\n",
      "23651 2020-07-21 22:55:00  88.86047  88.880970   95.850420\n",
      "23970 2020-07-23 01:30:00  91.95812  92.313770   94.648517\n",
      "29160 2020-08-10 02:00:00  87.85276  89.536492   95.651536\n",
      "29161 2020-08-10 02:05:00  89.10155  89.276137   95.807920\n",
      "32327 2020-08-21 01:55:00  90.19985  90.420247   95.651137\n",
      "32328 2020-08-21 02:00:00  90.30953  90.423391   95.662894\n",
      "33421 2020-08-24 23:30:00  90.37901  90.757562   95.379295\n",
      "33422 2020-08-24 23:35:00  90.33269  90.849443   95.356493\n",
      "33828 2020-08-26 09:25:00  60.55173  63.132375  111.934500\n",
      "33829 2020-08-26 09:30:00  59.51867  63.169398  111.824201\n",
      "36355 2020-09-04 10:30:00  79.75440  82.310547   99.300800\n",
      "36356 2020-09-04 10:35:00  77.25877  82.345979   99.362781\n",
      "39048 2020-09-13 22:20:00  88.13854  88.213555   95.588731\n",
      "39049 2020-09-13 22:25:00  87.95287  88.209944   95.605779\n",
      "41680 2020-09-23 09:30:00  67.30839  68.431063  111.561724\n",
      "41681 2020-09-23 09:35:00  68.01204  68.431227  111.561097\n",
      "42331 2020-09-25 23:35:00  87.22338  87.726699   97.585292\n",
      "42332 2020-09-25 23:40:00  87.46291  87.724129   97.607536\n",
      "42627 2020-09-27 00:15:00  90.61168  90.613196   95.396061\n",
      "43769 2020-10-01 10:50:00  44.29979  44.648896   76.135007\n",
      "44238 2020-10-03 01:55:00  88.15905  88.241151   96.002481\n",
      "44453 2020-10-03 19:50:00  92.41030  92.596707   94.938173\n",
      "47086 2020-10-12 23:15:00  86.20107  86.697279   95.528885\n",
      "47087 2020-10-12 23:20:00  85.59904  86.653355   95.604433\n",
      "49859 2020-10-22 23:10:00  88.26680  88.392845   94.804604\n",
      "49861 2020-10-22 23:20:00  87.93707  88.067475   94.975515\n",
      "50453 2020-10-25 00:50:00  90.61999  91.060328   95.324911\n",
      "50454 2020-10-25 00:55:00  90.49735  91.059182   95.304261\n",
      "52300 2020-11-01 04:05:00  89.05544  89.169730   96.266295\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47 2020-11-07 05:15:00  85.89733      NaN     NaN      NaN      NaN\n",
      "48 2020-11-07 05:20:00  86.76670      NaN     NaN      NaN      NaN\n",
      "49 2020-11-07 05:25:00  87.59707      NaN     NaN      NaN      NaN\n",
      "50 2020-11-07 05:30:00  87.35853      NaN     NaN      NaN      NaN\n",
      "51 2020-11-07 05:35:00  88.59362      NaN     NaN      NaN      NaN\n",
      "52 2020-11-07 05:40:00  88.23920      NaN     NaN      NaN      NaN\n",
      "53 2020-11-07 05:45:00  87.30991      NaN     NaN      NaN      NaN\n",
      "54 2020-11-07 05:50:00  85.44654      NaN     NaN      NaN      NaN\n",
      "55 2020-11-07 05:55:00  82.95771      NaN     NaN      NaN      NaN\n",
      "56 2020-11-07 06:00:00  81.52166      NaN     NaN      NaN      NaN\n",
      "57 2020-11-07 06:05:00  78.75896      NaN     NaN      NaN      NaN\n",
      "58 2020-11-07 06:10:00  79.65320      NaN     NaN      NaN      NaN\n",
      "59 2020-11-07 06:15:00  83.52748      NaN     NaN      NaN      NaN\n",
      "60 2020-11-07 06:20:00  85.58503      NaN     NaN      NaN      NaN\n",
      "61 2020-11-07 06:25:00  87.00044      NaN     NaN      NaN      NaN\n",
      "62 2020-11-07 06:30:00  88.44071      NaN     NaN      NaN      NaN\n",
      "63 2020-11-07 06:35:00  88.92825      NaN     NaN      NaN      NaN\n",
      "64 2020-11-07 06:40:00  89.72923      NaN     NaN      NaN      NaN\n",
      "65 2020-11-07 06:45:00  90.16391      NaN     NaN      NaN      NaN\n",
      "66 2020-11-07 06:50:00  90.05029      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "5438  2020-11-25 22:30:00  89.38054  89.633612   95.004992\n",
      "5439  2020-11-25 22:35:00  88.43978  89.661616   95.012943\n",
      "6637  2020-11-30 02:25:00  90.48127  90.619677   94.462400\n",
      "6638  2020-11-30 02:30:00  90.48708  90.617849   94.461159\n",
      "8119  2020-12-06 00:30:00  87.65763  88.076015   96.423730\n",
      "11568 2020-12-17 23:55:00  89.59486  89.636163   95.591550\n",
      "11569 2020-12-18 00:00:00  89.45533  89.640926   95.577778\n",
      "11910 2020-12-19 04:25:00  85.88406  86.041548   96.242284\n",
      "13360 2020-12-24 05:15:00  89.60426  89.806141   95.873864\n",
      "13361 2020-12-24 05:20:00  88.98206  89.781069   95.867198\n",
      "13362 2020-12-24 05:25:00  89.32017  89.767672   95.857623\n",
      "13632 2020-12-25 03:55:00  92.87489  92.925630   94.962813\n",
      "17406 2021-01-12 04:00:00  91.97502  92.051604   95.271698\n",
      "17407 2021-01-12 04:05:00  91.71110  92.050674   95.274856\n",
      "20745 2021-01-24 00:40:00  89.35285  90.207727   95.936561\n",
      "20746 2021-01-24 00:45:00  89.48428  90.204393   95.936154\n",
      "27805 2021-02-18 03:05:00  93.50560  93.673034   94.493807\n",
      "33557 2021-03-12 00:15:00  90.65640  90.681005   96.318963\n",
      "33694 2021-03-12 17:00:00  88.12128  88.406435   96.839905\n",
      "36514 2021-03-23 01:15:00  90.76987  91.341819   95.390164\n",
      "36515 2021-03-23 01:20:00  90.66998  91.340722   95.393072\n",
      "37528 2021-03-26 21:15:00  82.60381  85.242795   94.931677\n",
      "37529 2021-03-26 21:20:00  84.93607  85.246576   94.938084\n",
      "41401 2021-04-10 14:55:00  71.10941  73.179999  102.530825\n",
      "48499 2021-07-14 22:50:00  90.10783  90.483359   94.906965\n",
      "52830 2021-07-29 23:45:00  88.89000  89.204695   96.819194\n",
      "52831 2021-07-29 23:50:00  89.11086  89.201134   96.841866\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2020-11-07 04:50:00  90.96262      NaN     NaN      NaN      NaN\n",
      "38 2020-11-07 04:55:00  90.49996      NaN     NaN      NaN      NaN\n",
      "39 2020-11-07 05:00:00  89.35474      NaN     NaN      NaN      NaN\n",
      "40 2020-11-07 05:05:00  88.73154      NaN     NaN      NaN      NaN\n",
      "41 2020-11-07 05:10:00  87.47327      NaN     NaN      NaN      NaN\n",
      "42 2020-11-07 05:15:00  85.89733      NaN     NaN      NaN      NaN\n",
      "43 2020-11-07 05:20:00  86.76670      NaN     NaN      NaN      NaN\n",
      "44 2020-11-07 05:25:00  87.59707      NaN     NaN      NaN      NaN\n",
      "45 2020-11-07 05:30:00  87.35853      NaN     NaN      NaN      NaN\n",
      "46 2020-11-07 05:35:00  88.59362      NaN     NaN      NaN      NaN\n",
      "47 2020-11-07 05:40:00  88.23920      NaN     NaN      NaN      NaN\n",
      "48 2020-11-07 05:45:00  87.30991      NaN     NaN      NaN      NaN\n",
      "49 2020-11-07 05:50:00  85.44654      NaN     NaN      NaN      NaN\n",
      "50 2020-11-07 05:55:00  82.95771      NaN     NaN      NaN      NaN\n",
      "51 2020-11-07 06:00:00  81.52166      NaN     NaN      NaN      NaN\n",
      "52 2020-11-07 06:05:00  78.75896      NaN     NaN      NaN      NaN\n",
      "53 2020-11-07 06:10:00  79.65320      NaN     NaN      NaN      NaN\n",
      "54 2020-11-07 06:15:00  83.52748      NaN     NaN      NaN      NaN\n",
      "55 2020-11-07 06:20:00  85.58503      NaN     NaN      NaN      NaN\n",
      "56 2020-11-07 06:25:00  87.00044      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "5433  2020-11-25 22:30:00  89.38054  89.633612   95.004992\n",
      "5434  2020-11-25 22:35:00  88.43978  89.661616   95.012943\n",
      "6632  2020-11-30 02:25:00  90.48127  90.619677   94.462400\n",
      "6633  2020-11-30 02:30:00  90.48708  90.617849   94.461159\n",
      "8114  2020-12-06 00:30:00  87.65763  88.076015   96.423730\n",
      "11563 2020-12-17 23:55:00  89.59486  89.636163   95.591550\n",
      "11564 2020-12-18 00:00:00  89.45533  89.640926   95.577778\n",
      "11905 2020-12-19 04:25:00  85.88406  86.041548   96.242284\n",
      "13355 2020-12-24 05:15:00  89.60426  89.806141   95.873864\n",
      "13356 2020-12-24 05:20:00  88.98206  89.781069   95.867198\n",
      "13357 2020-12-24 05:25:00  89.32017  89.767672   95.857623\n",
      "13627 2020-12-25 03:55:00  92.87489  92.925630   94.962813\n",
      "17401 2021-01-12 04:00:00  91.97502  92.051604   95.271698\n",
      "17402 2021-01-12 04:05:00  91.71110  92.050674   95.274856\n",
      "20740 2021-01-24 00:40:00  89.35285  90.207727   95.936561\n",
      "20741 2021-01-24 00:45:00  89.48428  90.204393   95.936154\n",
      "27800 2021-02-18 03:05:00  93.50560  93.673034   94.493807\n",
      "33552 2021-03-12 00:15:00  90.65640  90.681005   96.318963\n",
      "33689 2021-03-12 17:00:00  88.12128  88.406435   96.839905\n",
      "36509 2021-03-23 01:15:00  90.76987  91.341819   95.390164\n",
      "36510 2021-03-23 01:20:00  90.66998  91.340722   95.393072\n",
      "36674 2021-03-23 16:00:00  79.21348  80.750232  100.762737\n",
      "36675 2021-03-23 16:05:00  79.74641  80.774185  100.645984\n",
      "36676 2021-03-23 16:10:00  79.88265  80.805002  100.532501\n",
      "37523 2021-03-26 21:15:00  82.60381  85.242795   94.931677\n",
      "37524 2021-03-26 21:20:00  84.93607  85.246576   94.938084\n",
      "43060 2021-05-16 08:45:00  58.35871  61.603259  116.339304\n",
      "43061 2021-05-16 08:50:00  58.60641  61.578513  116.437850\n",
      "48494 2021-07-14 22:50:00  90.10783  90.483359   94.906965\n",
      "52825 2021-07-29 23:45:00  88.89000  89.204695   96.819194\n",
      "52826 2021-07-29 23:50:00  89.11086  89.201134   96.841866\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47 2021-08-03 05:10:00  91.72852      NaN     NaN      NaN      NaN\n",
      "48 2021-08-03 05:15:00  91.05191      NaN     NaN      NaN      NaN\n",
      "49 2021-08-03 05:20:00  89.50688      NaN     NaN      NaN      NaN\n",
      "50 2021-08-03 05:25:00  88.86687      NaN     NaN      NaN      NaN\n",
      "51 2021-08-03 05:30:00  87.98821      NaN     NaN      NaN      NaN\n",
      "52 2021-08-03 05:35:00  87.94771      NaN     NaN      NaN      NaN\n",
      "53 2021-08-03 05:40:00  87.78260      NaN     NaN      NaN      NaN\n",
      "54 2021-08-03 05:45:00  87.59568      NaN     NaN      NaN      NaN\n",
      "55 2021-08-03 05:50:00  87.28745      NaN     NaN      NaN      NaN\n",
      "56 2021-08-03 05:55:00  87.38524      NaN     NaN      NaN      NaN\n",
      "57 2021-08-03 06:00:00  87.71472      NaN     NaN      NaN      NaN\n",
      "58 2021-08-03 06:05:00  88.27374      NaN     NaN      NaN      NaN\n",
      "59 2021-08-03 06:10:00  88.36519      NaN     NaN      NaN      NaN\n",
      "60 2021-08-03 06:15:00  90.29565      NaN     NaN      NaN      NaN\n",
      "61 2021-08-03 06:20:00  91.45888      NaN     NaN      NaN      NaN\n",
      "62 2021-08-03 06:25:00  92.07145      NaN     NaN      NaN      NaN\n",
      "63 2021-08-03 06:30:00  92.74740      NaN     NaN      NaN      NaN\n",
      "64 2021-08-03 06:35:00  92.65730      NaN     NaN      NaN      NaN\n",
      "65 2021-08-03 06:40:00  92.71055      NaN     NaN      NaN      NaN\n",
      "66 2021-08-03 06:45:00  93.14232      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "4556  2021-08-19 02:55:00  93.00123  93.194674   96.648803\n",
      "4817  2021-08-20 00:40:00  90.14584  90.464938   96.214320\n",
      "5967  2021-08-24 00:55:00  92.08369  92.317136   95.798207\n",
      "7489  2021-08-29 08:10:00  80.69485  81.886318   98.789485\n",
      "11926 2021-09-16 16:25:00  73.17893  55.485810   72.867195\n",
      "13879 2021-11-10 21:00:00  91.65597  91.716319   96.239980\n",
      "13880 2021-11-10 21:05:00  91.55738  91.798047   96.199002\n",
      "13881 2021-11-10 21:10:00  91.53275  91.819669   96.191789\n",
      "15607 2021-11-17 00:00:00  93.60226  93.692883   96.093716\n",
      "16179 2021-11-19 00:40:00  90.06490  90.136313   97.096018\n",
      "16180 2021-11-19 00:45:00  89.86529  90.139121   97.090239\n",
      "16497 2021-11-20 03:10:00  89.49642  89.799281   97.364706\n",
      "20275 2021-12-03 23:30:00  91.71864  92.246477   95.398523\n",
      "20276 2021-12-03 23:35:00  92.19492  92.261882   95.423643\n",
      "20575 2021-12-05 00:30:00  89.38418  89.423665   95.601341\n",
      "22835 2021-12-12 22:50:00  93.95480  94.019984   96.324647\n",
      "22836 2021-12-12 22:55:00  93.82719  94.049561   96.311665\n",
      "22837 2021-12-12 23:00:00  93.92876  94.062817   96.305324\n",
      "23177 2021-12-14 03:20:00  91.20886  91.471891   96.673582\n",
      "26856 2021-12-27 04:10:00  91.62657  91.737063   95.449581\n",
      "26857 2021-12-27 04:15:00  91.21548  91.735767   95.448536\n",
      "27128 2021-12-28 02:50:00  87.80814  87.998450   97.351483\n",
      "27129 2021-12-28 02:55:00  87.48689  88.008512   97.299597\n",
      "27130 2021-12-28 03:00:00  87.68153  88.015988   97.263311\n",
      "27388 2021-12-29 00:30:00  88.38422  88.387605   97.418379\n",
      "30839 2022-01-11 22:05:00  90.34058  90.419323   95.895554\n",
      "30840 2022-01-11 22:10:00  90.27486  90.497359   95.866106\n",
      "30841 2022-01-11 22:15:00  90.31469  90.541959   95.841978\n",
      "33877 2022-01-22 12:15:00  68.63269  68.745827  100.813134\n",
      "39918 2022-02-13 01:45:00  91.92828  92.346854   95.686225\n",
      "40512 2022-02-15 03:15:00  90.39639  90.495549   97.320254\n",
      "40513 2022-02-15 03:20:00  89.92564  90.511039   97.277001\n",
      "43416 2022-03-02 04:20:00  80.79253  81.639968  101.910619\n",
      "44566 2022-03-06 05:10:00  91.40950  91.573428   96.704760\n",
      "44567 2022-03-06 05:15:00  91.52197  91.575565   96.676155\n",
      "51699 2022-03-30 23:35:00  84.13132  84.246361   99.648729\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2021-08-03 04:45:00  93.81165      NaN     NaN      NaN      NaN\n",
      "38 2021-08-03 04:50:00  93.93513      NaN     NaN      NaN      NaN\n",
      "39 2021-08-03 04:55:00  93.94505      NaN     NaN      NaN      NaN\n",
      "40 2021-08-03 05:00:00  93.18440      NaN     NaN      NaN      NaN\n",
      "41 2021-08-03 05:05:00  92.05052      NaN     NaN      NaN      NaN\n",
      "42 2021-08-03 05:10:00  91.72852      NaN     NaN      NaN      NaN\n",
      "43 2021-08-03 05:15:00  91.05191      NaN     NaN      NaN      NaN\n",
      "44 2021-08-03 05:20:00  89.50688      NaN     NaN      NaN      NaN\n",
      "45 2021-08-03 05:25:00  88.86687      NaN     NaN      NaN      NaN\n",
      "46 2021-08-03 05:30:00  87.98821      NaN     NaN      NaN      NaN\n",
      "47 2021-08-03 05:35:00  87.94771      NaN     NaN      NaN      NaN\n",
      "48 2021-08-03 05:40:00  87.78260      NaN     NaN      NaN      NaN\n",
      "49 2021-08-03 05:45:00  87.59568      NaN     NaN      NaN      NaN\n",
      "50 2021-08-03 05:50:00  87.28745      NaN     NaN      NaN      NaN\n",
      "51 2021-08-03 05:55:00  87.38524      NaN     NaN      NaN      NaN\n",
      "52 2021-08-03 06:00:00  87.71472      NaN     NaN      NaN      NaN\n",
      "53 2021-08-03 06:05:00  88.27374      NaN     NaN      NaN      NaN\n",
      "54 2021-08-03 06:10:00  88.36519      NaN     NaN      NaN      NaN\n",
      "55 2021-08-03 06:15:00  90.29565      NaN     NaN      NaN      NaN\n",
      "56 2021-08-03 06:20:00  91.45888      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "4551  2021-08-19 02:55:00  93.00123  93.194674   96.648803\n",
      "4812  2021-08-20 00:40:00  90.14584  90.464938   96.214320\n",
      "5962  2021-08-24 00:55:00  92.08369  92.317136   95.798207\n",
      "13874 2021-11-10 21:00:00  91.65597  91.716319   96.239980\n",
      "13875 2021-11-10 21:05:00  91.55738  91.798047   96.199002\n",
      "13876 2021-11-10 21:10:00  91.53275  91.819669   96.191789\n",
      "15602 2021-11-17 00:00:00  93.60226  93.692883   96.093716\n",
      "16174 2021-11-19 00:40:00  90.06490  90.136313   97.096018\n",
      "16175 2021-11-19 00:45:00  89.86529  90.139121   97.090239\n",
      "16492 2021-11-20 03:10:00  89.49642  89.799281   97.364706\n",
      "20270 2021-12-03 23:30:00  91.71864  92.246477   95.398523\n",
      "20271 2021-12-03 23:35:00  92.19492  92.261882   95.423643\n",
      "20570 2021-12-05 00:30:00  89.38418  89.423665   95.601341\n",
      "22830 2021-12-12 22:50:00  93.95480  94.019984   96.324647\n",
      "22831 2021-12-12 22:55:00  93.82719  94.049561   96.311665\n",
      "22832 2021-12-12 23:00:00  93.92876  94.062817   96.305324\n",
      "23172 2021-12-14 03:20:00  91.20886  91.471891   96.673582\n",
      "26851 2021-12-27 04:10:00  91.62657  91.737063   95.449581\n",
      "26852 2021-12-27 04:15:00  91.21548  91.735767   95.448536\n",
      "27123 2021-12-28 02:50:00  87.80814  87.998450   97.351483\n",
      "27124 2021-12-28 02:55:00  87.48689  88.008512   97.299597\n",
      "27125 2021-12-28 03:00:00  87.68153  88.015988   97.263311\n",
      "27383 2021-12-29 00:30:00  88.38422  88.387605   97.418379\n",
      "30834 2022-01-11 22:05:00  90.34058  90.419323   95.895554\n",
      "30835 2022-01-11 22:10:00  90.27486  90.497359   95.866106\n",
      "30836 2022-01-11 22:15:00  90.31469  90.541959   95.841978\n",
      "33872 2022-01-22 12:15:00  68.63269  68.745827  100.813134\n",
      "39913 2022-02-13 01:45:00  91.92828  92.346854   95.686225\n",
      "40507 2022-02-15 03:15:00  90.39639  90.495549   97.320254\n",
      "40508 2022-02-15 03:20:00  89.92564  90.511039   97.277001\n",
      "43411 2022-03-02 04:20:00  80.79253  81.639968  101.910619\n",
      "44561 2022-03-06 05:10:00  91.40950  91.573428   96.704760\n",
      "44562 2022-03-06 05:15:00  91.52197  91.575565   96.676155\n",
      "51694 2022-03-30 23:35:00  84.13132  84.246361   99.648729\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47 2022-04-08 03:15:00  94.70779      NaN     NaN      NaN      NaN\n",
      "48 2022-04-08 03:20:00  94.95533      NaN     NaN      NaN      NaN\n",
      "49 2022-04-08 03:25:00  94.86378      NaN     NaN      NaN      NaN\n",
      "50 2022-04-08 03:30:00  94.72475      NaN     NaN      NaN      NaN\n",
      "51 2022-04-08 03:35:00  94.24718      NaN     NaN      NaN      NaN\n",
      "52 2022-04-08 03:40:00  93.78601      NaN     NaN      NaN      NaN\n",
      "53 2022-04-08 03:45:00  93.54469      NaN     NaN      NaN      NaN\n",
      "54 2022-04-08 03:50:00  93.21350      NaN     NaN      NaN      NaN\n",
      "55 2022-04-08 03:55:00  93.24232      NaN     NaN      NaN      NaN\n",
      "56 2022-04-08 04:00:00  93.73797      NaN     NaN      NaN      NaN\n",
      "57 2022-04-08 04:05:00  93.78996      NaN     NaN      NaN      NaN\n",
      "58 2022-04-08 04:10:00  93.90526      NaN     NaN      NaN      NaN\n",
      "59 2022-04-08 04:15:00  93.94707      NaN     NaN      NaN      NaN\n",
      "60 2022-04-08 04:20:00  93.82670      NaN     NaN      NaN      NaN\n",
      "61 2022-04-08 04:25:00  93.90469      NaN     NaN      NaN      NaN\n",
      "62 2022-04-08 04:30:00  94.06068      NaN     NaN      NaN      NaN\n",
      "63 2022-04-08 04:35:00  94.14602      NaN     NaN      NaN      NaN\n",
      "64 2022-04-08 04:40:00  93.95387      NaN     NaN      NaN      NaN\n",
      "65 2022-04-08 04:45:00  93.78714      NaN     NaN      NaN      NaN\n",
      "66 2022-04-08 04:50:00  93.93973      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "7827  2022-05-05 04:05:00  93.19428  93.220864   95.143149\n",
      "9829  2022-05-12 02:55:00  87.63307  88.014696   96.219090\n",
      "12137 2022-05-20 03:15:00  91.87407  92.012828   95.795222\n",
      "12408 2022-05-21 01:50:00  88.30013  88.703711   96.992877\n",
      "13245 2022-05-23 23:35:00  78.72737  79.082778   97.478668\n",
      "22297 2022-06-25 01:25:00  94.13921  94.210752   95.128568\n",
      "22298 2022-06-25 01:30:00  94.13496  94.210918   95.126790\n",
      "23130 2022-06-27 22:50:00  91.49150  91.704776   95.053364\n",
      "23131 2022-06-27 22:55:00  91.51063  91.693712   95.079599\n",
      "33119 2022-08-02 04:50:00  79.98811  80.024830  100.226029\n",
      "33665 2022-08-04 02:20:00  91.34930  91.391369   95.428648\n",
      "38846 2022-08-22 02:05:00  89.47986  89.495421   95.557343\n",
      "39990 2022-08-26 02:25:00  87.74648  88.342533   96.272919\n",
      "39991 2022-08-26 02:30:00  87.16360  88.344930   96.267284\n",
      "39992 2022-08-26 02:35:00  88.33501  88.349001   96.255448\n",
      "45131 2022-09-12 22:50:00  90.71629  90.976787   95.089163\n",
      "45132 2022-09-12 22:55:00  90.33241  90.982179   95.099143\n",
      "45133 2022-09-12 23:00:00  90.69706  90.988047   95.111375\n",
      "47752 2022-09-22 01:15:00  90.41270  90.848097   94.504117\n",
      "51747 2022-10-05 22:10:00  89.05753  89.327755   96.099761\n",
      "51748 2022-10-05 22:15:00  88.77656  89.320214   96.135910\n",
      "51749 2022-10-05 22:20:00  89.04114  89.312779   96.159544\n",
      "52594 2022-10-08 20:45:00  86.02611  86.230296   97.043610\n",
      "52595 2022-10-08 20:50:00  85.84237  86.229101   97.090893\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2022-04-08 02:50:00  92.32336      NaN     NaN      NaN      NaN\n",
      "38 2022-04-08 02:55:00  92.57373      NaN     NaN      NaN      NaN\n",
      "39 2022-04-08 03:00:00  92.74893      NaN     NaN      NaN      NaN\n",
      "40 2022-04-08 03:05:00  93.30279      NaN     NaN      NaN      NaN\n",
      "41 2022-04-08 03:10:00  94.13867      NaN     NaN      NaN      NaN\n",
      "42 2022-04-08 03:15:00  94.70779      NaN     NaN      NaN      NaN\n",
      "43 2022-04-08 03:20:00  94.95533      NaN     NaN      NaN      NaN\n",
      "44 2022-04-08 03:25:00  94.86378      NaN     NaN      NaN      NaN\n",
      "45 2022-04-08 03:30:00  94.72475      NaN     NaN      NaN      NaN\n",
      "46 2022-04-08 03:35:00  94.24718      NaN     NaN      NaN      NaN\n",
      "47 2022-04-08 03:40:00  93.78601      NaN     NaN      NaN      NaN\n",
      "48 2022-04-08 03:45:00  93.54469      NaN     NaN      NaN      NaN\n",
      "49 2022-04-08 03:50:00  93.21350      NaN     NaN      NaN      NaN\n",
      "50 2022-04-08 03:55:00  93.24232      NaN     NaN      NaN      NaN\n",
      "51 2022-04-08 04:00:00  93.73797      NaN     NaN      NaN      NaN\n",
      "52 2022-04-08 04:05:00  93.78996      NaN     NaN      NaN      NaN\n",
      "53 2022-04-08 04:10:00  93.90526      NaN     NaN      NaN      NaN\n",
      "54 2022-04-08 04:15:00  93.94707      NaN     NaN      NaN      NaN\n",
      "55 2022-04-08 04:20:00  93.82670      NaN     NaN      NaN      NaN\n",
      "56 2022-04-08 04:25:00  93.90469      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf     lim_sup\n",
      "7822  2022-05-05 04:05:00  93.19428  93.220864   95.143149\n",
      "9824  2022-05-12 02:55:00  87.63307  88.014696   96.219090\n",
      "12132 2022-05-20 03:15:00  91.87407  92.012828   95.795222\n",
      "12403 2022-05-21 01:50:00  88.30013  88.703711   96.992877\n",
      "13240 2022-05-23 23:35:00  78.72737  79.082778   97.478668\n",
      "22292 2022-06-25 01:25:00  94.13921  94.210752   95.128568\n",
      "22293 2022-06-25 01:30:00  94.13496  94.210918   95.126790\n",
      "23125 2022-06-27 22:50:00  91.49150  91.704776   95.053364\n",
      "23126 2022-06-27 22:55:00  91.51063  91.693712   95.079599\n",
      "33114 2022-08-02 04:50:00  79.98811  80.024830  100.226029\n",
      "33660 2022-08-04 02:20:00  91.34930  91.391369   95.428648\n",
      "38841 2022-08-22 02:05:00  89.47986  89.495421   95.557343\n",
      "39985 2022-08-26 02:25:00  87.74648  88.342533   96.272919\n",
      "39986 2022-08-26 02:30:00  87.16360  88.344930   96.267284\n",
      "39987 2022-08-26 02:35:00  88.33501  88.349001   96.255448\n",
      "45126 2022-09-12 22:50:00  90.71629  90.976787   95.089163\n",
      "45127 2022-09-12 22:55:00  90.33241  90.982179   95.099143\n",
      "45128 2022-09-12 23:00:00  90.69706  90.988047   95.111375\n",
      "47747 2022-09-22 01:15:00  90.41270  90.848097   94.504117\n",
      "51742 2022-10-05 22:10:00  89.05753  89.327755   96.099761\n",
      "51743 2022-10-05 22:15:00  88.77656  89.320214   96.135910\n",
      "51744 2022-10-05 22:20:00  89.04114  89.312779   96.159544\n",
      "52589 2022-10-08 20:45:00  86.02611  86.230296   97.043610\n",
      "52590 2022-10-08 20:50:00  85.84237  86.229101   97.090893\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "47 2022-10-13 21:50:00  91.45634      NaN     NaN      NaN      NaN\n",
      "48 2022-10-13 21:55:00  91.16631      NaN     NaN      NaN      NaN\n",
      "49 2022-10-13 22:00:00  90.49297      NaN     NaN      NaN      NaN\n",
      "50 2022-10-13 22:05:00  89.59406      NaN     NaN      NaN      NaN\n",
      "51 2022-10-13 22:10:00  89.89314      NaN     NaN      NaN      NaN\n",
      "52 2022-10-13 22:15:00  90.04089      NaN     NaN      NaN      NaN\n",
      "53 2022-10-13 22:20:00  89.86696      NaN     NaN      NaN      NaN\n",
      "54 2022-10-13 22:25:00  89.63152      NaN     NaN      NaN      NaN\n",
      "55 2022-10-13 22:30:00  90.15020      NaN     NaN      NaN      NaN\n",
      "56 2022-10-13 22:35:00  89.42778      NaN     NaN      NaN      NaN\n",
      "57 2022-10-13 22:40:00  87.81796      NaN     NaN      NaN      NaN\n",
      "58 2022-10-13 22:45:00  87.19443      NaN     NaN      NaN      NaN\n",
      "59 2022-10-13 22:50:00  86.51134      NaN     NaN      NaN      NaN\n",
      "60 2022-10-13 22:55:00  86.17008      NaN     NaN      NaN      NaN\n",
      "61 2022-10-13 23:00:00  85.94494      NaN     NaN      NaN      NaN\n",
      "62 2022-10-13 23:05:00  86.25518      NaN     NaN      NaN      NaN\n",
      "63 2022-10-13 23:10:00  87.37603      NaN     NaN      NaN      NaN\n",
      "64 2022-10-13 23:15:00  88.79874      NaN     NaN      NaN      NaN\n",
      "65 2022-10-13 23:20:00  89.88866      NaN     NaN      NaN      NaN\n",
      "66 2022-10-13 23:25:00  90.26899      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf    lim_sup\n",
      "344   2022-10-14 22:35:00  87.75044  88.003626  94.562511\n",
      "345   2022-10-14 22:40:00  87.67129  88.001975  94.558638\n",
      "1206  2022-10-17 22:25:00  91.20815  91.368169  95.363719\n",
      "2625  2022-10-22 20:40:00  89.31760  89.575406  96.505411\n",
      "3230  2022-10-24 23:05:00  91.46595  91.886249  95.250991\n",
      "3231  2022-10-24 23:10:00  91.64629  91.887165  95.267554\n",
      "3862  2022-10-27 03:45:00  92.20939  92.501645  95.047788\n",
      "3863  2022-10-27 03:50:00  92.25292  92.505686  95.029456\n",
      "4262  2022-10-28 13:05:00  78.85083  79.370238  95.073208\n",
      "13320 2022-11-29 01:55:00  92.07666  92.129087  94.843426\n",
      "13321 2022-11-29 02:00:00  91.90587  92.133317  94.845615\n",
      "13969 2022-12-01 08:00:00  66.18780  68.284969  96.309111\n",
      "14756 2022-12-04 05:00:00  93.00941  93.195506  95.536439\n",
      "14757 2022-12-04 05:05:00  93.07246  93.168538  95.585254\n",
      "14952 2022-12-04 21:20:00  91.79874  92.212556  95.642344\n",
      "14953 2022-12-04 21:25:00  91.84959  92.217347  95.641340\n",
      "14954 2022-12-04 21:30:00  92.11701  92.214496  95.642058\n",
      "15241 2022-12-05 21:25:00  90.53499  90.862087  94.271923\n",
      "15281 2022-12-06 00:45:00  90.69221  90.774539  94.679402\n",
      "15282 2022-12-06 00:50:00  90.75159  90.782468  94.685690\n",
      "21059 2022-12-26 03:35:00  93.56341  93.564446  94.961123\n",
      "21060 2022-12-26 03:40:00  93.43678  93.571448  94.963167\n",
      "30782 2023-01-28 21:50:00  81.30425  81.427258  96.040974\n",
      "35080 2023-02-12 23:35:00  88.72794  88.740138  95.569257\n",
      "37334 2023-02-20 19:25:00  76.32178  77.090238  97.588899\n",
      "37613 2023-02-21 18:40:00  71.55945  71.656804  97.533580\n",
      "39673 2023-02-28 22:20:00  80.99947  81.498178  98.114548\n",
      "39963 2023-03-01 22:30:00  81.99368  82.804538  96.945011\n",
      "39964 2023-03-01 22:35:00  81.39751  82.804184  96.941649\n",
      "41995 2023-03-08 23:50:00  92.27836  92.377867  94.136167\n",
      "41996 2023-03-08 23:55:00  92.15173  92.378369  94.136137\n",
      "41997 2023-03-09 00:00:00  92.31229  92.381837  94.135527\n",
      "44591 2023-03-18 00:10:00  90.38782  90.479382  94.370803\n",
      "46008 2023-03-22 22:15:00  88.25247  88.586636  94.822944\n",
      "46009 2023-03-22 22:20:00  88.04781  88.588190  94.823777\n",
      "46061 2023-03-23 02:40:00  88.29655  88.444949  95.542029\n",
      "46321 2023-03-24 00:20:00  87.68881  88.127438  94.666999\n",
      "46322 2023-03-24 00:25:00  87.34790  88.123369  94.712230\n",
      "46323 2023-03-24 00:30:00  88.01502  88.122878  94.750081\n",
      "46403 2023-03-24 07:10:00  85.90568  87.094602  97.645394\n",
      "46404 2023-03-24 07:15:00  84.38883  87.094944  97.647580\n",
      "46405 2023-03-24 07:20:00  86.86452  87.095337  97.649402\n",
      "46632 2023-03-25 02:15:00  90.05976  90.533884  95.374415\n",
      "46633 2023-03-25 02:20:00  90.32816  90.532914  95.378871\n",
      "47045 2023-03-26 12:40:00  66.94051  67.548820  91.090411\n",
      "47046 2023-03-26 12:45:00  67.55688  67.586451  90.912982\n",
      "                 Fecha     Valor  mean_PF  std_PF  lim_inf  lim_sup\n",
      "37 2022-10-13 21:25:00  89.80720      NaN     NaN      NaN      NaN\n",
      "38 2022-10-13 21:30:00  89.85017      NaN     NaN      NaN      NaN\n",
      "39 2022-10-13 21:35:00  90.44662      NaN     NaN      NaN      NaN\n",
      "40 2022-10-13 21:40:00  91.27995      NaN     NaN      NaN      NaN\n",
      "41 2022-10-13 21:45:00  91.47499      NaN     NaN      NaN      NaN\n",
      "42 2022-10-13 21:50:00  91.45634      NaN     NaN      NaN      NaN\n",
      "43 2022-10-13 21:55:00  91.16631      NaN     NaN      NaN      NaN\n",
      "44 2022-10-13 22:00:00  90.49297      NaN     NaN      NaN      NaN\n",
      "45 2022-10-13 22:05:00  89.59406      NaN     NaN      NaN      NaN\n",
      "46 2022-10-13 22:10:00  89.89314      NaN     NaN      NaN      NaN\n",
      "47 2022-10-13 22:15:00  90.04089      NaN     NaN      NaN      NaN\n",
      "48 2022-10-13 22:20:00  89.86696      NaN     NaN      NaN      NaN\n",
      "49 2022-10-13 22:25:00  89.63152      NaN     NaN      NaN      NaN\n",
      "50 2022-10-13 22:30:00  90.15020      NaN     NaN      NaN      NaN\n",
      "51 2022-10-13 22:35:00  89.42778      NaN     NaN      NaN      NaN\n",
      "52 2022-10-13 22:40:00  87.81796      NaN     NaN      NaN      NaN\n",
      "53 2022-10-13 22:45:00  87.19443      NaN     NaN      NaN      NaN\n",
      "54 2022-10-13 22:50:00  86.51134      NaN     NaN      NaN      NaN\n",
      "55 2022-10-13 22:55:00  86.17008      NaN     NaN      NaN      NaN\n",
      "56 2022-10-13 23:00:00  85.94494      NaN     NaN      NaN      NaN\n",
      "                    Fecha     Valor    lim_inf    lim_sup\n",
      "339   2022-10-14 22:35:00  87.75044  88.003626  94.562511\n",
      "340   2022-10-14 22:40:00  87.67129  88.001975  94.558638\n",
      "1201  2022-10-17 22:25:00  91.20815  91.368169  95.363719\n",
      "2620  2022-10-22 20:40:00  89.31760  89.575406  96.505411\n",
      "3225  2022-10-24 23:05:00  91.46595  91.886249  95.250991\n",
      "3226  2022-10-24 23:10:00  91.64629  91.887165  95.267554\n",
      "3857  2022-10-27 03:45:00  92.20939  92.501645  95.047788\n",
      "3858  2022-10-27 03:50:00  92.25292  92.505686  95.029456\n",
      "4257  2022-10-28 13:05:00  78.85083  79.370238  95.073208\n",
      "13315 2022-11-29 01:55:00  92.07666  92.129087  94.843426\n",
      "13316 2022-11-29 02:00:00  91.90587  92.133317  94.845615\n",
      "14751 2022-12-04 05:00:00  93.00941  93.195506  95.536439\n",
      "14752 2022-12-04 05:05:00  93.07246  93.168538  95.585254\n",
      "14947 2022-12-04 21:20:00  91.79874  92.212556  95.642344\n",
      "14948 2022-12-04 21:25:00  91.84959  92.217347  95.641340\n",
      "14949 2022-12-04 21:30:00  92.11701  92.214496  95.642058\n",
      "15236 2022-12-05 21:25:00  90.53499  90.862087  94.271923\n",
      "15276 2022-12-06 00:45:00  90.69221  90.774539  94.679402\n",
      "15277 2022-12-06 00:50:00  90.75159  90.782468  94.685690\n",
      "21054 2022-12-26 03:35:00  93.56341  93.564446  94.961123\n",
      "21055 2022-12-26 03:40:00  93.43678  93.571448  94.963167\n",
      "30777 2023-01-28 21:50:00  81.30425  81.427258  96.040974\n",
      "35075 2023-02-12 23:35:00  88.72794  88.740138  95.569257\n",
      "37329 2023-02-20 19:25:00  76.32178  77.090238  97.588899\n",
      "37608 2023-02-21 18:40:00  71.55945  71.656804  97.533580\n",
      "39668 2023-02-28 22:20:00  80.99947  81.498178  98.114548\n",
      "39958 2023-03-01 22:30:00  81.99368  82.804538  96.945011\n",
      "39959 2023-03-01 22:35:00  81.39751  82.804184  96.941649\n",
      "41990 2023-03-08 23:50:00  92.27836  92.377867  94.136167\n",
      "41991 2023-03-08 23:55:00  92.15173  92.378369  94.136137\n",
      "41992 2023-03-09 00:00:00  92.31229  92.381837  94.135527\n",
      "44586 2023-03-18 00:10:00  90.38782  90.479382  94.370803\n",
      "46003 2023-03-22 22:15:00  88.25247  88.586636  94.822944\n",
      "46004 2023-03-22 22:20:00  88.04781  88.588190  94.823777\n",
      "46056 2023-03-23 02:40:00  88.29655  88.444949  95.542029\n",
      "46316 2023-03-24 00:20:00  87.68881  88.127438  94.666999\n",
      "46317 2023-03-24 00:25:00  87.34790  88.123369  94.712230\n",
      "46318 2023-03-24 00:30:00  88.01502  88.122878  94.750081\n",
      "46398 2023-03-24 07:10:00  85.90568  87.094602  97.645394\n",
      "46399 2023-03-24 07:15:00  84.38883  87.094944  97.647580\n",
      "46400 2023-03-24 07:20:00  86.86452  87.095337  97.649402\n",
      "46627 2023-03-25 02:15:00  90.05976  90.533884  95.374415\n",
      "46628 2023-03-25 02:20:00  90.32816  90.532914  95.378871\n",
      "47040 2023-03-26 12:40:00  66.94051  67.548820  91.090411\n",
      "47041 2023-03-26 12:45:00  67.55688  67.586451  90.912982\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_coherPFvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1add052-3700-456b-b350-ffbb7610289f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_varminh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449b253-9dcb-4b22-896d-a898101a2cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffae449-bdf5-43d3-8a79-d968c7460a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe0a4d5f-ddfc-4cd6-a108-e43da098013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Fecha       Valor  mean_5  std_5  lim_inf  lim_sup\n",
      "37 2024-01-01 03:05:00  104.640878     NaN    NaN      NaN      NaN\n",
      "38 2024-01-01 03:10:00   99.756331     NaN    NaN      NaN      NaN\n",
      "39 2024-01-01 03:15:00   85.710635     NaN    NaN      NaN      NaN\n",
      "40 2024-01-01 03:20:00  107.027710     NaN    NaN      NaN      NaN\n",
      "41 2024-01-01 03:25:00   87.466289     NaN    NaN      NaN      NaN\n",
      "42 2024-01-01 03:30:00   83.890767     NaN    NaN      NaN      NaN\n",
      "43 2024-01-01 03:35:00  103.235479     NaN    NaN      NaN      NaN\n",
      "44 2024-01-01 03:40:00  103.962081     NaN    NaN      NaN      NaN\n",
      "45 2024-01-01 03:45:00   99.870471     NaN    NaN      NaN      NaN\n",
      "46 2024-01-01 03:50:00   90.447196     NaN    NaN      NaN      NaN\n",
      "47 2024-01-01 03:55:00   97.913549     NaN    NaN      NaN      NaN\n",
      "48 2024-01-01 04:00:00   84.935664     NaN    NaN      NaN      NaN\n",
      "49 2024-01-01 04:05:00   88.966224     NaN    NaN      NaN      NaN\n",
      "50 2024-01-01 04:10:00  100.865845     NaN    NaN      NaN      NaN\n",
      "51 2024-01-01 04:15:00   93.439276     NaN    NaN      NaN      NaN\n",
      "52 2024-01-01 04:20:00  114.404798     NaN    NaN      NaN      NaN\n",
      "53 2024-01-01 04:25:00  125.820880     NaN    NaN      NaN      NaN\n",
      "54 2024-01-01 04:30:00  107.605837     NaN    NaN      NaN      NaN\n",
      "55 2024-01-01 04:35:00   97.432725     NaN    NaN      NaN      NaN\n",
      "56 2024-01-01 04:40:00   89.545427     NaN    NaN      NaN      NaN\n",
      "                   Fecha       Valor    lim_inf     lim_sup\n",
      "661  2024-01-03 07:05:00   64.648208  67.056102  132.086953\n",
      "1064 2024-01-04 16:40:00   74.536740  75.427728  127.779217\n",
      "1150 2024-01-04 23:50:00  133.703102  68.188410  132.647666\n",
      "1683 2024-01-06 20:15:00  129.772833  73.952569  128.243561\n",
      "2158 2024-01-08 11:50:00  131.025765  71.190942  125.622187\n",
      "2304 2024-01-09 00:00:00   62.341030  63.187339  137.096880\n",
      "2436 2024-01-09 11:00:00  138.794513  69.563487  131.440833\n",
      "2466 2024-01-09 13:30:00   65.689654  66.889798  133.335547\n",
      "3987 2024-01-14 20:15:00   67.678146  72.089342  130.869052\n",
      "4167 2024-01-15 11:15:00   70.111195  70.190714  127.122173\n",
      "5282 2024-01-19 08:10:00  122.971305  74.976626  122.781743\n",
      "5353 2024-01-19 14:05:00  135.017440  65.428220  134.053098\n",
      "Revisar el archivo 'resultado_prueba.csv' para verificar los resultados.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Crear datos de prueba\n",
    "def crear_datos_prueba(frecuencia, num_datos):\n",
    "    fechas = pd.date_range(start='2024-01-01', periods=num_datos, freq=frecuencia)\n",
    "    valores = np.random.normal(loc=100, scale=10, size=num_datos)\n",
    "    datos = {'Fecha': fechas, 'Valor': valores, 'Station': ['TestStation'] * num_datos}\n",
    "    df_prueba = pd.DataFrame(datos)\n",
    "    return df_prueba\n",
    "\n",
    "# Simular la clase y la función\n",
    "class Validador:\n",
    "    def __init__(self):\n",
    "        self.last_rows = None\n",
    "        self.current_file = None\n",
    "    \n",
    "    def p_coher5vals(self, chunk, archivo):\n",
    "        '''Esta prueba verifica que un valor tenga coherencia con los 5 anteriores y 5 posteriores según su desviación estándar y media'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = None    \n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = None\n",
    "\n",
    "        ## Trabajo con frecuencias\n",
    "        # Asumimos un periodo fijo para simplificar\n",
    "        periodos = '5T'\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return chunk, None\n",
    "\n",
    "        ## Se asegura la revisión de 5 datos anteriores aún si cambia el chunk\n",
    "        # Verificar si el archivo ha cambiado\n",
    "        if self.current_file != archivo:\n",
    "            # Si el archivo cambió, resetea self.last_rows y actualiza self.current_file\n",
    "            self.last_rows = None\n",
    "            self.current_file = archivo\n",
    "        # Usar self.last_rows para concatenar con el chunk actual\n",
    "        if self.last_rows is not None:\n",
    "            chunk = pd.concat([self.last_rows, chunk])\n",
    "            chunk.reset_index(drop=True)\n",
    "\n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "\n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "\n",
    "        # Crear una columna de diferencia temporal\n",
    "        chunk['Fecha_anterior'] = chunk['Fecha'].shift(1)\n",
    "        chunk['Delta_tiempo'] = chunk['Fecha'] - chunk['Fecha_anterior']\n",
    "\n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos\n",
    "        if 'Estado' not in chunk.columns or chunk['Estado'].isnull().all():\n",
    "            chunk_5vals = chunk.copy()\n",
    "        else:\n",
    "            chunk_5vals = chunk[~chunk['Estado'].str.startswith(('0PER','0PAT'), na=False)].copy()\n",
    "\n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        mask_consecutivo = chunk_5vals['Delta_tiempo'] == pd.to_timedelta(periodos)\n",
    "        chunk_5vals['consec_group'] = (~mask_consecutivo).cumsum()\n",
    "\n",
    "        # Se establecen diferentes ventanas según frecuencias\n",
    "        windows = {'T': {'window': 240}, '5T': {'window': 72}, '10T': {'window': 48}, 'H': {'window': 11}}\n",
    "        window_size = windows[periodos]['window']\n",
    "        half_window = window_size // 2\n",
    "\n",
    "        # Filtrar grupos que tienen al menos el tamaño de ventana necesario\n",
    "        group_counts = chunk_5vals['consec_group'].value_counts()\n",
    "        valid_groups = group_counts[group_counts >= window_size].index\n",
    "        chnk_coh5vl = chunk_5vals[chunk_5vals['consec_group'].isin(valid_groups)]\n",
    "\n",
    "        # Verificar que los datos anteriores y posteriores sean consecutivos\n",
    "        valid_indices = []\n",
    "        for i in range(half_window, len(chnk_coh5vl) - half_window):\n",
    "            if all(mask_consecutivo[i-half_window:i+half_window]):\n",
    "                valid_indices.append(chnk_coh5vl.index[i])\n",
    "\n",
    "        chnk_coh5vl = chnk_coh5vl.loc[valid_indices]\n",
    "\n",
    "        # Calcular el promedio y desviación estándar de los registros anteriores y posteriores\n",
    "        chnk_coh5vl['mean_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).mean()\n",
    "        chnk_coh5vl['std_5'] = chnk_coh5vl['Valor'].rolling(window=window_size, center=True).std()\n",
    "\n",
    "        # Calcular los límites superior e inferior\n",
    "        chnk_coh5vl['lim_inf'] = chnk_coh5vl['mean_5'] - (3 * chnk_coh5vl['std_5'])\n",
    "        chnk_coh5vl['lim_sup'] = chnk_coh5vl['mean_5'] + (3 * chnk_coh5vl['std_5'])\n",
    "\n",
    "        # Añadir mensajes de depuración para verificar los límites\n",
    "        print(chnk_coh5vl[['Fecha', 'Valor', 'mean_5', 'std_5', 'lim_inf', 'lim_sup']].head(20))\n",
    "\n",
    "        # Máscara para identificar valores fuera de los límites\n",
    "        mask_var5prev = (chnk_coh5vl['Valor'] < chnk_coh5vl['lim_inf']) | (chnk_coh5vl['Valor'] > chnk_coh5vl['lim_sup'])\n",
    "        \n",
    "        # Añadir mensajes de depuración para verificar los valores fuera de los límites\n",
    "        print(chnk_coh5vl[mask_var5prev][['Fecha', 'Valor', 'lim_inf', 'lim_sup']])\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado', sospechoso, '0PSO0'\n",
    "        condicion_0PSO0 = mask_var5prev & (chnk_coh5vl['Estado'].isnull())\n",
    "        chnk_coh5vl.loc[condicion_0PSO0, 'Estado'] = '0PSO0'\n",
    "        mask_var5prev = mask_var5prev & ~condicion_0PSO0\n",
    "        # 0PSO1\n",
    "        condicion_0PSO1 = mask_var5prev & (chnk_coh5vl['Estado'] == '0PSO0')\n",
    "        chnk_coh5vl.loc[condicion_0PSO1, 'Estado'] = '0PSO1'\n",
    "        mask_var5prev = mask_var5prev & ~condicion_0PSO1\n",
    "        # 0PSO2\n",
    "        condicion_0PSO2 = mask_var5prev & (chnk_coh5vl['Estado'] == '0PSO1')\n",
    "        chnk_coh5vl.loc[condicion_0PSO2, 'Estado'] = '0PSO2'\n",
    "\n",
    "        # Se asegura la verificación de los valores anteriores si hubo cambio de chunk\n",
    "        self.last_rows = chnk_coh5vl.tail(5)\n",
    "\n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        if 'Fecha_anterior' in chunk.columns:\n",
    "            chunk.drop(columns=['Fecha_anterior','Delta_tiempo'], axis=1, inplace=True)\n",
    "\n",
    "        # Copiar datos de chunk_coher al chunk original\n",
    "        chunk.loc[chnk_coh5vl.index] = chnk_coh5vl\n",
    "        # Continuar eliminando filas\n",
    "        if 'mean_5' in chunk.columns:\n",
    "            chunk.drop(columns=['mean_5','std_5','lim_inf','lim_sup'], axis=1, inplace=True)\n",
    "\n",
    "        return chunk, mask_var5prev\n",
    "\n",
    "# Probar la función\n",
    "def probar_p_coher5vals():\n",
    "    # Crear un conjunto de datos de prueba\n",
    "    df_prueba = crear_datos_prueba('5T', 8000)  # Cambia '5T' y el número de datos según sea necesario\n",
    "\n",
    "    # Crear instancia de la clase Validador\n",
    "    validador = Validador()\n",
    "    \n",
    "    # Introducir algunos valores fuera de los límites para probar el etiquetado\n",
    "    df_prueba.loc[10:15, 'Valor'] = 200  # Valores anómalos que deberían ser etiquetados\n",
    "\n",
    "    # Aplicar la función\n",
    "    resultado_chunk, mask_var5prev = validador.p_coher5vals(df_prueba, 'archivo_prueba.csv')\n",
    "\n",
    "    # Guardar el resultado en un CSV para revisión manual\n",
    "    resultado_chunk.to_csv('resultado_prueba.csv', index=False)\n",
    "    \n",
    "    # Verificar si el resultado parece correcto\n",
    "    print(\"Revisar el archivo 'resultado_prueba.csv' para verificar los resultados.\")\n",
    "\n",
    "# Ejecutar la prueba\n",
    "probar_p_coher5vals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a62f93-ae2d-463a-b163-54b3ca3d3193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf873bc6-9ad6-4eef-aca7-86b415803ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1910ba-dde6-4667-9c5b-cac66bfc65bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
