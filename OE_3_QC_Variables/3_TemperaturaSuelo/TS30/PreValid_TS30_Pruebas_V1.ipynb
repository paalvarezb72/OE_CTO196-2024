{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f2b16b-912e-4a9b-98c0-5a393e545013",
   "metadata": {},
   "source": [
    "# Pruebas automatizadas datos humedad relativa - Clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885f6f6",
   "metadata": {},
   "source": [
    "> Elaborado por Paola Álvarez, profesional contratista IDEAM, contrato 196 de 2024. Comentarios o inquietudes, remitir a *palvarez@ideam.gov.co* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ebabc-ed05-4660-a06e-7c242cb0ffeb",
   "metadata": {},
   "source": [
    "**Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28398810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from functools import wraps\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14c1a4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7267c",
   "metadata": {},
   "source": [
    "A continuación, se encuentran las pruebas de pre-validación de datos de EMA para verificar su capacidad de detección de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3c8ea",
   "metadata": {},
   "source": [
    "## Clase con métodos de aplicación de QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21dab107-ab7e-48ae-939b-7b0a6b24ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del logger para guardar en el directorio de archivos y sobrescribir cada vez\n",
    "def setup_logger(log_file_path):\n",
    "    logger = logging.getLogger('RawUnmodified_TS30')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    # Clear existing handlers to avoid duplicate logs\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    file_handler = logging.FileHandler(log_file_path, mode='a')\n",
    "    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(file_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb424af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutomatTS30cmEMA:\n",
    "    \n",
    "    def __init__(self, dir_files, chunk_size=540000):\n",
    "        self.dir_files = dir_files\n",
    "        self.ruta_archivos = os.listdir(dir_files)\n",
    "        self.chunk_size = chunk_size\n",
    "        self.last_rows = None\n",
    "        self.current_file = None\n",
    "        # Sección configuración de logs\n",
    "        log_file_path = os.path.join(dir_files, 'QC_TS30.log')\n",
    "        self.logger = setup_logger(log_file_path)\n",
    "        self.logger.info('Inicialización de PreValidTS10EMA en directorio: %s', dir_files)\n",
    "\n",
    "    def process_freqs(self, chunk, archivo):\n",
    "        '''Esta función procesa las frecuencias para abreviar variedad de métodos en adelante'''\n",
    "        # Convertir la columna de fecha a datetime si aún no lo es\n",
    "        if not pd.api.types.is_datetime64_any_dtype(chunk['Fecha']):\n",
    "            chunk['Fecha'] = pd.to_datetime(chunk['Fecha'])\n",
    "            \n",
    "        # Cargar el archivo de frecuencias\n",
    "        freqinst200b = pd.read_csv('EMATS30_LatLonEntFreq.csv', encoding='latin-1', sep=';')\n",
    "    \n",
    "        # Definir el diccionario de frecuencias y cantidades esperadas\n",
    "        frecuencias = {\n",
    "            'min': {'cant_esperd_h': 60, 'cant_esperd_d': 1440, 'cant_esperd_m': 43200, \n",
    "                  'cant_esperd_a': 518400, 'minutos': 1, 'shiftnum': 90, 'jumpnum':3},\n",
    "            '5min': {'cant_esperd_h': 12, 'cant_esperd_d': 288, 'cant_esperd_m': 8640, \n",
    "                   'cant_esperd_a': 103680, 'minutos': 5, 'shiftnum': 25, 'jumpnum':3.5},\n",
    "            '10min': {'cant_esperd_h': 6, 'cant_esperd_d': 144, 'cant_esperd_m': 4320, \n",
    "                    'cant_esperd_a': 51840, 'minutos': 10, 'shiftnum': 18, 'jumpnum':4.0},\n",
    "            'h': {'cant_esperd_h': 1, 'cant_esperd_d': 24, 'cant_esperd_m': 720, \n",
    "                  'cant_esperd_a': 8640, 'shiftnum':10, 'jumpnum':4.5} ## Cambiar para adaptarse a directriz GGD\n",
    "        }\n",
    "    \n",
    "        # Obtener el valor de la estación\n",
    "        station_value = chunk['Station'].values[0]\n",
    "        if pd.isna(station_value):\n",
    "            print(f'La estación {station_value} no se encuentra en el análisis de frecuencias')\n",
    "            return {'periodos': None, 'frecuencias': None}\n",
    "        else:\n",
    "            freqinst200b_station = freqinst200b.loc[freqinst200b['Station'] == station_value]\n",
    "            if freqinst200b_station.empty:\n",
    "                print(f\"No se encontró la estación {station_value} en freqinst200b\")\n",
    "                return {'periodos': None, 'frecuencias': None}\n",
    "            else:\n",
    "                freq_inf_value = freqinst200b_station['FreqInf'].values[0]\n",
    "    \n",
    "            if pd.isna(freq_inf_value):\n",
    "                try:\n",
    "                    periodos = pd.infer_freq(chunk['Fecha'][-25:])\n",
    "                    print(periodos)\n",
    "                    if periodos is None:\n",
    "                        print(f\"Frecuencia inferida es None para el archivo {archivo}\")\n",
    "                        return {'periodos': None, 'frecuencias': None}\n",
    "                except ValueError as e:\n",
    "                    print(f'Error al inferir la frecuencia en el archivo {archivo}: {str(e)}')\n",
    "                    return {'periodos': None, 'frecuencias': None}\n",
    "            else:\n",
    "                periodos = freq_inf_value\n",
    "    \n",
    "        if periodos is None:\n",
    "            print(f\"Periodo es None para el archivo {archivo}\")\n",
    "            return {'periodos': None, 'frecuencias': None}\n",
    "    \n",
    "        if periodos in frecuencias:\n",
    "            return {'periodos': periodos, 'frecuencias': frecuencias[periodos]}\n",
    "        else:\n",
    "            print(f\"Periodo {periodos} no es reconocido en el diccionario de frecuencias\")\n",
    "            return {'periodos': None, 'frecuencias': None}\n",
    "\n",
    "    def p_transm(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si existe al menos el 70% de datos esperados por día y hora\n",
    "        en la serie de datos; aquellos que no superen la prueba, son marcados como sospechosos'''\n",
    "        # Se instancia el método 'process_freqs' para obtener las frecuencias \n",
    "        freq_info = self.process_freqs(chunk, archivo)\n",
    "        if freq_info is None or freq_info['periodos'] is None or freq_info['frecuencias'] is None:\n",
    "            print(f\"No se pudo obtener información de frecuencia para el archivo {archivo}\")\n",
    "            return chunk\n",
    "        \n",
    "        periodos = freq_info['periodos']\n",
    "        frecuencias = freq_info['frecuencias']\n",
    "\n",
    "        # Obtener las cantidades esperadas de acuerdo a la frecuencia\n",
    "        cant_esperd_h = frecuencias['cant_esperd_h']\n",
    "        cant_esperd_d = frecuencias['cant_esperd_d']\n",
    "    \n",
    "        # Se establecen los aceptables\n",
    "        cant_aceptab_hora = 0.7 * cant_esperd_h\n",
    "        cant_aceptab_dia = 0.7 * cant_esperd_d\n",
    "    \n",
    "        # Agregar columna de etiquetas al dataframe original\n",
    "        chunk['Estado'] = ''\n",
    "        \n",
    "        # Definir función para asignar etiquetas y llenar archivo log\n",
    "        def asignar_etiqueta(row):\n",
    "            if row['count'] < cant_aceptab_hora:\n",
    "                filas_fallidas = chunk.loc[chunk['Fecha'].dt.floor('h') == row['Fecha'].floor('h')]\n",
    "                chunk.loc[filas_fallidas.index, 'Estado'] = '0PSO0'\n",
    "                # Registrar en el log las filas que fallaron\n",
    "                for index, fila in filas_fallidas.iterrows():\n",
    "                    self.logger.info('File %s - Row %s - failed hour p_transm: %s', archivo, index, fila['Fecha'])\n",
    "\n",
    "        # Evaluar por cada grupo de datos por hora y asignar la etiqueta\n",
    "        canthora = chunk.groupby(chunk['Fecha'].dt.floor('h')).size().reset_index(name='count')\n",
    "        canthora.apply(asignar_etiqueta, axis=1)\n",
    "        \n",
    "        # Definir función para asignar etiquetas de acumulado diario y llenar archivo log\n",
    "        def asignar_etiqueta_diaria(row):\n",
    "            if row['count'] < cant_aceptab_dia:\n",
    "                filas_fallidas_dia = chunk.loc[chunk['Fecha'].dt.floor('D') == row['Fecha'].floor('D')]\n",
    "                chunk.loc[filas_fallidas_dia.index, 'Estado'] = '0PSO0'\n",
    "                # Registrar en el log las filas que fallaron\n",
    "                for index, fila in filas_fallidas_dia.iterrows():\n",
    "                    self.logger.info('File %s - Row %s - failed day p_transm: %s', archivo, index, fila['Fecha'])\n",
    "\n",
    "        # Evaluar por cada grupo de datos por día y asignar la etiqueta\n",
    "        cantdia = chunk.groupby(chunk['Fecha'].dt.floor('D')).size().reset_index(name='count')\n",
    "        cantdia.apply(asignar_etiqueta_diaria, axis=1)\n",
    "        \n",
    "        return chunk\n",
    "\n",
    "    def p_estruc(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si los datos fueron transmitidos en horas y minutos exactos al ser el\n",
    "        comportamiento esperado'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = ''\n",
    "        # Se instancia el método 'process_freqs' para obtener las frecuencias \n",
    "        freq_info = self.process_freqs(chunk, archivo)\n",
    "        # Se verifica si 'freq_info' is None\n",
    "        if freq_info is None or freq_info['periodos'] is None or freq_info['frecuencias'] is None:\n",
    "            print(f\"No se pudo obtener información de frecuencia para el archivo {archivo}\")\n",
    "            return chunk\n",
    "        periodos =  freq_info['periodos']\n",
    "        frecuencias = freq_info['frecuencias']\n",
    "\n",
    "        # Generar la operación para observar si la estructura es exacta en minutos\n",
    "        fecha = chunk['Fecha']\n",
    "    \n",
    "        # Se vectoriza la evaluación de la estructura por minuto para cada chunk:\n",
    "        if periodos == 'min':\n",
    "            mask_estr = fecha.dt.second != 0\n",
    "        elif periodos == 'h':\n",
    "            mask_estr = (fecha.dt.minute != 0) | (fecha.dt.second != 0)\n",
    "        else:\n",
    "            # Se obtiene num_para_modulo\n",
    "            num_para_modulo = frecuencias['minutos']\n",
    "            mask_estr = fecha.dt.minute % num_para_modulo != 0\n",
    "    \n",
    "        # Se registran los errores en el log\n",
    "        if mask_estr.any():\n",
    "           aligned_mask = mask_estr.reindex(chunk.index, fill_value=False)\n",
    "           for index, row in chunk[aligned_mask].iterrows():\n",
    "               self.logger.info('File %s - Row %s - failed time p_estruc: %s', archivo, index, row['Fecha'])\n",
    "        else:\n",
    "           self.logger.info('File: %s - No se encontraron fallos en p_estruc', archivo)\n",
    "        \n",
    "        chunk['Estado'] = chunk['Estado'].fillna('')\n",
    "        # Lógica de etiquetado para 'Estado', sospechoso, '0PSO0'\n",
    "        condicion_0PSO0 = mask_estr & (chunk['Estado']=='')\n",
    "        chunk.loc[condicion_0PSO0, 'Estado'] = '0PSO0'\n",
    "        mask_estr = mask_estr & ~condicion_0PSO0\n",
    "        # 0PSO1\n",
    "        condicion_0PSO1 = mask_estr & (chunk['Estado'] == '0PSO0')\n",
    "        chunk.loc[condicion_0PSO1, 'Estado'] = '0PSO1'\n",
    "\n",
    "        return chunk\n",
    "\n",
    "    def p_limrig(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si los datos crudos se encuentran fuera del umbral físico inferior o superior'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = ''\n",
    "        # Se genera la columna de estado anterior\n",
    "        chunk['Estado_Anterior'] = ''\n",
    "        \n",
    "        # Se establecen los umbrales físicos/rígidos a datos crudos en nuevas colummnas para vectorizar\n",
    "        chunk['umbr_crud_inf'] = -15.0\n",
    "        chunk['umbr_crud_sup'] = 40.0\n",
    "\n",
    "        # Compara el dato con umbrales inferiores y superiores \n",
    "        mask_outbounds = (chunk['Valor'] < chunk['umbr_crud_inf']) | (chunk['Valor'] > chunk['umbr_crud_sup'])\n",
    "\n",
    "        # Se registran los errores en el log\n",
    "        if mask_outbounds.any():\n",
    "            aligned_mask_lr = mask_outbounds.reindex(chunk.index, fill_value=False)\n",
    "            for index, row in chunk[aligned_mask_lr].iterrows():\n",
    "                self.logger.info('File %s - Row %s - failed val p_limrig: %s', archivo, index, row['Valor'])\n",
    "        else:\n",
    "            self.logger.info('File: %s - No se encontraron fallos en p_limrig', archivo)\n",
    "\n",
    "        chunk['Estado'] = chunk['Estado'].fillna('')\n",
    "        # Lógica de etiquetado para 'Estado_Anterior'\n",
    "        condicion_0PSO0 = mask_outbounds & chunk['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
    "        # Lógica de etiquetado para 'Estado'\n",
    "        condicion_0PER0 = mask_outbounds & ((chunk['Estado']=='') | chunk['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk.loc[condicion_0PER0, 'Estado'] = '0PER0'\n",
    "        \n",
    "        # Se eliminan las columnas no deseadas\n",
    "        if 'umbr_crud_inf' in chunk.columns:\n",
    "            chunk.drop(columns=['umbr_crud_inf', 'umbr_crud_sup'], axis=1, inplace=True)\n",
    "                \n",
    "        return chunk\n",
    "\n",
    "    def p_perst(self, chunk, archivo):\n",
    "        '''Esta prueba detecta los datos que se repiten por más de cuatro horas consecutivas'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = ''    \n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = ''\n",
    "\n",
    "        # Verificar si el archivo ha cambiado\n",
    "        if self.current_file != archivo:\n",
    "            # Si el archivo cambió, resetea self.last_rows y actualiza self.current_file\n",
    "            self.last_rows = None\n",
    "            self.current_file = archivo\n",
    "            \n",
    "        # Guardar referencia a las filas originales del chunk actual\n",
    "        original_chunk = chunk.copy()\n",
    "            \n",
    "        # Usar self.last_rows para concatenar con el chunk actual\n",
    "        if self.last_rows is not None:\n",
    "            chunk = pd.concat([self.last_rows, chunk])\n",
    "            chunk.reset_index(drop=True)\n",
    "\n",
    "        # Verificar y eliminar duplicados en el índice después de la concatenación\n",
    "        if not chunk.index.is_unique:\n",
    "            chunk = chunk.reset_index(drop=True)  # Crear un nuevo índice único\n",
    "\n",
    "        # Crear una etiqueta temporal para saber qué filas provienen del chunk anterior\n",
    "        if self.last_rows is not None:\n",
    "            chunk['from_previous_chunk'] = [True] * len(self.last_rows) + [False] * len(original_chunk)\n",
    "        else:\n",
    "            chunk['from_previous_chunk'] = [False] * len(original_chunk)\n",
    "\n",
    "        # Se crean máscaras para el intervalo del día con radiación solar que puede afectar la humedad\n",
    "        mask_sunny = (chunk['Fecha'].dt.hour >= 5) & (chunk['Fecha'].dt.hour <= 19)\n",
    "        # Se filtran los datos para esas horas\n",
    "        mask_sun = chunk[mask_sunny]\n",
    "\n",
    "        ## Se manejan las distintas frecuencias para verificar adecuadamente las persistencias\n",
    "        # Se instancia el método 'process_freqs' para obtener las frecuencias \n",
    "        freq_info = self.process_freqs(chunk, archivo)\n",
    "        # Se verifica si 'freq_info' is None\n",
    "        if freq_info is None or freq_info['periodos'] is None or freq_info['frecuencias'] is None:\n",
    "            print(f\"No se pudo obtener información de frecuencia para el archivo {archivo}\")\n",
    "            return original_chunk\n",
    "        \n",
    "        # Se accede a las claves del diccionario\n",
    "        periodos =  freq_info['periodos']\n",
    "        # Se accede a los datos del diccionario\n",
    "        frecuencias = freq_info['frecuencias']\n",
    "        # Se asignan los shiftnums\n",
    "        cantshifts = frecuencias['shiftnum']\n",
    "        \n",
    "        # Crear una lista de máscaras usando una lista por comprensión\n",
    "        masks = [(mask_sun['Valor'] == mask_sun['Valor'].shift(i)) for i in range(1, cantshifts + 1)]\n",
    "\n",
    "        # Combinar todas las máscaras usando reduce y operador &\n",
    "        from functools import reduce\n",
    "        mask_persdatos = reduce(lambda x, y: x & y, masks)\n",
    "        \n",
    "        #chunk.reset_index(drop=True)\n",
    "        # Se registran los errores en el log\n",
    "        if mask_persdatos.any():\n",
    "            aligned_mask_pers = mask_persdatos.reindex(chunk.index, fill_value=False)\n",
    "            for index, row in chunk[aligned_mask_pers].iterrows():\n",
    "                self.logger.info('File %s - Row %s - failed val p_perst: %s', archivo, index, row['Valor'])\n",
    "        else:\n",
    "            self.logger.info('File: %s - No se encontraron fallos en p_perst', archivo)\n",
    "\n",
    "        chunk['Estado'] = chunk['Estado'].fillna('')\n",
    "        # Etiquetado de valores, se inicia con el Estado Anterior\n",
    "        condicion_0PSO0 = mask_persdatos & chunk['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Lógica de etiquetado para 'Estado'\n",
    "        condicion_0PER0 = mask_persdatos & ((chunk['Estado']=='') | chunk['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk.loc[condicion_0PER0, 'Estado'] = '0PER0'\n",
    "        mask_persdatos = mask_persdatos & ~condicion_0PER0\n",
    "\n",
    "        condicion_0PER1 = mask_persdatos & (chunk['Estado'] == '0PER0')\n",
    "        chunk.loc[condicion_0PER1, 'Estado'] = '0PER1'\n",
    "\n",
    "        # Eliminar solo las filas del chunk anterior que fueron evaluadas\n",
    "        chunk = chunk[~chunk['from_previous_chunk']].copy()\n",
    "\n",
    "        # Eliminar la columna temporal\n",
    "        chunk.drop(columns=['from_previous_chunk'], inplace=True)\n",
    "\n",
    "        # Actualizar las filas de self.last_rows para el próximo chunk\n",
    "        self.last_rows = chunk.tail(cantshifts).copy()\n",
    "\n",
    "        return chunk\n",
    "\n",
    "    def p_jump(self, chunk, archivo):\n",
    "        '''Esta prueba verifica si la variación entre valores consecutivos excede 45.0 %'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = ''\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = ''\n",
    "\n",
    "        # Se hace una instancia del método de 'process_freqs' para obtener las frecuencias\n",
    "        freq_info = self.process_freqs(chunk, archivo)\n",
    "        if freq_info is None or freq_info['periodos'] is None or freq_info['frecuencias'] is None:\n",
    "            print(f\"No se pudo obtener información de frecuencia para el archivo {archivo}\")\n",
    "            return chunk\n",
    "\n",
    "        periodos = freq_info['periodos']\n",
    "        frecuencias = freq_info['frecuencias']\n",
    "\n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "        \n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "        \n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos\n",
    "        chunk['Estado'] = chunk['Estado'].fillna('')\n",
    "        if chunk['Estado'].notna().all(): # Se verifica que no hayan valores nulos en tal columna\n",
    "            chunk_jmp = chunk[~chunk['Estado'].str.startswith('0PER', na=False)].copy()\n",
    "        else:\n",
    "            # Si todos los valores son NaN, se copia el chunk\n",
    "            chunk_jmp = chunk.copy()\n",
    "        \n",
    "        # Crear una columna de diferencia temporal\n",
    "        chunk_jmp['Fecha_anterior'] = chunk_jmp['Fecha'].shift(1)\n",
    "        chunk_jmp['Delta_tiempo'] = chunk_jmp['Fecha'] - chunk_jmp['Fecha_anterior']\n",
    "        \n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        mask_consecutivo = chunk_jmp['Delta_tiempo'] == pd.to_timedelta(periodos)\n",
    "        \n",
    "        # Calcular la diferencia absoluta entre los valores consecutivos\n",
    "        chunk_jmp['Delta'] = chunk_jmp['Valor'].diff().abs()\n",
    "        chunk_jmp['Delta'] = chunk_jmp['Delta'].where(mask_consecutivo)\n",
    "\n",
    "        # Se determina número de salto\n",
    "        jumpnum = frecuencias['jumpnum']\n",
    "        \n",
    "        # Máscara para identificar variaciones mayores al número determinado para cada frecuencia\n",
    "        mask_variacion = chunk_jmp['Delta'] > jumpnum\n",
    "\n",
    "        # Se registran los errores en el log\n",
    "        if mask_variacion.any():\n",
    "            aligned_mask_salto = mask_variacion.reindex(chunk_jmp.index, fill_value=False)\n",
    "            for index, row in chunk_jmp[aligned_mask_salto].iterrows():\n",
    "                self.logger.info('File %s - Row %s - failed val p_jump: %s', archivo, index, row['Valor'])\n",
    "        else:\n",
    "            self.logger.info('File: %s - No se encontraron fallos en p_jump', archivo)\n",
    "      \n",
    "        # Etiquetado de valores, se inicia con el Estado Anterior\n",
    "        condicion_0PSO0 = mask_variacion & chunk_jmp['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
    "        \n",
    "        chunk_jmp['Estado'] = chunk_jmp['Estado'].fillna('')\n",
    "        ## Actualización de estado\n",
    "        # Condición llenado de 'Estado_Anterior', si aplica\n",
    "        condicion_0PSO0 = mask_variacion & chunk_jmp['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Se etiquetan los atípicos\n",
    "        condicion_0PAT0 = mask_variacion & ((chunk_jmp['Estado'] == '') | chunk_jmp['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk_jmp.loc[condicion_0PAT0, 'Estado'] = '0PAT0'\n",
    "\n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        chunk_jmp.drop(columns=['Delta', 'Fecha_anterior', 'Delta_tiempo'], axis=1, inplace=True)\n",
    "        \n",
    "        # Se copia al chunk original\n",
    "        chunk.loc[chunk_jmp.index] = chunk_jmp\n",
    "        return chunk\n",
    "\n",
    "    def p_valvminmax(self, chunk, archivo):\n",
    "        '''Esta prueba detecta los datos que son máximos y mínimos en horarios distintos a los conocidos en cada periodo semidiurno\n",
    "        y los marca como atípicos'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = ''\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = ''\n",
    "\n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos\n",
    "        chunk['Estado'] = chunk['Estado'].fillna('')\n",
    "        if chunk['Estado'].notna().all(): # Se verifica que no hayan valores nulos en tal columna\n",
    "            chunk_hm = chunk[~chunk['Estado'].str.startswith('0PER', na=False)].copy()\n",
    "        else:\n",
    "            # Si todos los valores son NaN, se copia el chunk\n",
    "            chunk_hm = chunk.copy()\n",
    "            \n",
    "        # Se crean máscaras para los intervalos de tiempo conocidos para valores mínimos\n",
    "        mask_min_morning = (chunk_hm['Fecha'].dt.hour >= 0) & (chunk_hm['Fecha'].dt.hour <= 6)\n",
    "        mask_min_evening = (chunk_hm['Fecha'].dt.hour >= 19) & (chunk_hm['Fecha'].dt.hour <= 23)\n",
    "        mask_max = (chunk_hm['Fecha'].dt.hour > 6) & (chunk_hm['Fecha'].dt.hour < 19)\n",
    "        # Se filtran los datos para esas horas\n",
    "        min_validdata = chunk_hm[mask_min_morning | mask_min_evening ]\n",
    "        max_validdata = chunk_hm[mask_max]\n",
    "\n",
    "        # Encontrar dos valores mínimos por día\n",
    "        min_values = chunk_hm.groupby(chunk_hm['Fecha'].dt.date).apply(lambda x: x.nsmallest(1, 'Valor')).reset_index(level=0, drop=True)\n",
    "        # Encontrar los dos valores máximos por día\n",
    "        max_values = chunk_hm.groupby(chunk_hm['Fecha'].dt.date).apply(lambda x: x.nlargest(1, 'Valor')).reset_index(level=0, drop=True)\n",
    "\n",
    "        # Verificar los mínimos y obtener las horas correspondientes\n",
    "        notvalid_max_values = max_values[~max_values.index.isin(max_validdata.index)]\n",
    "        notvalid_min_values = min_values[~min_values.index.isin(min_validdata.index)]        \n",
    "\n",
    "        # Combinar los valores no válidos en un solo DataFrame\n",
    "        notvalid_values = pd.concat([notvalid_max_values, notvalid_min_values])\n",
    "        # Crear una máscara para identificar los índices de los valores no válidos\n",
    "        notval_maxmin = chunk_hm.index.isin(notvalid_values.index)\n",
    "\n",
    "        # Se registran los errores en el log\n",
    "        if notval_maxmin.any():\n",
    "            for index, row in chunk_hm[notval_maxmin].iterrows():\n",
    "                self.logger.info('File %s - Row %s - failed val p_valvminmax: %s', archivo, index, row['Valor'])\n",
    "        else:\n",
    "            self.logger.info('File: %s - No se encontraron fallos en p_valvminmax', archivo)\n",
    "        \n",
    "        chunk_hm['Estado'] = chunk_hm['Estado'].fillna('')\n",
    "        ## Actualización de estado\n",
    "        # Condición llenado de 'Estado_Anterior', si aplica\n",
    "        condicion_0PSO0 = notval_maxmin & chunk_hm['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Se etiquetan los atípicos\n",
    "        condicion_0PAT0 = notval_maxmin & ((chunk_hm['Estado'] == '') | chunk_hm['Estado'].isin(['0PSO0', '0PSO1'])) #notval_maxmin\n",
    "        chunk_hm.loc[condicion_0PAT0, 'Estado'] = '0PAT0'\n",
    "        notval_maxmin = notval_maxmin & ~condicion_0PAT0\n",
    "        \n",
    "        condicion_0PAT1 = notval_maxmin & (chunk_hm['Estado'] == '0PAT0')\n",
    "        chunk_hm.loc[condicion_0PAT1, 'Estado'] = '0PAT1'\n",
    "\n",
    "        # Se copia al chunk original\n",
    "        chunk.loc[chunk_hm.index] = chunk_hm\n",
    "        return chunk\n",
    "        \n",
    "    def p_sigma(self, chunk, archivo):\n",
    "        '''Esta prueba calcula, con los datos no etiquetados como erróneos, 4sigmas +- la media -como líms sup e inf- para detectar\n",
    "        datos atípicos en cada estación'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = ''\n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = ''\n",
    "\n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos\n",
    "        chunk['Estado'] = chunk['Estado'].fillna('')\n",
    "        if chunk['Estado'].notna().all(): # Se verifica que no hayan valores nulos en tal columna\n",
    "            chunk_sgm = chunk[~chunk['Estado'].str.startswith('0PER', na=False)].copy()\n",
    "        else:\n",
    "            # Si todos los valores son NaN, simplemente copia el chunk\n",
    "            chunk_sgm = chunk.copy()\n",
    "\n",
    "        # Se calculan los estadísticos para sigma\n",
    "        mean = chunk_sgm['Valor'].mean()\n",
    "        std = chunk_sgm['Valor'].std()\n",
    "        # Con ellos, se establecen los límites superior e inferior\n",
    "        chunk_sgm['LimSup_Sigma'] = (mean + (4 * std))\n",
    "        chunk_sgm['LimInf_Sigma'] = (mean - (4 * std))\n",
    "\n",
    "        # Se etiquetan los valores que sobrepasen el límite\n",
    "        mask_outbsigma = (chunk_sgm['Valor'] < chunk_sgm['LimInf_Sigma']) | (chunk_sgm['Valor'] > chunk_sgm['LimSup_Sigma'])\n",
    "\n",
    "        # Se registran los errores en el log\n",
    "        if mask_outbsigma.any():\n",
    "            aligned_mask_sigma = mask_outbsigma.reindex(chunk_sgm.index, fill_value=False)\n",
    "            for index, row in chunk_sgm[aligned_mask_sigma].iterrows():\n",
    "                self.logger.info('File %s - Row %s - failed val p_sigma: %s', archivo, index, row['Valor'])\n",
    "        else:\n",
    "            self.logger.info('File: %s - No se encontraron fallos en p_sigma', archivo)\n",
    "        \n",
    "        chunk_sgm['Estado'] = chunk_sgm['Estado'].fillna('')\n",
    "        ## Actualización de estado\n",
    "        # Condición llenado de 'Estado_Anterior', si aplica\n",
    "        condicion_0PSO0 = mask_outbsigma & chunk_sgm['Estado'].isin(['0PSO0', '0PSO1'])\n",
    "        chunk_sgm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_sgm.loc[condicion_0PSO0, 'Estado']\n",
    "\n",
    "        # Se etiquetan los atípicos - '0PAT0'\n",
    "        condicion_0PAT0 = mask_outbsigma & ((chunk_sgm['Estado'] == '') | chunk_sgm['Estado'].isin(['0PSO0', '0PSO1']))\n",
    "        chunk_sgm.loc[condicion_0PAT0, 'Estado'] = '0PAT0'\n",
    "        mask_outbsigma = mask_outbsigma & ~condicion_0PAT0\n",
    "        # 0PAT1\n",
    "        condicion_0PAT1 = mask_outbsigma & (chunk_sgm['Estado'] == '0PAT0')\n",
    "        chunk_sgm.loc[condicion_0PAT1, 'Estado'] = '0PAT1'\n",
    "        mask_outbsigma = mask_outbsigma & ~condicion_0PAT1\n",
    "        # 0PAT2\n",
    "        condicion_0PAT2 = mask_outbsigma & (chunk_sgm['Estado'] == '0PAT1')\n",
    "        chunk_sgm.loc[condicion_0PAT2, 'Estado'] = '0PAT2'\n",
    "                    \n",
    "        # Se eliminan las columnas no deseadas\n",
    "        if 'LimSup_Sigma' in chunk.columns:\n",
    "            chunk.drop(columns=['LimSup_Sigma', 'LimInf_Sigma'], axis=1, inplace=True)\n",
    "    \n",
    "        chunk.loc[chunk_sgm.index] = chunk_sgm\n",
    "        return chunk\n",
    "\n",
    "    def p_coherPNv(self, chunk, archivo):\n",
    "        '''Esta prueba verifica que un valor tenga coherencia con los 5 valores anteriores y los 5 posteriores\n",
    "        según su desviación estándar y media'''\n",
    "        # Se crea la columna 'Estado' si no existe\n",
    "        if 'Estado' not in chunk.columns:\n",
    "            chunk['Estado'] = ''    \n",
    "        # Se genera la columna 'Estado_anterior' si no existe\n",
    "        if 'Estado_Anterior' not in chunk.columns:\n",
    "            chunk['Estado_Anterior'] = ''\n",
    "            \n",
    "        ## Trabajo con frecuencias\n",
    "        # Se hace una instancia del método de 'process_freqs' para obtener las frecuencias\n",
    "        freq_info = self.process_freqs(chunk, archivo)\n",
    "        if freq_info is None or freq_info['periodos'] is None or freq_info['frecuencias'] is None:\n",
    "            print(f\"No se pudo obtener información de frecuencia para el archivo {archivo}\")\n",
    "            return chunk\n",
    "\n",
    "        periodos = freq_info['periodos']\n",
    "        frecuencias = freq_info['frecuencias']\n",
    "\n",
    "        ## Se asegura la revisión de 5 datos anteriores aún si cambia el chunk\n",
    "        # Verificar si el archivo ha cambiado\n",
    "        if self.current_file != archivo:\n",
    "            # Si el archivo cambió, resetea self.last_rows y actualiza self.current_file\n",
    "            self.last_rows = None\n",
    "            self.current_file = archivo\n",
    "        # Usar self.last_rows para concatenar con el chunk actual\n",
    "        if self.last_rows is not None:\n",
    "            chunk = pd.concat([self.last_rows, chunk])\n",
    "            chunk.reset_index(drop=True)\n",
    "    \n",
    "        # Ordenar el chunk por la columna 'Fecha'\n",
    "        chunk = chunk.sort_values('Fecha').reset_index(drop=True)\n",
    "\n",
    "        # Asegurarse de que 'periodos' tenga un número antes de la unidad\n",
    "        if periodos.isalpha():\n",
    "            periodos = '1' + periodos\n",
    "\n",
    "        # Crear una columna de diferencia temporal\n",
    "        chunk['Fecha_anterior'] = chunk['Fecha'].shift(1)\n",
    "        chunk['Delta_tiempo'] = chunk['Fecha'] - chunk['Fecha_anterior']\n",
    "\n",
    "        # Se genera filtro para no considerar datos ya catalogados como erróneos o atípicos\n",
    "        chunk['Estado'] = chunk['Estado'].fillna('')\n",
    "        if 'Estado' not in chunk.columns or (chunk['Estado'] == '').all():\n",
    "            chunk_PFvals = chunk.copy()\n",
    "        else:\n",
    "            chunk_PFvals = chunk[~chunk['Estado'].str.startswith(('0PER','0PAT'), na=False)].copy()\n",
    "\n",
    "        # Crear una máscara para identificar filas consecutivas según la frecuencia esperada\n",
    "        mask_consecutivo = chunk_PFvals['Delta_tiempo'] == pd.to_timedelta(periodos)\n",
    "        chunk_PFvals['consec_group'] = (~mask_consecutivo).cumsum()\n",
    "\n",
    "        # Se establecen diferentes ventanas según frecuencias\n",
    "        windows = {'1min': {'window': 240}, '5min': {'window': 72}, '10min': {'window': 48}, '1h': {'window': 11}}\n",
    "        window_size = windows[periodos]['window']\n",
    "        half_window = window_size // 2\n",
    "\n",
    "        # Filtrar grupos que tienen al menos el tamaño de ventana necesario\n",
    "        group_counts = chunk_PFvals['consec_group'].value_counts()\n",
    "        valid_groups = group_counts[group_counts >= window_size].index\n",
    "        chnk_cohPFvl = chunk_PFvals[chunk_PFvals['consec_group'].isin(valid_groups)]\n",
    "\n",
    "        # Verificar que los datos anteriores y posteriores sean consecutivos\n",
    "        valid_indices = []\n",
    "        for i in range(half_window, len(chnk_cohPFvl) - half_window):\n",
    "            if all(mask_consecutivo[i-half_window:i+half_window]):\n",
    "                valid_indices.append(chnk_cohPFvl.index[i])\n",
    "\n",
    "        chnk_cohPFvl = chnk_cohPFvl.loc[valid_indices]\n",
    "\n",
    "        # Calcular el promedio y desviación estándar de los registros anteriores y posteriores\n",
    "        chnk_cohPFvl['mean_PF'] = chnk_cohPFvl['Valor'].rolling(window=window_size, center=True).mean()\n",
    "        chnk_cohPFvl['std_PF'] = chnk_cohPFvl['Valor'].rolling(window=window_size, center=True).std()\n",
    "\n",
    "        # Calcular los límites superior e inferior\n",
    "        chnk_cohPFvl['lim_inf'] = chnk_cohPFvl['mean_PF'] - (3 * chnk_cohPFvl['std_PF'])\n",
    "        chnk_cohPFvl['lim_sup'] = chnk_cohPFvl['mean_PF'] + (3 * chnk_cohPFvl['std_PF'])\n",
    "\n",
    "        # Máscara para identificar valores fuera de los límites\n",
    "        mask_varPF = (chnk_cohPFvl['Valor'] < chnk_cohPFvl['lim_inf']) | (chnk_cohPFvl['Valor'] > chnk_cohPFvl['lim_sup'])\n",
    "\n",
    "        # Se registran los errores en el log\n",
    "        if mask_varPF.any():\n",
    "            aligned_mask_sigma = mask_varPF.reindex(chnk_cohPFvl.index, fill_value=False)\n",
    "            for index, row in chnk_cohPFvl[aligned_mask_sigma].iterrows():\n",
    "                self.logger.info('File %s - Row %s - failed val p_coherPNv %s', archivo, index, row['Valor'])\n",
    "        else:\n",
    "            self.logger.info('File: %s - No se encontraron fallos en p_coherPNv', archivo)\n",
    "        \n",
    "        chnk_cohPFvl['Estado'] = chnk_cohPFvl['Estado'].fillna('')\n",
    "        # Lógica de etiquetado para 'Estado', sospechoso, '0PSO0'\n",
    "        condicion_0PSO0 = mask_varPF & ((chnk_cohPFvl['Estado'] == ''))\n",
    "        chnk_cohPFvl.loc[condicion_0PSO0, 'Estado'] = '0PSO0'\n",
    "        mask_varPF = mask_varPF & ~condicion_0PSO0\n",
    "        # 0PSO1\n",
    "        condicion_0PSO1 = mask_varPF & (chnk_cohPFvl['Estado'] == '0PSO0')\n",
    "        chnk_cohPFvl.loc[condicion_0PSO1, 'Estado'] = '0PSO1'\n",
    "        mask_varPF = mask_varPF & ~condicion_0PSO1\n",
    "        # 0PSO2\n",
    "        condicion_0PSO2 = mask_varPF & (chnk_cohPFvl['Estado'] == '0PSO1')\n",
    "        chnk_cohPFvl.loc[condicion_0PSO2, 'Estado'] = '0PSO2'\n",
    "    \n",
    "        # Se asegura la verificación de los valores anteriores si hubo cambio de chunk\n",
    "        self.last_rows = chnk_cohPFvl.tail(5)\n",
    "\n",
    "        # Eliminar las columnas temporales antes de devolver el chunk\n",
    "        if 'Fecha_anterior' in chunk.columns:\n",
    "            chunk.drop(columns=['Fecha_anterior','Delta_tiempo'], axis=1, inplace=True)\n",
    "            \n",
    "        # Copiar datos de chunk_coher al chunk original\n",
    "        chunk.loc[chnk_cohPFvl.index] = chnk_cohPFvl\n",
    "        # Continuar eliminando filas\n",
    "        if 'mean_PF' in chunk.columns:\n",
    "            chunk.drop(columns=['mean_PF','std_PF','lim_inf','lim_sup'], axis=1, inplace=True)\n",
    "        \n",
    "        return chunk\n",
    "\n",
    "    def procesar_archivos(self, funcion_evaluacion):\n",
    "        '''Este método procesa la lectura y guardado de los archivos para todas las pruebas'''\n",
    "        archivos = self.ruta_archivos\n",
    "\n",
    "        archivos_salida = []  # Lista para almacenar nombres de archivos de salida\n",
    "\n",
    "        # Se recorre cada archivo en la carpeta\n",
    "        for archivo in archivos:\n",
    "            if archivo.endswith('.csv'):\n",
    "                ruta_archivo = os.path.join(self.dir_files, archivo)\n",
    "\n",
    "                reader = pd.read_csv(ruta_archivo, encoding='latin-1', chunksize=self.chunk_size)#,dtype={7: 'str'}, low_memory=False)\n",
    "                resultados = []\n",
    "\n",
    "                for chunk in reader:\n",
    "                    try:\n",
    "                        chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                    except ValueError:\n",
    "                        chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                    chunk['Station'] = chunk['Station'].astype('int64')\n",
    "\n",
    "                    # try:\n",
    "                    #     chunk_resultado, _ = funcion_evaluacion(chunk, archivo)  # Desempaqueta solo el DataFrame\n",
    "                    # except ValueError:\n",
    "                    chunk_resultado = funcion_evaluacion(chunk, archivo)  # Desempaqueta solo el DataFrame\n",
    "                    resultados.append(chunk_resultado)\n",
    "\n",
    "                if not resultados:  # Se verifica si la lista está vacía\n",
    "                    self.logger.warning('No hay resultados válidos para concatenar en el archivo %s. Continuando con el siguiente.', archivo)\n",
    "                    continue\n",
    "                    \n",
    "                resultados_consolidados = pd.concat(resultados)\n",
    "\n",
    "                # Genera el nombre del archivo de salida conservando los primeros 19 caracteres del nombre del archivo original\n",
    "                nombre_archivo_salida = archivo[:19] + '_qc.csv'\n",
    "\n",
    "                resultados_consolidados.to_csv(os.path.join(self.dir_files, nombre_archivo_salida), encoding='latin-1', index=False)\n",
    "\n",
    "                archivos_salida.append(nombre_archivo_salida)  # Agregar el nombre del archivo a la lista\n",
    "            \n",
    "        # Actualiza self.ruta_archivos para que la próxima prueba procese los resultados de esta prueba\n",
    "        self.ruta_archivos = archivos_salida\n",
    "        # Se fija el log de procesamiento completo de archivos\n",
    "        self.logger.info('Procesamiento completo de archivos de estaciones HR. Archivos generados: %s', archivos_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58f92b9d-0c3a-4652-aa4b-f41a66ab8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador = AutomatTS30cmEMA('RawUnmodified_TS30') #Test_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d4348e0-435a-4f34-ad20-e1d5d8da9827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "procesador.procesar_archivos(procesador.p_transm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d2d470b-c286-4289-90e5-8d9148c65a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_estruc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c17071-31e8-4484-9ae9-7ce1af648709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_limrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ea10b68-a8cb-4b67-b977-65d83029a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' ... '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:278: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk.loc[condicion_0PSO0, 'Estado']\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_perst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a4b8d2a-8da3-4629-8884-bdc299e12d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan '0PSO0' nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:359: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_jmp.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_jmp.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:375: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_jmp.index] = chunk_jmp\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_jump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aafcc6e5-8bee-4f94-9d04-14d4dd4d97e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:429: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:440: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hm.index] = chunk_hm\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:429: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:440: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hm.index] = chunk_hm\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:429: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:440: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hm.index] = chunk_hm\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:429: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:440: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hm.index] = chunk_hm\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:429: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:440: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' nan nan ... nan nan '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hm.index] = chunk_hm\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:429: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:440: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hm.index] = chunk_hm\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:429: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:440: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... '0PSO0' nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hm.index] = chunk_hm\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:429: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0'\n",
      " '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0' '0PSO0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk_hm.loc[condicion_0PSO0, 'Estado_Anterior'] = chunk_hm.loc[condicion_0PSO0, 'Estado']\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:440: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  chunk.loc[chunk_hm.index] = chunk_hm\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_valvminmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c2e9e11-6850-4803-9a51-5bbc30c78678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43d3f1d7-4219-42d7-b574-e61723082392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n",
      "C:\\Users\\palvarez\\AppData\\Local\\Temp\\ipykernel_29664\\54528303.py:636: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in reader:\n"
     ]
    }
   ],
   "source": [
    "procesador.procesar_archivos(procesador.p_coherPNv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analizar presencia de '0PAT0'\n",
    "# Cambia este directorio al lugar donde tengas tu carpeta 'ReadytoCassandraFiles'\n",
    "directorio = 'RawUnmodified_TS10' #r'Test_QC/10T'\n",
    "# Lista para almacenar los nombres de los archivos que contienen '0PSO1' en la columna 'Estado'\n",
    "cantdatos_0PAT = []\n",
    "\n",
    "# Itera sobre cada archivo en el directorio\n",
    "for archivo in os.listdir(directorio):\n",
    "    if archivo.endswith('_qc.csv'):\n",
    "        # Construye la ruta completa al archivo\n",
    "        ruta_archivo = os.path.join(directorio, archivo)\n",
    "        # Especifica los tipos de dato para las columnas deseadas\n",
    "        tipos_de_dato = {'Estado': str, 'Estado_Anterior': str}\n",
    "        # Lee el archivo CSV en un DataFrame de pandas\n",
    "        df = pd.read_csv(ruta_archivo, encoding='latin-1',dtype=tipos_de_dato)\n",
    "        # Checa cuántos '0PER0' hay en la columna 'Estado'\n",
    "        count_0PAT0 = df['Estado'].value_counts().get('0PAT0', 0)\n",
    "        # Guarda el nombre del archivo y la cantidad de datos con '0PER0'\n",
    "        cantdatos_0PAT.append((archivo, count_0PAT0))\n",
    "\n",
    "# Imprime la cantidad de datos con '0PER0' en cada archivo\n",
    "#for archivo, count in cantdatos_0PAT:\n",
    "    #print(f\"Archivo: {archivo}, Datos con '0PER0': {count}\")\n",
    "\n",
    "# Crear un DataFrame a partir de los resultados\n",
    "df_resultados = pd.DataFrame(cantdatos_0PAT, columns=['Archivo', 'Cantidad_0PAT0'])\n",
    "# Guardar resultados\n",
    "prueba = 'jump'\n",
    "df_resultados.to_csv(f'cant_{prueba}_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449b253-9dcb-4b22-896d-a898101a2cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffae449-bdf5-43d3-8a79-d968c7460a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559f9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
