{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9cea67",
   "metadata": {},
   "source": [
    "# Rutina de análisis inicial y de resultados de datos etiquetados durante QC a EMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20690e7",
   "metadata": {},
   "source": [
    "> Elaborado por Paola Álvarez, profesional contratista IDEAM, contrato 196 de 2024. Comentarios o inquietudes, remitir a *palvarez@ideam.gov.co* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d67452",
   "metadata": {},
   "source": [
    "El análisis de resultados se incluye dentro del documento de diagnóstico de series temporales.\n",
    "___\n",
    "**Librerías:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42949f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import os\n",
    "import statistics\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de0e53",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9a310",
   "metadata": {},
   "source": [
    "### Longitud y continuidad series de datos de EMA - Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27f4f3-99ce-434a-9245-e56e45fc74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the CSV files\n",
    "data_directory = \"../OE_3_QC_Variables/5_Evaporacion/RawUnmodified_EV/\"\n",
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Load each CSV file into a dataframe and add it to the list\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(data_directory, filename), parse_dates=['Fecha'], encoding='latin-1')\n",
    "\n",
    "            # Se verifica si 'Estado' existe y se aplica filtro\n",
    "            if 'Estado' in df.columns:\n",
    "                df = df[~df['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PSO0','0PAT','0PER']]))]\n",
    "\n",
    "            # Only proceed if the DataFrame is not empty after filtering\n",
    "            if not df.empty:\n",
    "                df = df.copy()\n",
    "                df.set_index('Fecha', inplace=True)\n",
    "                df['Presence'] = 1  # Add a column to indicate data presence\n",
    "                dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "# Se muestran los headers y fechas por archivo para ver estructura - Para caso de ejemplo\n",
    "dataframes_info = [(df.head(), df.index.min(), df.index.max()) for df in dataframes]\n",
    "dataframes_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08485480-900a-4190-9743-b90645f38526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta si\n",
    "# Ordenar lista de dataframes\n",
    "dataframes = sorted(dataframes, key=lambda x: x['Station'].iloc[0])\n",
    "\n",
    "# Se crea el date range con las fechas inicial y final conocidas, para presión atmosférica 01/01/2001 a 03/04/2024, horaria\n",
    "date_range = pd.date_range(start=\"2001-12-01 00:00\", end=\"2024-10-15 23:00\", freq='h')\n",
    "\n",
    "# Número de estaciones por gráfico\n",
    "estaciones_por_grafico = 50\n",
    "\n",
    "# Total de gráficos a generar\n",
    "total_graficos = len(dataframes) // estaciones_por_grafico + (len(dataframes) % estaciones_por_grafico > 0)\n",
    "\n",
    "# Configuración de la fuente para todo el gráfico\n",
    "font = {'family': 'Franklin Gothic Book',\n",
    "        'weight': 'normal',\n",
    "        'size': 10}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "for j in range(total_graficos):\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    inicio = j * estaciones_por_grafico\n",
    "    fin = min(inicio + estaciones_por_grafico, len(dataframes))  # Asegurarse de no pasarse del rango\n",
    "\n",
    "    # Define a helper function to plot data for clarity\n",
    "    def plot_station_data(ax, data, index, station_label):\n",
    "        # Find where data is present\n",
    "        presence_mask = data['Presence'] == 1\n",
    "        # Plot only where data is present\n",
    "        ax.fill_between(data.index, index - 0.45, index + 0.45, where=~presence_mask, color='#f0f0f0', step='mid', label='Sin dato' if i == 1 else \"\")\n",
    "        ax.fill_between(data.index, index - 0.45, index + 0.45, where=presence_mask, color='#5dade2', step='mid', label='Con dato' if i == 1 else \"\")\n",
    "\n",
    "    for i, df in enumerate(dataframes[inicio:fin], start=1):\n",
    "        # Check for duplicates\n",
    "        duplicates = df.index.duplicated()\n",
    "        # Optionally, drop or keep the first/last occurrence of duplicates\n",
    "        if duplicates.any():\n",
    "            df = df.loc[~duplicates]\n",
    "        # Reindex the dataframe to the full date range, filling missing data with 0 (indicating absence)\n",
    "        df_complete = df.reindex(date_range, fill_value=0)\n",
    "        plot_station_data(ax, df_complete, i, f\"Station {df['Station'].iloc[0]}\")\n",
    "\n",
    "    #ax.legend(loc='upper left')  # Agrega la leyenda en la esquina superior izquierda\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=2)\n",
    "    # Setting the labels and ticks for better readability\n",
    "    ax.set_yticks(range(1, fin - inicio + 1))\n",
    "    ax.set_yticklabels([f\"{df['Station'].iloc[0]}\" for df in dataframes[inicio:fin]], fontsize=8)\n",
    "    ax.set_ylim(0.5, fin - inicio + 0.5)\n",
    "    ax.set_xlim(date_range[0], date_range[-1])\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Código de estación CNE')\n",
    "    plt.title(f'Completitud de datos por estación - Grupo de estaciones {j+1} de {total_graficos}')\n",
    "    plt.grid(True, which='both', linestyle='-', linewidth=0.25)\n",
    "\n",
    "    # Show and save the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'completitud_datos_grafico_{j+1}.png')  # Guarda el gráfico como un archivo PNG\n",
    "    plt.close(fig)  # Cierra la figura para liberar memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd2b52-4f21-49c4-8793-b5e0ceaa6e75",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271f66c",
   "metadata": {},
   "source": [
    "### Cantidad total de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d0eff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número total de datos es: 9519677\n"
     ]
    }
   ],
   "source": [
    "## Se indaga sobre cuál es la cantidad de datos de todas las series descargadas en el período 2001-01-01 al 2024-03-31\n",
    "# Se crea la función cantidad_datos\n",
    "def cantidad_datos(archivos):\n",
    "    total_filas = 0\n",
    "\n",
    "    for archivo in archivos:\n",
    "        # Se utiliza el método 'chunksize' de pandas para leer los archivos por partes (chunks)\n",
    "        # y procesarlos de forma incremental sin cargar todos los datos en memoria al mismo tiempo\n",
    "        chunks = pd.read_csv(archivo, encoding='latin-1', chunksize=100000)  # Se establece este valor de chunk para poder hacer otras actividades\n",
    "\n",
    "        for chunk in chunks:\n",
    "            total_filas += len(chunk)\n",
    "\n",
    "    return total_filas\n",
    "\n",
    "# Ruta de la carpeta con los archivos CSV\n",
    "carpeta_proces = \"../OE_3_QC_Variables/5_Evaporacion/RawUnmodified_EV/\"\n",
    "\n",
    "# Obtener la lista de archivos en la carpeta\n",
    "archivos = [carpeta_proces + archivo for archivo in os.listdir(carpeta_proces) if archivo.endswith('.csv')]\n",
    "\n",
    "# Llamar a la función para contar las filas\n",
    "total_filas = cantidad_datos(archivos)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(\"El número total de datos es:\", total_filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae3a4b-8a6f-42a6-8e20-dec3623e126e",
   "metadata": {},
   "source": [
    "### Contar datos por fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4abc70dd-488c-4fb8-ba51-6f3ff6d1b6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Station   Año  Cantidad_año  Año-mes  Cantidad_año-mes Año-mes-dia  \\\n",
      "1646  11105020  2005           773  2005-08                 4  2005-08-31   \n",
      "1645  11105020  2005           773  2005-09                10  2005-09-26   \n",
      "1633  11105020  2005           773  2005-10               590  2005-10-05   \n",
      "1635  11105020  2005           773  2005-10               590  2005-10-06   \n",
      "1634  11105020  2005           773  2005-10               590  2005-10-07   \n",
      "\n",
      "      Cantidad_año-mes-dia  \n",
      "1646                     4  \n",
      "1645                    10  \n",
      "1633                     7  \n",
      "1635                     4  \n",
      "1634                     6  \n"
     ]
    }
   ],
   "source": [
    "def contar_datos_por_fechas(archivos):\n",
    "    resultados = []\n",
    "\n",
    "    for archivo in archivos:\n",
    "        chunks = pd.read_csv(archivo, encoding='latin-1', chunksize=100000)\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            chunk['Fecha'] = pd.to_datetime(chunk['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "            estacion = chunk['Station'].iloc[0]\n",
    "            \n",
    "            # Conteo por año, mes y día\n",
    "            conteo_dia = chunk['Fecha'].dt.to_period('D').value_counts().rename_axis('Año-mes-dia').reset_index(name='Cantidad_año-mes-dia')\n",
    "            conteo_dia['Año-mes'] = conteo_dia['Año-mes-dia'].dt.to_timestamp().dt.to_period('M')\n",
    "            conteo_dia['Año'] = conteo_dia['Año-mes'].dt.year\n",
    "\n",
    "            # Conteo por año y mes\n",
    "            conteo_mes = chunk['Fecha'].dt.to_period('M').value_counts().rename_axis('Año-mes').reset_index(name='Cantidad_año-mes')\n",
    "            conteo_mes['Año'] = conteo_mes['Año-mes'].dt.year\n",
    "\n",
    "            # Conteo por año\n",
    "            conteo_anual = chunk['Fecha'].dt.year.value_counts().rename_axis('Año').reset_index(name='Cantidad_año')\n",
    "            \n",
    "            # Combinar con la información de la estación\n",
    "            conteo_anual['Station'] = estacion\n",
    "            conteo_mes['Station'] = estacion\n",
    "            conteo_dia['Station'] = estacion\n",
    "            \n",
    "            # Merge considerando Station, Año y Año-mes\n",
    "            merged_data = pd.merge(pd.merge(conteo_anual, conteo_mes, on=['Station', 'Año']), conteo_dia, on=['Station', 'Año', 'Año-mes'])\n",
    "            resultados.append(merged_data)\n",
    "    \n",
    "    df_resultados = pd.concat(resultados, ignore_index=True)\n",
    "    # Reordenar columnas\n",
    "    df_resultados = df_resultados[['Station', 'Año', 'Cantidad_año', 'Año-mes', 'Cantidad_año-mes','Año-mes-dia','Cantidad_año-mes-dia']]\n",
    "    df_resultados.sort_values(by=['Station', 'Año', 'Año-mes', 'Año-mes-dia'], inplace=True)\n",
    "    \n",
    "    # Rellenar la columna 'Cantidad_año' sólo una vez por cada año y estación\n",
    "    df_resultados['Cantidad_año'] = df_resultados.groupby(['Station', 'Año'])['Cantidad_año'].transform(lambda x: x.iloc[0] if not x.isna().all() else pd.NA)\n",
    "    \n",
    "    df_resultados.to_csv('ConteoDatos_AnioMesDia_EV.csv', index=False, encoding='latin-1')\n",
    "    return df_resultados\n",
    "\n",
    "# Uso de la función\n",
    "carpeta_proces = \"../OE_3_QC_Variables/5_Evaporacion/RawUnmodified_EV/\"\n",
    "archivos = [carpeta_proces + archivo for archivo in os.listdir(carpeta_proces) if archivo.endswith('.csv')]\n",
    "resultados = contar_datos_por_fechas(archivos)\n",
    "print(resultados.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e05e174-1767-4db4-9ccb-7b686eb25bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Año</th>\n",
       "      <th>Cantidad_año</th>\n",
       "      <th>Año-mes</th>\n",
       "      <th>Cantidad_año-mes</th>\n",
       "      <th>Año-mes-dia</th>\n",
       "      <th>Cantidad_año-mes-dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11105020</td>\n",
       "      <td>2005</td>\n",
       "      <td>773</td>\n",
       "      <td>2005-08</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-08-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11105020</td>\n",
       "      <td>2005</td>\n",
       "      <td>773</td>\n",
       "      <td>2005-09</td>\n",
       "      <td>10</td>\n",
       "      <td>2005-09-26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11105020</td>\n",
       "      <td>2005</td>\n",
       "      <td>773</td>\n",
       "      <td>2005-10</td>\n",
       "      <td>590</td>\n",
       "      <td>2005-10-05</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11105020</td>\n",
       "      <td>2005</td>\n",
       "      <td>773</td>\n",
       "      <td>2005-10</td>\n",
       "      <td>590</td>\n",
       "      <td>2005-10-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11105020</td>\n",
       "      <td>2005</td>\n",
       "      <td>773</td>\n",
       "      <td>2005-10</td>\n",
       "      <td>590</td>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302880</th>\n",
       "      <td>3526500201</td>\n",
       "      <td>2024</td>\n",
       "      <td>6462</td>\n",
       "      <td>2024-10</td>\n",
       "      <td>338</td>\n",
       "      <td>2024-10-11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302881</th>\n",
       "      <td>3526500201</td>\n",
       "      <td>2024</td>\n",
       "      <td>6462</td>\n",
       "      <td>2024-10</td>\n",
       "      <td>338</td>\n",
       "      <td>2024-10-12</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302882</th>\n",
       "      <td>3526500201</td>\n",
       "      <td>2024</td>\n",
       "      <td>6462</td>\n",
       "      <td>2024-10</td>\n",
       "      <td>338</td>\n",
       "      <td>2024-10-13</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302883</th>\n",
       "      <td>3526500201</td>\n",
       "      <td>2024</td>\n",
       "      <td>6462</td>\n",
       "      <td>2024-10</td>\n",
       "      <td>338</td>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302884</th>\n",
       "      <td>3526500201</td>\n",
       "      <td>2024</td>\n",
       "      <td>6462</td>\n",
       "      <td>2024-10</td>\n",
       "      <td>338</td>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302885 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Station   Año  Cantidad_año  Año-mes  Cantidad_año-mes Año-mes-dia  \\\n",
       "0         11105020  2005           773  2005-08                 4  2005-08-31   \n",
       "1         11105020  2005           773  2005-09                10  2005-09-26   \n",
       "2         11105020  2005           773  2005-10               590  2005-10-05   \n",
       "3         11105020  2005           773  2005-10               590  2005-10-06   \n",
       "4         11105020  2005           773  2005-10               590  2005-10-07   \n",
       "...            ...   ...           ...      ...               ...         ...   \n",
       "302880  3526500201  2024          6462  2024-10               338  2024-10-11   \n",
       "302881  3526500201  2024          6462  2024-10               338  2024-10-12   \n",
       "302882  3526500201  2024          6462  2024-10               338  2024-10-13   \n",
       "302883  3526500201  2024          6462  2024-10               338  2024-10-14   \n",
       "302884  3526500201  2024          6462  2024-10               338  2024-10-15   \n",
       "\n",
       "        Cantidad_año-mes-dia  \n",
       "0                          4  \n",
       "1                         10  \n",
       "2                          7  \n",
       "3                          4  \n",
       "4                          6  \n",
       "...                      ...  \n",
       "302880                    22  \n",
       "302881                    24  \n",
       "302882                    24  \n",
       "302883                    24  \n",
       "302884                     5  \n",
       "\n",
       "[302885 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lectura de frecuencias para revisión inicial\n",
    "dffreq = pd.read_csv('ConteoDatos_AnioMesDia_EV.csv', encoding='latin-1')\n",
    "dffreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2de44772-d910-4344-b7b5-8d988f1e9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se agrupa por 'Station' y se suma la columna respectiva\n",
    "sttn_qtty = dffreq.groupby('Station')['Cantidad_año-mes-dia'].sum().reset_index()\n",
    "\n",
    "# Se renombra la columna\n",
    "sttn_qtty.rename(columns={'Cantidad_año-mes-dia': 'CantDatos'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6c63231-e43e-42bb-ba8d-52536ee30a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sttn_qtty.to_csv('CantDatosPorEstacion_EV.csv', encoding='latin-1', index=True, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44cc995",
   "metadata": {},
   "source": [
    "### Obtener fechas iniciales y finales de estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6980883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_fechas(archivo):\n",
    "    try:\n",
    "        # Se lee el archivo\n",
    "        datos = pd.read_csv(archivo, encoding='latin-1')#, names=['Fecha', 'Valor'])\n",
    "        try:\n",
    "            datos['Fecha'] = pd.to_datetime(datos['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "        except ValueError:\n",
    "            datos['Fecha'] = pd.to_datetime(datos['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Se obtiene el código de la estación\n",
    "        station = datos['Station'].values[0]\n",
    "        \n",
    "        # Se obtiene primera y última fecha \n",
    "        fecha_inicial = datos['Fecha'].iloc[0]\n",
    "        fecha_final = datos['Fecha'].iloc[-1]\n",
    "        \n",
    "        return station, fecha_inicial, fecha_final\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error con el archivo {archivo}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def main():\n",
    "    # Cambia la ruta según la ubicación de tu carpeta\n",
    "    ruta_carpeta = \"../OE_3_QC_Variables/5_Evaporacion/RawUnmodified_EV/\"\n",
    "\n",
    "    # Listamos todos los archivos en la carpeta que terminen con .csv\n",
    "    archivos = [f for f in os.listdir(ruta_carpeta) if f.endswith('.csv')]\n",
    "    \n",
    "    # Creamos una lista para almacenar los resultados\n",
    "    resultados = []\n",
    "\n",
    "    # Iteramos sobre cada archivo y obtenemos las fechas\n",
    "    for archivo in archivos:\n",
    "        ruta_archivo = os.path.join(ruta_carpeta, archivo)\n",
    "        station, fecha_inicial, fecha_final = obtener_fechas(ruta_archivo)\n",
    "        \n",
    "        if station and fecha_inicial and fecha_final:\n",
    "            resultados.append([station, fecha_inicial, fecha_final])\n",
    "    \n",
    "    # Convertimos los resultados a un DataFrame\n",
    "    resultados_df = pd.DataFrame(resultados, columns=['CodEstacion', 'fecha_inicial', 'fecha_final'])\n",
    "    \n",
    "    # Guardamos el DataFrame como un archivo CSV\n",
    "    resultados_df.to_csv('FechaInicialFinal_EV.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340adf4d",
   "metadata": {},
   "source": [
    "### Obtener estadísticos descriptivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad0582ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11105020 -10.0 32778.0 12.240600740639143 2.0 300.72481919585067 90435.41688037707\n",
      "11135030 -10.0 10149.0 961.8640816747447 19.0 2901.6885810161843 8419796.621199718\n",
      "12015100 -29696.0 32778.0 41.61201887627194 24.0 176.71873582877956 31229.51159292198\n",
      "12015110 -9.0 1536.0 27.497274651048457 9.0 54.97807916072609 3022.5891882030646\n",
      "13085050 -6507.0 32779.0 24.615343360149236 12.0 334.32951210376797 111776.22266354352\n",
      "15085050 -23032.0 32779.0 1277.8742263602605 34.0 3899.034861167012 15202472.84859566\n",
      "16015120 -10.0 360.0 48.47532004230399 39.0 41.93884546202917 1758.8667586879649\n",
      "21015050 -25780.0 27728.0 1027.7516146356913 5.0 3513.263749064712 12343022.170492236\n",
      "21015060 -10.0 679.0 0.849130650769995 -1.0 16.771451967636686 281.2816011027445\n",
      "21015070 -27136.0 32779.0 24.705285015858554 23.0 189.16926744729065 35785.01174654458\n",
      "21115010 0.0 32778.0 62.14738824462286 56.0 295.6880874119241 87431.44503732165\n",
      "21115180 -10.0 32778.0 7.831430285184579 0.0 217.29319376106002 47216.332054881575\n",
      "21185090 -16314.0 32779.0 18.809105731844976 0.0 211.49642646786413 44730.738408676654\n",
      "21195170 -31728.0 62495.0 1517.0877631869093 74.0 4291.908350802473 18420477.291688003\n",
      "21195190 -10.0 111.0 63.92152468771779 54.0 34.72926942413844 1206.1221547343969\n",
      "21205480 -1.419 239.6193 112.07034679133223 123.821 68.07826207122818 4634.649766638825\n",
      "21205509 0.405 239.546 143.6482114064727 146.729 58.74601135576385 3451.093850211535\n",
      "21205511 0.0 241.249 156.8215504685545 150.65449999999998 46.46478536654323 2158.97627915893\n",
      "21205512 0.0 239.582 141.00654693538033 135.2476 54.4837260278621 2968.4764018791375\n",
      "21205513 2.504 239.519 168.72652123785133 163.32 24.54896490344098 602.6516778303769\n",
      "21205514 48.677 370.041 149.69048227908306 147.133 26.05289809613198 678.7534992074372\n",
      "21205515 0.0 239.561 132.30821384275526 134.684 40.83077644713722 1667.1523052760951\n",
      "21205516 0.317 376.043 142.39150059797788 150.18 63.48061603925738 4029.7886127236206\n",
      "21205517 39.38 239.565 157.0870986273189 154.8965 41.035656967708874 1683.9251427714742\n",
      "21205518 0.0 864417.4 134.41933762858727 124.562 2233.5150599255776 4988589.522914357\n",
      "21205519 0.0 237.318 155.8718056989488 152.873 33.40689398446842 1116.020565689512\n",
      "21205521 0.0 239.65 83.16337825128763 102.22825 74.67745055346914 5576.721621165828\n",
      "21205522 0.0 239.436 136.61074395504076 142.883 45.70710459890458 2089.139410815204\n",
      "21205523 3.411571 238.1808 120.42960295460887 121.18424999999999 28.650625231938644 820.8583261809994\n",
      "21205524 0.0 232.8621 154.94627659781582 156.7705 49.561648483605076 2456.357000412433\n",
      "21205525 40.229 238.391 149.8250391510856 152.773 40.749734298441396 1660.5408453935713\n",
      "21205526 0.411 239.44 141.1704003182753 146.334 62.25072504733631 3875.1527689190643\n",
      "21205527 2.039 239.62 145.74749896565893 155.327 44.890789647084866 2015.1829951388215\n",
      "21205970 -11.0 32778.0 29.23150444876022 16.0 144.5478609409588 20894.084102606765\n",
      "21206790 -11.0 32778.0 29.23150444876022 16.0 144.5478609409588 20894.084102606765\n",
      "21206930 -32184.0 63908.0 2069.5038116467426 24.0 4889.452069597325 23906741.54088957\n",
      "21206950 -30208.0 32308.0 500.81573473632693 13.0 2475.268253245933 6126952.925527172\n",
      "21206980 -32448.0 58823.0 124.27088468639289 1.0 1495.300490474711 2235923.5568139115\n",
      "21206990 -32768.0 32779.0 29.613385697677884 25.0 238.02359423940047 56655.23141464276\n",
      "21237060 0.0 239.53 148.1317461288086 154.368 59.13398319413958 3496.8279684047825\n",
      "21255160 -10.0 32778.0 37.17874409709319 0.0 514.3292177823081 264534.5442645609\n",
      "23065160 0.0 385.167 135.93953112002853 156.041 83.78067424545583 7019.201377023185\n",
      "23065506 44.535 239.232 172.02892872449453 162.008 40.430775027808 1634.647569349223\n",
      "23065507 0.588 241.163 197.27191398473096 201.574 45.0726390062144 2031.54278698452\n",
      "23085260 -10.0 209.0 75.3772147926423 27.0 81.4457388854148 6633.408382591168\n",
      "23105060 -10.0 32778.0 10.828587745777924 3.0 324.71716326520504 105441.23611900183\n",
      "23195040 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "23195240 -10.0 32778.0 11.900644721668938 0.0 169.97272086388008 28890.725837870497\n",
      "24015110 -10.0 32778.0 30.873068036800092 32.0 194.12602205608388 37684.91243931917\n",
      "24015507 0.3217098 239.642 143.02263967838778 143.824 49.435130881060914 2443.832165227622\n",
      "24015508 2.342245e-31 239.203 146.97796399103333 141.638 38.34159959550868 1470.0782595423113\n",
      "24015513 0.0 123.65 0.5601633705932932 0.04 6.253237816673493 39.10298319187547\n",
      "24025050 0.0 227.01 0.22446435630517855 0.03 4.499201938018338 20.24281807906797\n",
      "24025090 -23540.0 32779.0 26.190738158935904 26.0 203.93289163278232 41588.62428970813\n",
      "24035390 -9024.0 62495.0 718.3833710369606 13.0 3073.4012116101435 9445795.007526698\n",
      "24035430 -11.0 32778.0 25.644412641112453 22.0 153.3571582847337 23518.417997168868\n",
      "24055070 -121073.0 131071.0 1637.3140469423479 7.0 6272.210970817852 39340630.46244782\n",
      "24055080 -17.0 32778.0 30.183512992761546 2.0 479.4166503191566 229840.32460324044\n",
      "25010010 -0.1 205.3 161.12979006736646 185.0 52.8632618595657 2794.524454433013\n",
      "25015020 -19961.0 343.0 15.681521518090733 19.0 287.50156199173136 82657.14814768535\n",
      "25025100 -111.0 1003.0 110.95629939349386 96.1 127.37673390216499 16224.832339582947\n",
      "25025240 -0.1 197.3 145.0290238233585 170.6 51.00891423927996 2601.909331870218\n",
      "25025280 -10.0 210.0 73.58799820868786 65.0 61.446458323180174 3775.667240462318\n",
      "25025340 -2060.0 3040.0 63.33494175093237 7.0 143.62457973239484 20628.01990330704\n",
      "26015040 0.0 110.0 21.79338756047963 19.0 16.48283325294065 271.68379204424605\n",
      "26035100 -10.0 32778.0 40.476550452057694 23.0 553.58860694407 306460.34573827597\n",
      "26055110 63.0 70.0 67.08158508158508 67.0 0.5114010837239675 0.2615310684340485\n",
      "26095320 -11.0 32779.0 33.40145969732747 23.0 191.83790544085363 36801.7819639339\n",
      "26105250 -32395.0 32778.0 129.61487651644262 18.0 1279.221302692856 1636407.1412632077\n",
      "26135290 -12297.0 32778.0 11.747726056714821 -8.0 229.70909395600344 52766.26784608801\n",
      "26135300 -16348.0 32778.0 31.604251311718013 23.0 139.2448876258257 19389.138729928825\n",
      "26145090 -129168.0 106350.0 551.4733897404905 0.0 2705.541940592715 7319957.192306195\n",
      "26225060 -10.0 32778.0 38.694589754939436 30.0 212.00164507543454 44944.69751469052\n",
      "26255030 0.0 3.0 0.0003063147973609802 0.0 0.023277897316795686 0.0005418605034912837\n",
      "27015280 -11.0 32779.0 154.34995898417472 6.0 1188.0997258879265 1411580.9586549662\n",
      "27015320 0.0 1.0 0.002183406113537118 0.0 0.046701390529057016 0.0021810198773474965\n",
      "28025120 -26.0 32779.0 1761.6510511325105 5.0 4506.283782694763 20306593.530177828\n",
      "29015040 -32399.0 32778.0 204.08429164196798 14.0 1430.7069584240412 2046922.4008829715\n",
      "29045150 -10.0 32778.0 6.2999451904631405 -9.0 332.86192296047165 110797.05975694297\n",
      "29065130 -20.0 218.0 31.560946095633476 18.0 39.42448407018657 1554.2899442003948\n",
      "35020300 -0.1 258.2 115.54128215942639 127.7 53.33761489771568 2844.9011629770216\n",
      "35025110 -32012.0 9732.0 9.313775711245961 0.0 164.10704143432824 26931.12104832832\n",
      "35025502 0.409 239.43 128.71207756056046 132.2585 52.91849222466288 2800.3668193317053\n",
      "35035130 0.0 110.0 59.79190751445087 72.0 32.92389229807299 1083.98268405511\n",
      "35075070 -10.0 110.0 6.548113129984379 0.0 15.304690844123595 234.2335618342006\n",
      "35075080 -32720.0 53248.0 1176.0347545888717 21.0 3823.9364094506004 14622489.663521951\n",
      "35075090 0.689 239.0902 142.82479281097983 143.75 58.56983692871319 3430.425797856055\n",
      "35095120 -31104.0 32779.0 115.27652824754948 28.0 1008.649346371779 1017373.5039362168\n",
      "35185010 -10.0 32778.0 16.68420621176567 -6.0 185.21593183446387 34304.94140530877\n",
      "35215020 14167.0 62166.0 27840.619565217392 18874.5 16549.564474759703 273888084.30422837\n",
      "35260050 -0.1 999.1 132.79396714247238 141.8 53.41905217150478 2853.5951349019497\n",
      "36015020 -27136.0 33908.0 1513.408069565987 0.0 4255.78457167671 18111702.32052152\n",
      "37015030 -32723.0 58083.0 1307.356077865644 44.0 3927.16725846183 15422642.675934605\n",
      "46015030 0.0 0.0 0.0 0.0 nan nan\n",
      "47035030 -10.0 32778.0 19.220883534136547 0.0 344.04719511574893 118368.47246701422\n",
      "48015040 -2918.4 3277.9 85.624035422567 51.3 106.49182773369617 11340.509374063222\n",
      "51025060 -10.0 32779.0 13.162684506743124 0.0 162.93342515020447 26547.301031177285\n",
      "51025090 -60.86 1255.0 52.74210587424259 50.92 30.15107100609792 909.0870828147586\n",
      "52025080 -10.0 32778.0 0.771072773054773 -3.0 125.04177548271473 15635.44561586964\n",
      "52035040 -10.0 32778.0 64.00421657022383 83.0 297.1510222766711 88298.73004007067\n",
      "52050060 0.0 477.0 7.328802485857702 0.1 32.568832072843776 1060.7288225890975\n",
      "52050080 0.1 209.0 111.86927816484196 114.5 37.08014688379498 1374.9372929238107\n",
      "52050090 0.1 435.9 123.34995756349153 158.9 94.67243194352845 8962.869370102026\n",
      "52055090 -59.3 231.6 116.924337972167 125.2 50.34161225941062 2534.2779248768416\n",
      "52055150 -29581.0 32778.0 306.9365385173926 22.0 1938.4498999229888 3757588.0145114455\n",
      "52055160 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "52055210 -10.0 32779.0 30.547136542399326 29.0 133.30181877892684 17769.374889769857\n",
      "52055220 -11274.0 16640.0 82.17103746397694 126.0 109.79451104878922 12054.834656442697\n",
      "53075020 -11.0 32778.0 -1.0053075894349717 -10.0 213.9606215252675 45779.147563478764\n",
      "54017040 0.0 0.0 0.0 0.0 nan nan\n",
      "55015010 -57.0 32778.0 10.243163883281335 0.0 153.66906411433104 23614.18126577438\n",
      "57025020 -16386.0 32778.0 35.499014838685966 7.0 178.98581162665727 32035.92076365324\n",
      "3526500201 -0.1 999.1 127.26573076158282 135.6 53.677415633589014 2881.264949101066\n",
      "        Station   minimo   maximo       media  mediana      desvest  \\\n",
      "0      11105020    -10.0  32778.0   12.240601      2.0   300.724819   \n",
      "1      11135030    -10.0  10149.0  961.864082     19.0  2901.688581   \n",
      "2      12015100 -29696.0  32778.0   41.612019     24.0   176.718736   \n",
      "3      12015110     -9.0   1536.0   27.497275      9.0    54.978079   \n",
      "4      13085050  -6507.0  32779.0   24.615343     12.0   334.329512   \n",
      "..          ...      ...      ...         ...      ...          ...   \n",
      "108    53075020    -11.0  32778.0   -1.005308    -10.0   213.960622   \n",
      "109    54017040      0.0      0.0    0.000000      0.0          NaN   \n",
      "110    55015010    -57.0  32778.0   10.243164      0.0   153.669064   \n",
      "111    57025020 -16386.0  32778.0   35.499015      7.0   178.985812   \n",
      "112  3526500201     -0.1    999.1  127.265731    135.6    53.677416   \n",
      "\n",
      "         varianza  \n",
      "0    9.043542e+04  \n",
      "1    8.419797e+06  \n",
      "2    3.122951e+04  \n",
      "3    3.022589e+03  \n",
      "4    1.117762e+05  \n",
      "..            ...  \n",
      "108  4.577915e+04  \n",
      "109           NaN  \n",
      "110  2.361418e+04  \n",
      "111  3.203592e+04  \n",
      "112  2.881265e+03  \n",
      "\n",
      "[113 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def obtener_EstadDescript(archivo):\n",
    "    try:\n",
    "        # Se lee el archivo\n",
    "        datos = pd.read_csv(archivo, encoding='latin-1')#, names=['Fecha', 'Valor'])\n",
    "        try:\n",
    "            datos['Fecha'] = pd.to_datetime(datos['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "        except ValueError:\n",
    "            datos['Fecha'] = pd.to_datetime(datos['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Se obtiene el código de la estación\n",
    "        station = datos['Station'].values[0]\n",
    "        \n",
    "        # Se obtienen los estadísticos descriptivos\n",
    "        minimo = datos['Valor'].min()\n",
    "        maximo = datos['Valor'].max()\n",
    "        media = datos['Valor'].mean()\n",
    "        mediana = datos['Valor'].median()\n",
    "        desvest = datos['Valor'].std()\n",
    "        varianza = datos['Valor'].var()\n",
    "        #first_q = datos['Valor'].quantile(0.25)\n",
    "        #third_q = datos['Valor'].quantile(0.75)\n",
    "        \n",
    "        return station, minimo, maximo, media, mediana, desvest, varianza, #first_q, third_q, mediana --no fue posible calcular estos estad.\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error con el archivo {archivo}: {e}\")\n",
    "        print(e.__class__)\n",
    "        return None, None, None, None, None, None, None#, None, None --no fue posible calcular estos estad.\n",
    "\n",
    "def main():\n",
    "    # Cambia la ruta según la ubicación de tu carpeta\n",
    "    ruta_carpeta = \"../OE_3_QC_Variables/5_Evaporacion/RawUnmodified_EV/\"\n",
    "\n",
    "    # Listamos todos los archivos en la carpeta que terminen con .csv\n",
    "    archivos = [f for f in os.listdir(ruta_carpeta) if f.endswith('.csv')]\n",
    "    \n",
    "    # Se crea una lista para almacenar los resultados\n",
    "    resultados = []\n",
    "\n",
    "    # Se itera sobre cada archivo y se obtienen fechas las fechas\n",
    "    for archivo in archivos:\n",
    "        ruta_archivo = os.path.join(ruta_carpeta, archivo)\n",
    "        station, minimo, maximo, media, mediana, desvest, varianza= obtener_EstadDescript(ruta_archivo)\n",
    "        print(station, minimo, maximo, media, mediana, desvest, varianza)\n",
    "        resultados.append([station, minimo, maximo, media, mediana, desvest, varianza])\n",
    "        #if station and minimo: #and maximo and media and mediana and desvest and varianza:\n",
    "            #resultados.append([station, minimo, maximo, media, mediana, desvest, varianza])\n",
    "        #else:\n",
    "            #print(f'Sin suficientes resultado para {archivo}. No se generaron sus estadísticos')\n",
    "    \n",
    "    # Se convierten los resultados a un DataFrame\n",
    "    resultados_df = pd.DataFrame(resultados, columns=['Station', 'minimo', 'maximo', 'media', 'mediana','desvest', 'varianza'])\n",
    "    \n",
    "    print(resultados_df)\n",
    "    \n",
    "    # Se guarda el DataFrame como un archivo CSV\n",
    "    resultados_df.to_csv('EstadDescript_EV.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df16d760-dda9-4659-af72-45c3e70cee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_df = pd.read_csv('EstadDescript_TS10_Raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c86dcad-8226-4e4e-a3c3-d5513ba0c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "altipatm = pd.read_table('EMA_Patm_TMaxMin.txt', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "582de89c-cb55-4dc2-935b-5a5fdfb9c1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Station</th>\n",
       "      <th>lat</th>\n",
       "      <th>long_</th>\n",
       "      <th>nombre</th>\n",
       "      <th>sede</th>\n",
       "      <th>id_rule</th>\n",
       "      <th>codigo</th>\n",
       "      <th>Instituc</th>\n",
       "      <th>FreqInf</th>\n",
       "      <th>Altitud</th>\n",
       "      <th>TmaxNorm</th>\n",
       "      <th>TminNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11030010.0</td>\n",
       "      <td>5.375</td>\n",
       "      <td>-76.613</td>\n",
       "      <td>Valle</td>\n",
       "      <td>09 - Cali</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>IDEAM</td>\n",
       "      <td>H</td>\n",
       "      <td>58</td>\n",
       "      <td>27.853392</td>\n",
       "      <td>19.794912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11035030.0</td>\n",
       "      <td>5.285</td>\n",
       "      <td>-76.628</td>\n",
       "      <td>Valle</td>\n",
       "      <td>09 - Cali</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>IDEAM</td>\n",
       "      <td>H</td>\n",
       "      <td>104</td>\n",
       "      <td>27.376471</td>\n",
       "      <td>19.418962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID     Station    lat   long_ nombre       sede  id_rule  codigo  \\\n",
       "0         1  11030010.0  5.375 -76.613  Valle  09 - Cali        9       9   \n",
       "1         2  11035030.0  5.285 -76.628  Valle  09 - Cali        9       9   \n",
       "\n",
       "  Instituc FreqInf  Altitud   TmaxNorm   TminNorm  \n",
       "0    IDEAM       H       58  27.853392  19.794912  \n",
       "1    IDEAM       H      104  27.376471  19.418962  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altipatm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8778590-87b1-46eb-a8b0-19d2f607e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "estadalt = pd.merge(resultados_df, altipatm[['Station','Altitud']], on='Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0b1c9dc-c99e-479f-ae9d-67bb4a80ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se sobreescriben los estadísticos para incluir altitud\n",
    "estadalt.to_csv('EstadDescript_Patm_Raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb8869-5586-4431-a71a-bf49c612a291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb150cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De datos con QC\n",
    "def obtener_EstadDescript(archivo):\n",
    "    try:\n",
    "        # Se lee el archivo\n",
    "        datos = pd.read_csv(archivo, encoding='latin-1')#, names=['Fecha', 'Valor'])\n",
    "        try:\n",
    "            datos['Fecha'] = pd.to_datetime(datos['Fecha'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "        except ValueError:\n",
    "            datos['Fecha'] = pd.to_datetime(datos['Fecha'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Se hace el filtro para que solo queden los valores que superaron las pruebas\n",
    "        dfC = datos[datos['Estado'].apply(lambda x: any([str(x).startswith(prefix) for prefix in ['0PC']]))]\n",
    "        \n",
    "        # Se obtiene el código de la estación\n",
    "        station = dfC['Station'].values[0]\n",
    "        \n",
    "        # Se obtienen los estadísticos descriptivos\n",
    "        minimo = dfC['Valor'].min()\n",
    "        maximo = dfC['Valor'].max()\n",
    "        media = dfC['Valor'].mean()\n",
    "        #mediana = datos['Valor'].median()\n",
    "        desvest = dfC['Valor'].std()\n",
    "        varianza = dfC['Valor'].var()\n",
    "        #first_q = datos['Valor'].quantile(0.25)\n",
    "        #third_q = datos['Valor'].quantile(0.75)\n",
    "        \n",
    "        return station, minimo, maximo, media, desvest, varianza, #first_q, third_q, mediana --no fue posible calcular estos estad.\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error con el archivo {archivo}: {e}\")\n",
    "        print(e.__class__)\n",
    "        return None, None, None, None, None, None#, None, None, None --no fue posible calcular estos estad.\n",
    "\n",
    "def main():\n",
    "    # Cambia la ruta según la ubicación de tu carpeta\n",
    "    ruta_carpeta = 'DatosEjemplo'\n",
    "\n",
    "    # Listamos todos los archivos en la carpeta que terminen con .csv\n",
    "    archivos = [f for f in os.listdir(ruta_carpeta) if f.endswith('.csv')]\n",
    "    \n",
    "    # Creamos una lista para almacenar los resultados\n",
    "    resultados = []\n",
    "\n",
    "    # Iteramos sobre cada archivo y obtenemos las fechas\n",
    "    for archivo in archivos:\n",
    "        ruta_archivo = os.path.join(ruta_carpeta, archivo)\n",
    "        station, minimo, maximo, media, desvest, varianza= obtener_EstadDescript(ruta_archivo)\n",
    "        \n",
    "        if station and minimo and maximo and media and desvest and varianza:\n",
    "            resultados.append([station, minimo, maximo, media, desvest, varianza])\n",
    "    \n",
    "    # Convertimos los resultados a un DataFrame\n",
    "    resultados_df = pd.DataFrame(resultados, columns=['Station', 'minimo', 'maximo', 'media', 'desvest', 'varianza'])\n",
    "    \n",
    "    # Guardamos el DataFrame como un archivo CSV\n",
    "    resultados_df.to_csv('EstadDescript_Patm_QC.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c424855f",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27419e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
